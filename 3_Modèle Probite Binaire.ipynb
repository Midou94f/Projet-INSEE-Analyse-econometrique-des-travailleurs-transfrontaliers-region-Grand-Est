{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "836d5ec1",
   "metadata": {},
   "source": [
    "# Projet INSEE Partie (3) - RÃ‰GRESSION PROBIT BINAIRE - TRANSFRONTALIER MOBILITÃ‰ TRANSFRONTALIÃˆRE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f35602",
   "metadata": {},
   "source": [
    "## Step 1 : PrÃ©paration de la base donnÃ©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8fcf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STRUCTURE DU FICHIER X_final_clean.csv\n",
      "================================================================================\n",
      "\n",
      "Dimensions : 494,483 lignes Ã— 81 colonnes\n",
      "\n",
      "================================================================================\n",
      "LISTE DES COLONNES\n",
      "================================================================================\n",
      "   1. AGEREV\n",
      "   2. AGEREV_sq\n",
      "   3. GS_1\n",
      "   4. GS_2\n",
      "   5. GS_3\n",
      "   6. GS_4\n",
      "   7. GS_5\n",
      "   8. GS_6\n",
      "   9. EMPL_11\n",
      "  10. EMPL_12\n",
      "  11. EMPL_13\n",
      "  12. EMPL_14\n",
      "  13. EMPL_15\n",
      "  14. EMPL_16\n",
      "  15. EMPL_21\n",
      "  16. EMPL_22\n",
      "  17. EMPL_23\n",
      "  18. INATC_1\n",
      "  19. INATC_2\n",
      "  20. COUPLE_1\n",
      "  21. COUPLE_2\n",
      "  22. NENFR_0\n",
      "  23. NENFR_1\n",
      "  24. NENFR_2\n",
      "  25. NENFR_3\n",
      "  26. NENFR_4\n",
      "  27. NENFR_Z\n",
      "  28. NA5_AZ\n",
      "  29. NA5_BE\n",
      "  30. NA5_FZ\n",
      "  31. NA5_GU\n",
      "  32. NA5_OQ\n",
      "  33. DIPL_1\n",
      "  34. DIPL_11\n",
      "  35. DIPL_12\n",
      "  36. DIPL_13\n",
      "  37. DIPL_14\n",
      "  38. DIPL_15\n",
      "  39. DIPL_16\n",
      "  40. DIPL_17\n",
      "  41. DIPL_18\n",
      "  42. DIPL_19\n",
      "  43. DIPL_2\n",
      "  44. DIPL_3\n",
      "  45. ETUD_1\n",
      "  46. ETUD_2\n",
      "  47. SANI_0\n",
      "  48. SANI_1\n",
      "  49. SANI_2\n",
      "  50. SANI_X\n",
      "  51. SEXE_1\n",
      "  52. SEXE_2\n",
      "  53. TP_1\n",
      "  54. TP_2\n",
      "  55. DEPT_10\n",
      "  56. DEPT_51\n",
      "  57. DEPT_52\n",
      "  58. DEPT_54\n",
      "  59. DEPT_55\n",
      "  60. DEPT_57\n",
      "  61. DEPT_67\n",
      "  62. DEPT_68\n",
      "  63. DEPT_88\n",
      "  64. STOCD_10.0\n",
      "  65. STOCD_21.0\n",
      "  66. STOCD_22.0\n",
      "  67. STOCD_23.0\n",
      "  68. STOCD_30.0\n",
      "  69. VOIT_0.0\n",
      "  70. VOIT_1.0\n",
      "  71. VOIT_2.0\n",
      "  72. VOIT_3.0\n",
      "  73. TYPL_1.0\n",
      "  74. TYPL_2.0\n",
      "  75. TYPL_3.0\n",
      "  76. TYPL_4.0\n",
      "  77. TYPL_5.0\n",
      "  78. TYPL_6.0\n",
      "  79. DNAI_NEAUTREFR\n",
      "  80. DNAI_NEETRANGER\n",
      "  81. DNAI_NEGRANDEST\n",
      "\n",
      "================================================================================\n",
      "TYPES DE DONNÃ‰ES\n",
      "================================================================================\n",
      "AGEREV             int64\n",
      "AGEREV_sq          int64\n",
      "GS_1               int64\n",
      "GS_2               int64\n",
      "GS_3               int64\n",
      "                   ...  \n",
      "TYPL_5.0           int64\n",
      "TYPL_6.0           int64\n",
      "DNAI_NEAUTREFR     int64\n",
      "DNAI_NEETRANGER    int64\n",
      "DNAI_NEGRANDEST    int64\n",
      "Length: 81, dtype: object\n",
      "\n",
      "================================================================================\n",
      "APERÃ‡U (5 premiÃ¨res lignes)\n",
      "================================================================================\n",
      "   AGEREV  AGEREV_sq  GS_1  GS_2  GS_3  GS_4  GS_5  GS_6  EMPL_11  EMPL_12  \\\n",
      "0      35       1225     0     0     0     0     0     1        0        0   \n",
      "1      40       1600     0     0     0     0     0     1        0        0   \n",
      "2      44       1936     0     0     0     0     0     1        0        0   \n",
      "3      62       3844     0     0     0     1     0     0        0        0   \n",
      "4      59       3481     1     0     0     0     0     0        0        0   \n",
      "\n",
      "   ...  VOIT_3.0  TYPL_1.0  TYPL_2.0  TYPL_3.0  TYPL_4.0  TYPL_5.0  TYPL_6.0  \\\n",
      "0  ...         0         1         0         0         0         0         0   \n",
      "1  ...         1         1         0         0         0         0         0   \n",
      "2  ...         1         1         0         0         0         0         0   \n",
      "3  ...         0         1         0         0         0         0         0   \n",
      "4  ...         0         1         0         0         0         0         0   \n",
      "\n",
      "   DNAI_NEAUTREFR  DNAI_NEETRANGER  DNAI_NEGRANDEST  \n",
      "0               1                0                0  \n",
      "1               0                1                0  \n",
      "2               0                1                0  \n",
      "3               0                0                1  \n",
      "4               0                0                1  \n",
      "\n",
      "[5 rows x 81 columns]\n",
      "\n",
      "================================================================================\n",
      "STATISTIQUES\n",
      "================================================================================\n",
      "                    count         mean          std    min    25%     50%  \\\n",
      "AGEREV           494483.0    41.478560    12.471631   15.0   31.0    42.0   \n",
      "AGEREV_sq        494483.0  1876.012229  1053.827441  225.0  961.0  1764.0   \n",
      "GS_1             494483.0     0.012114     0.109394    0.0    0.0     0.0   \n",
      "GS_2             494483.0     0.056637     0.231148    0.0    0.0     0.0   \n",
      "GS_3             494483.0     0.162653     0.369049    0.0    0.0     0.0   \n",
      "...                   ...          ...          ...    ...    ...     ...   \n",
      "TYPL_5.0         494483.0     0.000562     0.023704    0.0    0.0     0.0   \n",
      "TYPL_6.0         494483.0     0.000677     0.026020    0.0    0.0     0.0   \n",
      "DNAI_NEAUTREFR   494483.0     0.144130     0.351222    0.0    0.0     0.0   \n",
      "DNAI_NEETRANGER  494483.0     0.127818     0.333888    0.0    0.0     0.0   \n",
      "DNAI_NEGRANDEST  494483.0     0.728051     0.444964    0.0    0.0     1.0   \n",
      "\n",
      "                    75%      max  \n",
      "AGEREV             52.0    101.0  \n",
      "AGEREV_sq        2704.0  10201.0  \n",
      "GS_1                0.0      1.0  \n",
      "GS_2                0.0      1.0  \n",
      "GS_3                0.0      1.0  \n",
      "...                 ...      ...  \n",
      "TYPL_5.0            0.0      1.0  \n",
      "TYPL_6.0            0.0      1.0  \n",
      "DNAI_NEAUTREFR      0.0      1.0  \n",
      "DNAI_NEETRANGER     0.0      1.0  \n",
      "DNAI_NEGRANDEST     1.0      1.0  \n",
      "\n",
      "[81 rows x 8 columns]\n",
      "\n",
      "================================================================================\n",
      "VALEURS MANQUANTES\n",
      "================================================================================\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier X\n",
    "X = pd.read_csv('/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/ML_READY/FINAL_AFTER_ARBITRAGES/X_final_clean.csv')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STRUCTURE DU FICHIER X_final_clean.csv\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nDimensions : {X.shape[0]:,} lignes Ã— {X.shape[1]} colonnes\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LISTE DES COLONNES\")\n",
    "print(\"=\"*80)\n",
    "for i, col in enumerate(X.columns):\n",
    "    print(f\"  {i+1:>2}. {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TYPES DE DONNÃ‰ES\")\n",
    "print(\"=\"*80)\n",
    "print(X.dtypes)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"APERÃ‡U (5 premiÃ¨res lignes)\")\n",
    "print(\"=\"*80)\n",
    "print(X.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTIQUES\")\n",
    "print(\"=\"*80)\n",
    "print(X.describe().T)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VALEURS MANQUANTES\")\n",
    "print(\"=\"*80)\n",
    "print(X.isnull().sum()[X.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944719ad",
   "metadata": {},
   "source": [
    "# Choix des catÃ©gories de rÃ©fÃ©rences + check vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb4c143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DIAGNOSTIC PRÃ‰-PROBIT : 17 VARIABLES CONCEPTUELLES\n",
      "================================================================================\n",
      "\n",
      "Base : 494,483 obs | Transfrontaliers : 44,264 (8.95%)\n",
      "\n",
      "================================================================================\n",
      "1. STRUCTURE : 81 DUMMIES â†’ 17 VARIABLES CONCEPTUELLES\n",
      "================================================================================\n",
      "\n",
      "Variable conceptuelle   Nb dummies Colonnes\n",
      "--------------------------------------------------------------------------------\n",
      "AGEREV                     2 AGEREV, AGEREV_sq\n",
      "COUPLE                     2 COUPLE_1, COUPLE_2\n",
      "DEPT                       9 DEPT_10, DEPT_51, DEPT_52 ... (+6)\n",
      "DIPL                      12 DIPL_1, DIPL_11, DIPL_12 ... (+9)\n",
      "DNAI                       3 DNAI_NEAUTREFR, DNAI_NEETRANGER, DNAI_NEGRANDEST\n",
      "EMPL                       9 EMPL_11, EMPL_12, EMPL_13 ... (+6)\n",
      "ETUD                       2 ETUD_1, ETUD_2\n",
      "GS                         6 GS_1, GS_2, GS_3 ... (+3)\n",
      "INATC                      2 INATC_1, INATC_2\n",
      "NA5                        5 NA5_AZ, NA5_BE, NA5_FZ ... (+2)\n",
      "NENFR                      6 NENFR_0, NENFR_1, NENFR_2 ... (+3)\n",
      "SANI                       4 SANI_0, SANI_1, SANI_2 ... (+1)\n",
      "SEXE                       2 SEXE_1, SEXE_2\n",
      "STOCD                      5 STOCD_10.0, STOCD_21.0, STOCD_22.0 ... (+2)\n",
      "TP                         2 TP_1, TP_2\n",
      "TYPL                       6 TYPL_1.0, TYPL_2.0, TYPL_3.0 ... (+3)\n",
      "VOIT                       4 VOIT_0.0, VOIT_1.0, VOIT_2.0 ... (+1)\n",
      "\n",
      "================================================================================\n",
      "2. MODALITÃ‰S PAR VARIABLE (effectifs + taux transfrontalier)\n",
      "================================================================================\n",
      "â†’ Pour choisir la CATÃ‰GORIE DE RÃ‰FÃ‰RENCE du Probit\n",
      "\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š AGEREV (2 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Type: CONTINUE\n",
      "  Moyenne: 41.5 ans | Ã‰cart-type: 12.5\n",
      "  Min: 15 | Max: 101\n",
      "  â†’ Pas de catÃ©gorie de rÃ©fÃ©rence (variable continue)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š COUPLE (2 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  1                         325,880    65.9%           9.7% â† REF (plus frÃ©quente)\n",
      "  2                         168,603    34.1%           7.5% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š DEPT (9 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  67                        118,398    23.9%           4.6% â† REF (plus frÃ©quente)\n",
      "  57                         98,869    20.0%          21.6% \n",
      "  68                         73,587    14.9%          14.1% \n",
      "  54                         64,924    13.1%           9.7% \n",
      "  51                         53,239    10.8%           0.1% \n",
      "  88                         29,098     5.9%           0.2% \n",
      "  10                         27,234     5.5%           0.1% \n",
      "  55                         14,885     3.0%           4.7% \n",
      "  52                         14,249     2.9%           0.1% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š DIPL (12 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  13                        117,859    23.8%           9.6% â† REF (plus frÃ©quente)\n",
      "  16                         75,404    15.2%           7.9% \n",
      "  18                         65,128    13.2%          10.7% \n",
      "  17                         63,260    12.8%           8.3% \n",
      "  15                         56,154    11.4%           8.7% \n",
      "  14                         50,473    10.2%           7.8% \n",
      "  3                          26,638     5.4%           9.1% \n",
      "  12                         16,298     3.3%           8.1% \n",
      "  2                          10,348     2.1%           8.1% \n",
      "  19                          5,428     1.1%          11.2% \n",
      "  11                          4,062     0.8%          12.0% \n",
      "  1                           3,431     0.7%           5.4% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š DNAI (3 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  NEGRANDEST                360,009    72.8%           8.1% â† REF (plus frÃ©quente)\n",
      "  NEAUTREFR                  71,270    14.4%           5.8% \n",
      "  NEETRANGER                 63,204    12.8%          17.5% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š EMPL (9 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  16                        374,974    75.8%          10.4% â† REF (plus frÃ©quente)\n",
      "  15                         40,025     8.1%           5.7% \n",
      "  21                         29,943     6.1%           2.6% \n",
      "  22                         20,770     4.2%           3.6% \n",
      "  11                         14,172     2.9%           1.8% \n",
      "  12                         10,308     2.1%          10.8% \n",
      "  13                          2,437     0.5%           1.3% \n",
      "  14                          1,350     0.3%           9.3% \n",
      "  23                            504     0.1%           3.8% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š ETUD (2 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  2                         469,236    94.9%           9.3% â† REF (plus frÃ©quente)\n",
      "  1                          25,247     5.1%           3.1% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š GS (6 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  5                         133,175    26.9%           7.8% â† REF (plus frÃ©quente)\n",
      "  4                         131,258    26.5%           8.2% \n",
      "  6                         115,625    23.4%          12.3% \n",
      "  3                          80,429    16.3%           9.8% \n",
      "  2                          28,006     5.7%           3.2% \n",
      "  1                           5,990     1.2%           0.4% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š INATC (2 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  1                         458,904    92.8%           8.0% â† REF (plus frÃ©quente)\n",
      "  2                          35,579     7.2%          21.8% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š NA5 (5 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  GU                        222,988    45.1%          11.4% â† REF (plus frÃ©quente)\n",
      "  OQ                        153,798    31.1%           3.5% \n",
      "  BE                         73,852    14.9%          12.9% \n",
      "  FZ                         32,768     6.6%          12.0% \n",
      "  AZ                         11,077     2.2%           0.7% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š NENFR (6 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  1                         124,300    25.1%           9.3% â† REF (plus frÃ©quente)\n",
      "  0                         116,349    23.5%           9.3% \n",
      "  2                         107,206    21.7%           9.5% \n",
      "  Z                         102,533    20.7%           7.8% \n",
      "  3                          33,423     6.8%           8.4% \n",
      "  4                          10,672     2.2%           8.4% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š SANI (4 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  2                         475,443    96.1%           8.9% â† REF (plus frÃ©quente)\n",
      "  1                          15,297     3.1%          11.2% \n",
      "  X                           3,093     0.6%           0.5% \n",
      "  0                             650     0.1%           7.7% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š SEXE (2 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  1                         256,784    51.9%          10.5% â† REF (plus frÃ©quente)\n",
      "  2                         237,699    48.1%           7.2% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š STOCD (5 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  10.0                      302,583    61.2%          10.4% â† REF (plus frÃ©quente)\n",
      "  21.0                      111,524    22.6%           8.3% \n",
      "  22.0                       59,162    12.0%           4.0% \n",
      "  23.0                       11,395     2.3%           6.4% \n",
      "  30.0                        9,819     2.0%           5.3% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š TP (2 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  1                         411,499    83.2%           9.1% â† REF (plus frÃ©quente)\n",
      "  2                          82,984    16.8%           8.3% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š TYPL (6 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  1.0                       293,723    59.4%          10.1% â† REF (plus frÃ©quente)\n",
      "  2.0                       198,316    40.1%           7.4% \n",
      "  3.0                         1,543     0.3%           4.2% \n",
      "  6.0                           335     0.1%           3.9% \n",
      "  4.0                           288     0.1%           4.9% \n",
      "  5.0                           278     0.1%           6.8% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š VOIT (4 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  2.0                       217,963    44.1%          10.1% â† REF (plus frÃ©quente)\n",
      "  1.0                       176,994    35.8%           7.7% \n",
      "  3.0                        65,569    13.3%          11.2% \n",
      "  0.0                        33,957     6.9%           4.2% \n",
      "\n",
      "================================================================================\n",
      "3. VIF - MULTICOLINÃ‰ARITÃ‰ (sur 17 variables conceptuelles)\n",
      "================================================================================\n",
      "MÃ©thode: Label encoding des catÃ©gorielles â†’ VIF\n",
      "Seuils : VIF < 5 âœ“ | 5-10 âš ï¸ | â‰¥10 ğŸ”´\n",
      "\n",
      "Calcul VIF sur 17 variables...\n",
      "\n",
      "Variable               VIF Statut\n",
      "----------------------------------------\n",
      "AGEREV                9.82 âš ï¸ ModÃ©rÃ©\n",
      "NA5                   6.80 âš ï¸ ModÃ©rÃ©\n",
      "DNAI                  5.35 âš ï¸ ModÃ©rÃ©\n",
      "DEPT                  4.89 âœ“ OK\n",
      "COUPLE                3.98 âœ“ OK\n",
      "NENFR                 3.43 âœ“ OK\n",
      "DIPL                  3.04 âœ“ OK\n",
      "EMPL                  2.80 âœ“ OK\n",
      "STOCD                 2.59 âœ“ OK\n",
      "VOIT                  2.56 âœ“ OK\n",
      "GS                    2.56 âœ“ OK\n",
      "SEXE                  2.13 âœ“ OK\n",
      "TYPL                  1.75 âœ“ OK\n",
      "ETUD                  1.40 âœ“ OK\n",
      "TP                    1.32 âœ“ OK\n",
      "INATC                 1.17 âœ“ OK\n",
      "SANI                  1.05 âœ“ OK\n",
      "----------------------------------------\n",
      "VIF moyen : 3.33 | VIF max : 9.82\n",
      "\n",
      "âš ï¸ 3 variable(s) avec VIF â‰¥ 5\n",
      "\n",
      "================================================================================\n",
      "4. CORRÃ‰LATIONS FORTES (|Ï| > 0.4)\n",
      "================================================================================\n",
      "\n",
      "âœ… Aucune corrÃ©lation |Ï| > 0.4\n",
      "\n",
      "================================================================================\n",
      "5. CATÃ‰GORIES DE RÃ‰FÃ‰RENCE SUGGÃ‰RÃ‰ES (pour Probit)\n",
      "================================================================================\n",
      "CritÃ¨re: modalitÃ© la plus frÃ©quente (convention standard)\n",
      "\n",
      "Variable        RÃ©fÃ©rence suggÃ©rÃ©e             Justification\n",
      "----------------------------------------------------------------------\n",
      "AGEREV          (continue)                     Pas de rÃ©fÃ©rence\n",
      "COUPLE          En couple                      65.9% des obs\n",
      "DEPT            67                             23.9% des obs\n",
      "DIPL            CAP/BEP                        23.8% des obs\n",
      "DNAI            NÃ© Grand Est                   72.8% des obs\n",
      "EMPL            CDI/Fonctionnaire              75.8% des obs\n",
      "ETUD            Non Ã©tudiant                   94.9% des obs\n",
      "GS              EmployÃ©s                       26.9% des obs\n",
      "INATC           FranÃ§ais                       92.8% des obs\n",
      "NA5             Commerce/Services              45.1% des obs\n",
      "NENFR           1                              25.1% des obs\n",
      "SANI            Salle de bain                  96.1% des obs\n",
      "SEXE            Homme                          51.9% des obs\n",
      "STOCD           PropriÃ©taire                   61.2% des obs\n",
      "TP              Temps complet                  83.2% des obs\n",
      "TYPL            Maison                         59.4% des obs\n",
      "VOIT            2 voitures                     44.1% des obs\n",
      "\n",
      "================================================================================\n",
      "FIN DU DIAGNOSTIC\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# ============================================\n",
    "# CHARGER DONNÃ‰ES\n",
    "# ============================================\n",
    "X = pd.read_csv('/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/ML_READY/FINAL_AFTER_ARBITRAGES/X_final_clean.csv')\n",
    "y = pd.read_csv('/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/ML_READY/FINAL_AFTER_ARBITRAGES/y_final.csv')\n",
    "\n",
    "df = X.copy()\n",
    "df['Y'] = y.values.ravel() if len(y.shape) > 1 else y.values\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DIAGNOSTIC PRÃ‰-PROBIT : 17 VARIABLES CONCEPTUELLES\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBase : {len(df):,} obs | Transfrontaliers : {df['Y'].sum():,} ({df['Y'].mean()*100:.2f}%)\")\n",
    "\n",
    "# ============================================\n",
    "# 1. MAPPING DUMMIES â†’ VARIABLES CONCEPTUELLES\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"1. STRUCTURE : 81 DUMMIES â†’ 17 VARIABLES CONCEPTUELLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Identifier les prÃ©fixes (variables conceptuelles)\n",
    "def get_prefix(col):\n",
    "    if col in ['AGEREV', 'AGEREV_sq']:\n",
    "        return 'AGEREV'\n",
    "    elif col.startswith('DNAI_'):\n",
    "        return 'DNAI'\n",
    "    elif '_' in col:\n",
    "        return col.rsplit('_', 1)[0]\n",
    "    else:\n",
    "        return col\n",
    "\n",
    "# Regrouper colonnes par variable conceptuelle\n",
    "var_mapping = {}\n",
    "for col in X.columns:\n",
    "    prefix = get_prefix(col)\n",
    "    if prefix not in var_mapping:\n",
    "        var_mapping[prefix] = []\n",
    "    var_mapping[prefix].append(col)\n",
    "\n",
    "print(f\"\\n{'Variable conceptuelle':<15} {'Nb dummies':>12} {'Colonnes'}\")\n",
    "print(\"-\"*80)\n",
    "for var, cols in sorted(var_mapping.items()):\n",
    "    cols_str = ', '.join(cols[:3])\n",
    "    if len(cols) > 3:\n",
    "        cols_str += f\" ... (+{len(cols)-3})\"\n",
    "    print(f\"{var:<15} {len(cols):>12} {cols_str}\")\n",
    "\n",
    "# ============================================\n",
    "# 2. DÃ‰TAIL PAR VARIABLE : EFFECTIFS + TAUX TRANSFRONTALIER\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. MODALITÃ‰S PAR VARIABLE (effectifs + taux transfrontalier)\")\n",
    "print(\"=\"*80)\n",
    "print(\"â†’ Pour choisir la CATÃ‰GORIE DE RÃ‰FÃ‰RENCE du Probit\\n\")\n",
    "\n",
    "ref_suggestions = {}\n",
    "\n",
    "for var, cols in sorted(var_mapping.items()):\n",
    "    print(f\"\\n{'â”€'*60}\")\n",
    "    print(f\"ğŸ“Š {var} ({len(cols)} modalitÃ©s)\")\n",
    "    print(f\"{'â”€'*60}\")\n",
    "    \n",
    "    if var == 'AGEREV':\n",
    "        # Variable continue\n",
    "        print(f\"  Type: CONTINUE\")\n",
    "        print(f\"  Moyenne: {X['AGEREV'].mean():.1f} ans | Ã‰cart-type: {X['AGEREV'].std():.1f}\")\n",
    "        print(f\"  Min: {X['AGEREV'].min()} | Max: {X['AGEREV'].max()}\")\n",
    "        print(f\"  â†’ Pas de catÃ©gorie de rÃ©fÃ©rence (variable continue)\")\n",
    "        ref_suggestions[var] = None\n",
    "        continue\n",
    "    \n",
    "    print(f\"  {'ModalitÃ©':<20} {'Effectif':>12} {'%':>8} {'Taux transf.':>14} {'Suggestion'}\")\n",
    "    print(f\"  {'-'*70}\")\n",
    "    \n",
    "    modal_stats = []\n",
    "    for col in cols:\n",
    "        modalite = col.replace(var + '_', '')\n",
    "        effectif = X[col].sum()\n",
    "        pct = effectif / len(X) * 100\n",
    "        taux_transf = df[df[col] == 1]['Y'].mean() * 100 if effectif > 0 else 0\n",
    "        modal_stats.append({\n",
    "            'col': col,\n",
    "            'modalite': modalite,\n",
    "            'effectif': effectif,\n",
    "            'pct': pct,\n",
    "            'taux': taux_transf\n",
    "        })\n",
    "    \n",
    "    # Trier par effectif dÃ©croissant\n",
    "    modal_stats = sorted(modal_stats, key=lambda x: x['effectif'], reverse=True)\n",
    "    \n",
    "    # La plus frÃ©quente = suggestion de rÃ©fÃ©rence\n",
    "    ref_col = modal_stats[0]['col']\n",
    "    ref_suggestions[var] = ref_col\n",
    "    \n",
    "    for i, m in enumerate(modal_stats):\n",
    "        suggestion = \"â† REF (plus frÃ©quente)\" if i == 0 else \"\"\n",
    "        print(f\"  {m['modalite']:<20} {m['effectif']:>12,} {m['pct']:>7.1f}% {m['taux']:>13.1f}% {suggestion}\")\n",
    "\n",
    "# ============================================\n",
    "# 3. VIF SUR VARIABLES CONCEPTUELLES\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. VIF - MULTICOLINÃ‰ARITÃ‰ (sur 17 variables conceptuelles)\")\n",
    "print(\"=\"*80)\n",
    "print(\"MÃ©thode: Label encoding des catÃ©gorielles â†’ VIF\")\n",
    "print(\"Seuils : VIF < 5 âœ“ | 5-10 âš ï¸ | â‰¥10 ğŸ”´\\n\")\n",
    "\n",
    "# Reconstruire les variables conceptuelles en label encoding\n",
    "X_conceptual = pd.DataFrame()\n",
    "\n",
    "for var, cols in var_mapping.items():\n",
    "    if var == 'AGEREV':\n",
    "        X_conceptual['AGEREV'] = X['AGEREV']\n",
    "        # On n'inclut pas AGEREV_sq car colinÃ©aire par construction\n",
    "    else:\n",
    "        # Reconstruire la variable catÃ©gorielle\n",
    "        # Trouver quelle modalitÃ© = 1 pour chaque ligne\n",
    "        temp = X[cols].idxmax(axis=1)\n",
    "        # Encoder en numÃ©rique\n",
    "        X_conceptual[var] = pd.factorize(temp)[0]\n",
    "\n",
    "# Calculer VIF\n",
    "print(f\"Calcul VIF sur {len(X_conceptual.columns)} variables...\")\n",
    "\n",
    "vif_results = []\n",
    "for i, col in enumerate(X_conceptual.columns):\n",
    "    try:\n",
    "        vif = variance_inflation_factor(X_conceptual.values.astype(float), i)\n",
    "        vif_results.append({'Variable': col, 'VIF': vif})\n",
    "    except Exception as e:\n",
    "        vif_results.append({'Variable': col, 'VIF': np.nan})\n",
    "\n",
    "vif_df = pd.DataFrame(vif_results).sort_values('VIF', ascending=False)\n",
    "\n",
    "print(f\"\\n{'Variable':<15} {'VIF':>10} {'Statut'}\")\n",
    "print(\"-\"*40)\n",
    "for _, row in vif_df.iterrows():\n",
    "    vif = row['VIF']\n",
    "    if pd.isna(vif) or np.isinf(vif):\n",
    "        statut = \"âŒ Erreur\"\n",
    "        vif_str = \"âˆ\"\n",
    "    elif vif >= 10:\n",
    "        statut = \"ğŸ”´ SÃ©vÃ¨re\"\n",
    "        vif_str = f\"{vif:.2f}\"\n",
    "    elif vif >= 5:\n",
    "        statut = \"âš ï¸ ModÃ©rÃ©\"\n",
    "        vif_str = f\"{vif:.2f}\"\n",
    "    else:\n",
    "        statut = \"âœ“ OK\"\n",
    "        vif_str = f\"{vif:.2f}\"\n",
    "    print(f\"{row['Variable']:<15} {vif_str:>10} {statut}\")\n",
    "\n",
    "vif_clean = vif_df[~vif_df['VIF'].isna() & ~np.isinf(vif_df['VIF'])]['VIF']\n",
    "print(\"-\"*40)\n",
    "print(f\"VIF moyen : {vif_clean.mean():.2f} | VIF max : {vif_clean.max():.2f}\")\n",
    "\n",
    "if vif_clean.max() < 5:\n",
    "    print(\"\\nâœ… PAS DE MULTICOLINÃ‰ARITÃ‰ PROBLÃ‰MATIQUE\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ {(vif_clean >= 5).sum()} variable(s) avec VIF â‰¥ 5\")\n",
    "\n",
    "# ============================================\n",
    "# 4. CORRÃ‰LATIONS FORTES ENTRE VARIABLES CONCEPTUELLES\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. CORRÃ‰LATIONS FORTES (|Ï| > 0.4)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "corr = X_conceptual.corr(method='spearman')\n",
    "\n",
    "pairs = []\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(i+1, len(corr.columns)):\n",
    "        r = corr.iloc[i, j]\n",
    "        if abs(r) > 0.4:\n",
    "            pairs.append((corr.columns[i], corr.columns[j], r))\n",
    "\n",
    "if pairs:\n",
    "    print(f\"\\n{'Variable 1':<15} {'Variable 2':<15} {'Ï Spearman':>12}\")\n",
    "    print(\"-\"*45)\n",
    "    for v1, v2, r in sorted(pairs, key=lambda x: abs(x[2]), reverse=True):\n",
    "        print(f\"{v1:<15} {v2:<15} {r:>12.3f}\")\n",
    "else:\n",
    "    print(\"\\nâœ… Aucune corrÃ©lation |Ï| > 0.4\")\n",
    "\n",
    "# ============================================\n",
    "# 5. RÃ‰CAPITULATIF CATÃ‰GORIES DE RÃ‰FÃ‰RENCE\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"5. CATÃ‰GORIES DE RÃ‰FÃ‰RENCE SUGGÃ‰RÃ‰ES (pour Probit)\")\n",
    "print(\"=\"*80)\n",
    "print(\"CritÃ¨re: modalitÃ© la plus frÃ©quente (convention standard)\\n\")\n",
    "\n",
    "print(f\"{'Variable':<15} {'RÃ©fÃ©rence suggÃ©rÃ©e':<30} {'Justification'}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Labels lisibles\n",
    "labels = {\n",
    "    'GS_5': 'EmployÃ©s',\n",
    "    'EMPL_16': 'CDI/Fonctionnaire',\n",
    "    'INATC_1': 'FranÃ§ais',\n",
    "    'COUPLE_1': 'En couple',\n",
    "    'NENFR_0': '0 enfant',\n",
    "    'NA5_GU': 'Commerce/Services',\n",
    "    'DIPL_13': 'CAP/BEP',\n",
    "    'ETUD_2': 'Non Ã©tudiant',\n",
    "    'SANI_2': 'Salle de bain',\n",
    "    'SEXE_1': 'Homme',\n",
    "    'TP_1': 'Temps complet',\n",
    "    'DEPT_57': 'Moselle',\n",
    "    'STOCD_10.0': 'PropriÃ©taire',\n",
    "    'VOIT_2.0': '2 voitures',\n",
    "    'TYPL_1.0': 'Maison',\n",
    "    'DNAI_NEGRANDEST': 'NÃ© Grand Est'\n",
    "}\n",
    "\n",
    "for var, ref_col in ref_suggestions.items():\n",
    "    if ref_col is None:\n",
    "        print(f\"{var:<15} {'(continue)':<30} {'Pas de rÃ©fÃ©rence'}\")\n",
    "    else:\n",
    "        label = labels.get(ref_col, ref_col.replace(var + '_', ''))\n",
    "        effectif = X[ref_col].sum()\n",
    "        pct = effectif / len(X) * 100\n",
    "        print(f\"{var:<15} {label:<30} {pct:.1f}% des obs\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FIN DU DIAGNOSTIC\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dded8c2f",
   "metadata": {},
   "source": [
    "# SYNTHÃˆSE EXHAUSTIVE DES VARIABLES DU MODÃˆLE PROBIT SIMPLE\n",
    "\n",
    "## Projet INSEE - MobilitÃ© TransfrontaliÃ¨re Grand Est\n",
    "\n",
    "**Base de donnÃ©es** : 494,483 observations | Transfrontaliers : 44,264 (8.95%)\n",
    "\n",
    "---\n",
    "\n",
    "# 1. AGEREV â€” Ã‚ge en annÃ©es rÃ©volues\n",
    "\n",
    "**Source** : INDCVI (Fichier Individus)\n",
    "\n",
    "| PropriÃ©tÃ©             | Valeur |\n",
    "|-----------            |--------|\n",
    "| **Type**              | Continue |\n",
    "| **Description INSEE** | Ã‚ge en annÃ©es rÃ©volues dÃ©taillÃ© (Ã¢ge au dernier anniversaire) |\n",
    "| **Plage**             | 0 Ã  120 ans |\n",
    "| **Dans le modÃ¨le**    | 15-101 ans (actifs occupÃ©s uniquement) |\n",
    "\n",
    "**Statistiques dans la BDD** :\n",
    "- Moyenne : 41.5 ans\n",
    "- Ã‰cart-type : 12.5 ans\n",
    "- Min : 15 ans | Max : 101 ans\n",
    "\n",
    "**SpÃ©cification probit** : \n",
    "- `AGEREV` (effet linÃ©aire)\n",
    "- `AGEREV_sq` (effet quadratique) â†’ Effet en U inversÃ© confirmÃ© par Elastic Net\n",
    "\n",
    "**Pas de catÃ©gorie de rÃ©fÃ©rence** (variable continue)\n",
    "\n",
    "---\n",
    "\n",
    "# 2. COUPLE â€” DÃ©claration de vie en couple\n",
    "\n",
    "**Source** : INDCVI (Fichier Individus)\n",
    "\n",
    "| Code  | LibellÃ© INSEE                    | Effectif | % Base | Taux transf. |\n",
    "|------ |---------------                   |----------|--------|--------------|\n",
    "| **1** | A dÃ©clarÃ© vivre en couple        | 325,880  | 65.9%  | 9.7% |\n",
    "| 2     | A dÃ©clarÃ© ne pas vivre en couple | 168,603  | 34.1%  | 7.5% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `COUPLE_1` (En couple) â€” 65.9% des observations\n",
    "\n",
    "**Note** : Variable dÃ©clarative, pas de distinction mariÃ©/pacsÃ©/concubinage ici (voir STAT_CONJ si nÃ©cessaire)\n",
    "\n",
    "---\n",
    "\n",
    "# 3. DEPT â€” DÃ©partement du lieu de rÃ©sidence\n",
    "\n",
    "**Source** : INDCVI + MOBPRO\n",
    "\n",
    "| Code   | DÃ©partement        | Effectif | % Base | Taux transf. | InterprÃ©tation |\n",
    "|------  |-------------       |----------|--------|--------------|----------------|\n",
    "| **67** | Bas-Rhin           | 118,398  | 23.9%  | 4.6% | Strasbourg, Ã©loignÃ© frontiÃ¨re |\n",
    "| 57     | Moselle            | 98,869   | 20.0%  | **21.6%** | ProximitÃ© Luxembourg |\n",
    "| 68     | Haut-Rhin          | 73,587   | 14.9%  | **14.1%** | ProximitÃ© Suisse/Allemagne|\n",
    "| 54     | Meurthe-et-Moselle | 64,924   | 13.1%  | 9.7% | ProximitÃ© Luxembourg |\n",
    "| 51     | Marne              | 53,239   | 10.8%  | 0.1% | Ã‰loignÃ© des frontiÃ¨res |\n",
    "| 88     | Vosges             | 29,098   | 5.9%   | 0.2% | Relief montagneux |\n",
    "| 10     | Aube               | 27,234   | 5.5%   | 0.1% | Ã‰loignÃ© des frontiÃ¨res |\n",
    "| 55     | Meuse              | 14,885   | 3.0%   | 4.7% | Entre Metz et frontiÃ¨re |\n",
    "| 52     | Haute-Marne        | 14,249   | 2.9%   | 0.1% | Ã‰loignÃ© des frontiÃ¨res |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `DEPT_67` (Bas-Rhin) â€” 23.9% des observations\n",
    "\n",
    "**Attention** : Le diagnostic suggÃ¨re DEPT_67 (plus frÃ©quent), mais Ã©conomÃ©triquement on pourrait prÃ©fÃ©rer un dÃ©partement \"neutre\" Ã©loignÃ© des frontiÃ¨res (ex: DEPT_51 Marne) pour que tous les coefficients des dÃ©partements frontaliers soient positifs et comparables.\n",
    "\n",
    "## Choix final : alternative selectionnÃ©e pour DEPT\n",
    "Utiliser DEPT_51 (Marne) comme rÃ©fÃ©rence pour avoir tous les coefficients des dÃ©partements frontaliers en positif, ce qui facilite l'interprÃ©tation.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. DIPL â€” DiplÃ´me le plus Ã©levÃ©\n",
    "\n",
    "**Source** : INDCVI (Fichier Individus)\n",
    "\n",
    "| Code | LibellÃ© INSEE complet                       | Effectif | % Base | Taux transf. |\n",
    "|------|----------------------                       |----------|--------|--------------|\n",
    "| 01 | Pas de scolaritÃ© ou arrÃªt avant fin primaire        | 3,431  | 0.7%  | 5.4% |\n",
    "| 02 | Aucun diplÃ´me, scolaritÃ© fin primaire/avant collÃ¨ge | 10,348 | 2.1%  | 8.1% |\n",
    "| 03 | Aucun diplÃ´me, scolaritÃ© jusqu'Ã  fin collÃ¨ge ou +   | 26,638 | 5.4%  | 9.1% |\n",
    "| 11 | CEP (certificat d'Ã©tudes primaires)                 | 4,062  | 0.8%  | 12.0% |\n",
    "| 12 | BEPC, brevet Ã©lÃ©mentaire, DNB                       | 16,298 | 3.3%  | 8.1% |\n",
    "| **13** | **CAP, BEP ou diplÃ´me Ã©quivalent**              | 117,859|**23.8%**| 9.6% |\n",
    "| 14 | Bac gÃ©nÃ©ral/techno, brevet supÃ©rieur, DAEU          | 50,473 | 10.2% | 7.8% |\n",
    "| 15 | Bac pro, brevet professionnel/technicien            | 56,154 | 11.4% | 8.7% |\n",
    "| 16 | BTS, DUT, Deug, Deust (Bac+2)                       | 75,404 | 15.2% | 7.9% |\n",
    "| 17 | Licence, licence pro, maÃ®trise (Bac+3/4)            | 63,260 | 12.8% | 8.3% |\n",
    "| 18 | Master, DEA, DESS, grande Ã©cole (Bac+5)             | 65,128 | 13.2% | **10.7%** |\n",
    "| 19 | Doctorat de recherche (hors santÃ©)                  | 5,428  | 1.1%  | **11.2%** |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `DIPL_13` (CAP/BEP) â€” 23.8% des observations\n",
    "\n",
    "**InterprÃ©tation** : Les trÃ¨s diplÃ´mÃ©s (18, 19) et les CEP (11) ont les taux transfrontaliers les plus Ã©levÃ©s. L'effet diplÃ´me n'est pas linÃ©aire.\n",
    "\n",
    "---\n",
    "\n",
    "# 5. DNAI â€” DÃ©partement de naissance (recodÃ©)\n",
    "\n",
    "**Source** : INDCVI â€” Variable DNAI recodÃ©e en 3 modalitÃ©s\n",
    "\n",
    "| Code recodÃ©    | Description                        | Effectif | % Base | Taux transf. |\n",
    "|-------------   |-------------                       |----------|--------|--------------|\n",
    "| **NEGRANDEST** | NÃ© dans le Grand Est            | 360,009 | 72.8% | 8.1% |\n",
    "| NEAUTREFR      | NÃ© ailleurs en France           | 71,270 | 14.4% | 5.8% |\n",
    "| NEETRANGER     | NÃ© Ã  l'Ã©tranger (code 99 INSEE) | 63,204 | 12.8% | **17.5%** |\n",
    "\n",
    "**Variable INSEE originale** : \n",
    "- Codes 08, 10, 51, 52, 54, 55, 57, 67, 68, 88 â†’ NEGRANDEST\n",
    "- Autres codes franÃ§ais â†’ NEAUTREFR\n",
    "- Code 99 â†’ NEETRANGER\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `DNAI_NEGRANDEST` â€” 72.8% des observations\n",
    "\n",
    "**InterprÃ©tation Ã©conomique** : Les personnes nÃ©es Ã  l'Ã©tranger ont 2Ã— plus de chances d'Ãªtre transfrontaliers (rÃ©seaux, expÃ©rience internationale, moins d'ancrage territorial).\n",
    "\n",
    "---\n",
    "\n",
    "# 6. EMPL â€” Condition d'emploi\n",
    "\n",
    "**Source** : INDCVI + MOBPRO\n",
    "\n",
    "| Code | LibellÃ© INSEE                                 | Effectif | % Base | Taux transf. |\n",
    "|------|---------------                                |----------|--------|--------------|\n",
    "| 11 | Contrat d'apprentissage ou professionnalisation  | 14,172  | 2.9%    | 1.8% |\n",
    "| 12 | PlacÃ©s par agence d'intÃ©rim                      | 10,308  | 2.1%    | **10.8%** |\n",
    "| 13 | Emplois aidÃ©s (CUI, avenir, etc.)                | 2,437   | 0.5%    | 1.3% |\n",
    "| 14 | Stagiaires rÃ©munÃ©rÃ©s en entreprise               | 1,350   | 0.3%    | 9.3% |\n",
    "| 15 | Autres emplois Ã  durÃ©e limitÃ©e (CDD, saisonnier) | 40,025  | 8.1%    | 5.7% |\n",
    "| **16** | **CDI, titulaire fonction publique**         | 374,974 |**75.8%**| **10.4%** |\n",
    "| 21 | Non salariÃ©s : IndÃ©pendants                      | 29,943  | 6.1%    | 2.6% |\n",
    "| 22 | Non salariÃ©s : Employeurs                        | 20,770  | 4.2%    | 3.6% |\n",
    "| 23 | Non salariÃ©s : Aides familiaux                   | 504     | 0.1%    | 3.8% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `EMPL_16` (CDI/Fonctionnaire) â€” 75.8% des observations\n",
    "\n",
    "**InterprÃ©tation** : \n",
    "- Les CDI ont le taux transfrontalier le plus Ã©levÃ© (stabilitÃ© â†’ acceptation dÃ©placements)\n",
    "- L'intÃ©rim (12) aussi Ã©levÃ© car souvent transfrontalier (agences spÃ©cialisÃ©es Luxembourg)\n",
    "- Les indÃ©pendants (21) trÃ¨s faibles car activitÃ© ancrÃ©e localement\n",
    "\n",
    "---\n",
    "\n",
    "# 7. ETUD â€” Inscription dans un Ã©tablissement d'enseignement\n",
    "\n",
    "**Source** : INDCVI (Fichier Individus)\n",
    "\n",
    "| Code  | LibellÃ© INSEE         | Effectif | % Base | Taux transf. |\n",
    "|------ |---------------        |----------|--------|--------------|\n",
    "| 1     | Oui (inscrit)         | 25,247   | 5.1%   | 3.1% |\n",
    "| **2** | **Non (non inscrit)** | 469,236  |**94.9%**| 9.3% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `ETUD_2` (Non Ã©tudiant) â€” 94.9% des observations\n",
    "\n",
    "**Note** : Dans ta base, tu as filtrÃ© sur les actifs occupÃ©s, donc les \"Ã©tudiants\" ici sont des travailleurs-Ã©tudiants (alternance, formation continue).\n",
    "\n",
    "---\n",
    "\n",
    "# 8. GS â€” Groupe socioprofessionnel en 6 postes\n",
    "\n",
    "**Source** : INDCVI + MOBPRO\n",
    "\n",
    "| Code | LibellÃ© INSEE                               | Effectif | % Base | Taux transf. |\n",
    "|------|---------------                              |----------|--------|--------------|\n",
    "| 1    | Agriculteurs exploitants                    | 5,990   | 1.2%    | **0.4%** |\n",
    "| 2    | Artisans, commerÃ§ants, chefs d'entreprise   | 28,006  | 5.7%    | 3.2% |\n",
    "| 3    | Cadres et professions intellect. supÃ©rieures| 80,429  | 16.3%   | 9.8% |\n",
    "| 4    | Professions intermÃ©diaires                  | 131,258 | 26.5%   | 8.2% |\n",
    "|**5** | **EmployÃ©s**                                | 133,175 |**26.9%**| 7.8% |\n",
    "| 6    | Ouvriers                                    | 115,625 | 23.4%   | **12.3%** |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `GS_5` (EmployÃ©s) â€” 26.9% des observations\n",
    "\n",
    "**InterprÃ©tation Ã©conomique** :\n",
    "- **Ouvriers (6)** : Taux le plus Ã©levÃ© (12.3%) â†’ industrie transfrontaliÃ¨re (Luxembourg, Allemagne)\n",
    "- **Agriculteurs (1)** : Taux quasi nul â†’ activitÃ© terrienne par nature\n",
    "- **Cadres (3)** : Taux Ã©levÃ© â†’ diffÃ©rentiel salarial attractif Luxembourg/Suisse\n",
    "\n",
    "---\n",
    "\n",
    "# 9. INATC â€” Indicateur de nationalitÃ© condensÃ©\n",
    "\n",
    "**Source** : INDCVI + MOBPRO\n",
    "\n",
    "| Code  | LibellÃ© INSEE | Effectif | % Base | Taux transf. |\n",
    "|------ |---------------|----------|--------|--------------|\n",
    "| **1** | **FranÃ§ais**  | 458,904  |**92.8%**| 8.0% |\n",
    "| 2     | Ã‰trangers     | 35,579   | 7.2%   | **21.8%** |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `INATC_1` (FranÃ§ais) â€” 92.8% des observations\n",
    "\n",
    "**InterprÃ©tation** : Les Ã©trangers rÃ©sidant dans le Grand Est ont 2.7Ã— plus de chances d'Ãªtre transfrontaliers (proximitÃ© culturelle/linguistique avec pays voisin, rÃ©seaux, moins de contraintes administratives perÃ§ues).\n",
    "\n",
    "---\n",
    "\n",
    "# 10. NA5 â€” ActivitÃ© Ã©conomique regroupÃ©e en 5 postes\n",
    "\n",
    "**Source** : INDCVI + MOBPRO (Nomenclature d'ActivitÃ©s FranÃ§aise)\n",
    "\n",
    "| Code | LibellÃ© INSEE                                | Effectif | % Base | Taux transf. |\n",
    "|------|---------------                               |----------|--------|--------------|\n",
    "| AZ | Agriculture, sylviculture et pÃªche              | 11,077 | 2.2%     | **0.7%** |\n",
    "| BE | Industrie manufacturiÃ¨re, extractives et autres | 73,852 | 14.9%    | **12.9%** |\n",
    "| FZ | Construction                                    | 32,768 | 6.6%     | **12.0%** |\n",
    "| **GU** | **Commerce, transports et services divers** | 222,988 |**45.1%**| 11.4% |\n",
    "| OQ | Administration publique, enseignement, santÃ©    | 153,798 | 31.1%   | 3.5% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `NA5_GU` (Commerce/Services) â€” 45.1% des observations\n",
    "\n",
    "**InterprÃ©tation Ã©conomique** :\n",
    "- **OQ (Administration)** : Taux trÃ¨s faible (3.5%) â†’ emplois publics franÃ§ais par nature\n",
    "- **AZ (Agriculture)** : Quasi nul â†’ activitÃ© terrienne\n",
    "- **BE (Industrie)** et **FZ (Construction)** : TrÃ¨s Ã©levÃ©s â†’ secteurs transfrontaliers typiques\n",
    "\n",
    "---\n",
    "\n",
    "# 11. NENFR â€” Nombre d'enfants de la famille (regroupÃ©)\n",
    "\n",
    "**Source** : INDCVI (Fichier Individus)\n",
    "\n",
    "| Code  | LibellÃ© INSEE                 | Effectif | % Base    | Taux transf. |\n",
    "|------ |---------------                |----------|--------   |--------------|\n",
    "| 0     | 0 enfant (couple sans enfant) | 116,349  | 23.5%     | 9.3% |\n",
    "| **1** | **1 enfant**                  | 124,300  | **25.1%** | 9.3% |\n",
    "| 2     | 2 enfants                     | 107,206  | 21.7%     | 9.5% |\n",
    "| 3     | 3 enfants                     | 33,423   | 6.8%      | 8.4% |\n",
    "| 4     | 4 enfants ou plus             | 10,672   | 2.2%      | 8.4% |\n",
    "| Z     | Personne hors famille ou hors logement ordinaire | 102,533 | 20.7% | 7.8% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `NENFR_1` (1 enfant) â€” 25.1% des observations\n",
    "\n",
    "**Choix final** : `NENFR_0` (0 enfant) car plus interprÃ©table Ã©conomiquement.\n",
    "\n",
    "**Note** : La modalitÃ© \"Z\" correspond aux personnes vivant seules ou hors famille.\n",
    "\n",
    "---\n",
    "\n",
    "# 12. SANI â€” Installations sanitaires (France mÃ©tropolitaine)\n",
    "\n",
    "**Source** : INDCVI (Fichier Individus)\n",
    "\n",
    "| Code  | LibellÃ© INSEE                                | Effectif | % Base | Taux transf. |\n",
    "|------ |---------------                               |----------|--------|--------------|\n",
    "| 0     | Ni baignoire, ni douche                          | 650     | 0.1%  | 7.7% |\n",
    "| 1     | Baignoire ou douche hors piÃ¨ce rÃ©servÃ©e          | 15,297  | 3.1%  | **11.2%** |\n",
    "| **2** | **Salle(s) de bains (avec douche ou baignoire)** | 475,443 |**96.1%**| 8.9% |\n",
    "| X     | Hors logement ordinaire                          | 3,093   | 0.6%  | 0.5% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `SANI_2` (Salle de bains standard) â€” 96.1% des observations\n",
    "\n",
    "**InterprÃ©tation** : Variable proxy du niveau de confort/standing du logement. Peut capter des effets de richesse.\n",
    "\n",
    "---\n",
    "\n",
    "# 13. SEXE â€” Sexe\n",
    "\n",
    "**Source** : INDCVI + MOBPRO\n",
    "\n",
    "| Code   | LibellÃ© INSEE | Effectif | % Base | Taux transf. |\n",
    "|------ |--------------  |----------|--------|--------------|\n",
    "| **1** | **Hommes**     | 256,784  | **51.9%** | **10.5%** |\n",
    "| 2     | Femmes         | 237,699  | 48.1%      | 7.2% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `SEXE_1` (Homme) â€” 51.9% des observations\n",
    "\n",
    "**InterprÃ©tation Ã©conomique** : Les hommes ont 1.5Ã— plus de chances d'Ãªtre transfrontaliers. Effet Ã  explorer avec interactions (SEXE Ã— NENFR, SEXE Ã— EMPL) dans le modÃ¨le 2.\n",
    "\n",
    "---\n",
    "\n",
    "# 14. STOCD â€” Statut d'occupation dÃ©taillÃ© du logement\n",
    "\n",
    "**Source** : INDCVI + MOBPRO\n",
    "\n",
    "| Code   | LibellÃ© INSEE                       | Effectif | % Base | Taux transf. |\n",
    "|------  |---------------                      |--------- |--------|--------------|\n",
    "| 00     | Logement ordinaire inoccupÃ©         | â€” | â€” | â€” |\n",
    "| **10** | **PropriÃ©taire**                    | 302,583  |**61.2%**| **10.4%** |\n",
    "| 21     | Locataire logement vide non HLM     | 111,524  | 22.6%   | 8.3% |\n",
    "| 22     | Locataire logement vide HLM         | 59,162   | 12.0%   | 4.0% |\n",
    "| 23     | Locataire meublÃ© ou chambre d'hÃ´tel | 11,395   | 2.3%    | 6.4% |\n",
    "| 30     | LogÃ© gratuitement                   | 9,819    | 2.0%    | 5.3% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `STOCD_10` (PropriÃ©taire) â€” 61.2% des observations\n",
    "\n",
    "**Note** : Dans ta base, le code apparaÃ®t comme `STOCD_10.0` (float) â†’ Ã  vÃ©rifier/nettoyer.\n",
    "\n",
    "**InterprÃ©tation** : Les propriÃ©taires ont le taux le plus Ã©levÃ© (revenus â†’ mobilitÃ© acceptÃ©e). Les locataires HLM ont le taux le plus faible.\n",
    "\n",
    "---\n",
    "\n",
    "# 15. TP â€” Temps de travail\n",
    "\n",
    "**Source** : INDCVI + MOBPRO\n",
    "\n",
    "| Code | LibellÃ© INSEE   | Effectif | % Base    | Taux transf. |\n",
    "|------|---------------  |----------|--------   |--------------|\n",
    "|**1** |**Temps complet**| 411,499  | **83.2%** | 9.1% |\n",
    "| 2    | Temps partiel   | 82,984   | 16.8%     | 8.3% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `TP_1` (Temps complet) â€” 83.2% des observations\n",
    "\n",
    "**Note** : La modalitÃ© \"Z\" (Sans objet) a Ã©tÃ© exclue car tu travailles sur les actifs occupÃ©s.\n",
    "\n",
    "---\n",
    "\n",
    "# 16. TYPL â€” Type de logement\n",
    "\n",
    "**Source** : INDCVI + MOBPRO\n",
    "\n",
    "| Code | LibellÃ© INSEE                       | Effectif | % Base | Taux transf. |\n",
    "|------|---------------                      |----------|--------|--------------|\n",
    "| **1** | **Maison**                         | 293,723  |**59.4%**| **10.1%** |\n",
    "| 2     | Appartement                        | 198,316  | 40.1%   | 7.4% |\n",
    "| 3     | Logement-foyer                     | 1,543    | 0.3%    | 4.2% |\n",
    "| 4     | Chambre d'hÃ´tel                    | 288      | 0.1%    | 4.9% |\n",
    "| 5     | Habitation de fortune              | 278      | 0.1%    | 6.8% |\n",
    "| 6     | PiÃ¨ce indÃ©pendante (entrÃ©e propre) | 335      | 0.1%    | 3.9% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `TYPL_1` (Maison) â€” 59.4% des observations\n",
    "\n",
    "**Note** : Dans ta base, le code apparaÃ®t comme `TYPL_1.0` (float) â†’ Ã  vÃ©rifier/nettoyer.\n",
    "\n",
    "**InterprÃ©tation** : Les habitants de maisons sont plus souvent transfrontaliers (pÃ©riurbain/rural frontalier vs. centre-ville).\n",
    "\n",
    "---\n",
    "\n",
    "# 17. VOIT â€” Nombre de voitures du mÃ©nage\n",
    "\n",
    "**Source** : INDCVI + MOBPRO\n",
    "\n",
    "| Code | LibellÃ© INSEE           | Effectif | % Base | Taux transf. |\n",
    "|------|---------------          |----------|--------|--------------|\n",
    "| 0     | Aucune voiture         | 33,957   | 6.9%   | 4.2% |\n",
    "| 1     | Une seule voiture      | 176,994  | 35.8%  | 7.7% |\n",
    "| **2** | **Deux voitures**      | 217,963  |**44.1%**| 10.1% |\n",
    "| 3     | Trois voitures ou plus | 65,569   | 13.3%  | **11.2%** |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `VOIT_2` (2 voitures) â€” 44.1% des observations\n",
    "\n",
    "**Note** : Dans ta base, le code apparaÃ®t comme `VOIT_2.0` (float) â†’ Ã  vÃ©rifier/nettoyer.\n",
    "\n",
    "**InterprÃ©tation Ã©conomique** : Effet monotone croissant â†’ plus de voitures = plus de mobilitÃ© possible = plus de travail transfrontalier. Effet revenu + effet accÃ¨s.\n",
    "\n",
    "---\n",
    "\n",
    "# TABLEAU RÃ‰CAPITULATIF DES CATÃ‰GORIES DE RÃ‰FÃ‰RENCE\n",
    "\n",
    "| Variable | RÃ©fÃ©rence suggÃ©rÃ©e| LibellÃ©           | % Base | Justification |\n",
    "|----------|-------------------|---------          |--------|---------------|\n",
    "| AGEREV   | â€”                 | Continue          | â€”     | Pas de rÃ©fÃ©rence |\n",
    "| COUPLE   | `COUPLE_1`        | En couple         | 65.9% | Plus frÃ©quente |\n",
    "| DEPT     | `DEPT_51`         | Marne          | 10.8% |Choix arbitraire \"effet frontiÃ¨re\"\n",
    "| DIPL     | `DIPL_13`         | CAP/BEP           | 23.8% | Plus frÃ©quente |\n",
    "| DNAI     | `DNAI_NEGRANDEST` | NÃ© Grand Est      | 72.8% | Plus frÃ©quente |\n",
    "| EMPL     | `EMPL_16`         | CDI/Fonctionnaire | 75.8% | Plus frÃ©quente |\n",
    "| ETUD     | `ETUD_2`          | Non Ã©tudiant      | 94.9% | Plus frÃ©quente |\n",
    "| GS       | `GS_5`            | EmployÃ©s          | 26.9% | Plus frÃ©quente |\n",
    "| INATC    | `INATC_1`         | FranÃ§ais          | 92.8% | Plus frÃ©quente |\n",
    "| NA5      | `NA5_GU`          | Commerce/Services | 45.1% | Plus frÃ©quente |\n",
    "| NENFR    | `NENFR_0`         | 0 enfant     | 23.5% |Choix arbitraire \"effet parentalitÃ©\"\n",
    "| SANI     | `SANI_2`          | Salle de bains    | 96.1% | Plus frÃ©quente |\n",
    "| SEXE     | `SEXE_1`          | Homme             | 51.9% | Plus frÃ©quente |\n",
    "| STOCD    | `STOCD_10`        | PropriÃ©taire      | 61.2% | Plus frÃ©quente |\n",
    "| TP       | `TP_1`            | Temps complet     | 83.2% | Plus frÃ©quente |\n",
    "| TYPL     | `TYPL_1`          | Maison            | 59.4% | Plus frÃ©quente |\n",
    "| VOIT     | `VOIT_2`          | 1 voitures        | 35.8% | Choix arbitraire \"mÃ©diane\" |\n",
    "\n",
    "---\n",
    "\n",
    "# POINTS D'ATTENTION\n",
    "\n",
    "## Variable NENFR\n",
    "La modalitÃ© \"Z\" (hors famille) mÃ©lange :\n",
    "- Personnes vivant seules\n",
    "- Personnes en colocation hors famille\n",
    "- Personnes en communautÃ©\n",
    "\n",
    "Ã€ interprÃ©ter avec prudence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f817a95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PRÃ‰PARATION DE LA BASE PROBIT\n",
      "================================================================================\n",
      "\n",
      "âœ“ Base chargÃ©e : 494,483 observations Ã— 81 variables\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CATÃ‰GORIES DE RÃ‰FÃ‰RENCE SUPPRIMÃ‰ES\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Variable     RÃ©fÃ©rence supprimÃ©e  Justification\n",
      "----------------------------------------------------------------------\n",
      "GS           GS_5                 EmployÃ©s - plus frÃ©quent (26.9%)\n",
      "EMPL         EMPL_16              CDI/Titulaire - plus frÃ©quent (75.8%)\n",
      "INATC        INATC_1              FranÃ§ais - plus frÃ©quent (92.8%)\n",
      "COUPLE       COUPLE_1             En couple - plus frÃ©quent (65.9%)\n",
      "NENFR        NENFR_0              0 enfant - CHOIX (interprÃ©tation parentalitÃ©)\n",
      "NA5          NA5_GU               Commerce/Services - plus frÃ©quent (45.1%)\n",
      "DIPL         DIPL_13              CAP/BEP - plus frÃ©quent (23.8%)\n",
      "ETUD         ETUD_2               Non Ã©tudiant - plus frÃ©quent (94.9%)\n",
      "SANI         SANI_2               Salle de bain - plus frÃ©quent (96.1%)\n",
      "SEXE         SEXE_1               Homme - plus frÃ©quent (51.9%)\n",
      "TP           TP_1                 Temps complet - plus frÃ©quent (83.2%)\n",
      "DEPT         DEPT_51              Marne - CHOIX (dept intÃ©rieur, non-frontalier)\n",
      "STOCD        STOCD_10.0           PropriÃ©taire - plus frÃ©quent (61.2%)\n",
      "VOIT         VOIT_1.0             1 voiture - CHOIX (rÃ©fÃ©rence mÃ©diane)\n",
      "TYPL         TYPL_1.0             Maison - plus frÃ©quent (59.4%)\n",
      "DNAI         DNAI_NEGRANDEST      NÃ© Grand Est - plus frÃ©quent (72.8%)\n",
      "\n",
      "================================================================================\n",
      "STRUCTURE DE LA BASE PROBIT\n",
      "================================================================================\n",
      "\n",
      "âœ“ Dimensions finales : 494,483 observations Ã— 65 variables\n",
      "  (suppression de 16 catÃ©gories de rÃ©fÃ©rence)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RÃ‰CAPITULATIF PAR VARIABLE CONCEPTUELLE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Variable     ModalitÃ©s gardÃ©es                        K-1\n",
      "----------------------------------------------------------------------\n",
      "AGEREV       AGEREV, AGEREV_sq                        2\n",
      "GS           GS_1, GS_2, GS_3... (+2)                 5\n",
      "EMPL         EMPL_11, EMPL_12, EMPL_13... (+5)        8\n",
      "INATC        INATC_2                                  1\n",
      "COUPLE       COUPLE_2                                 1\n",
      "NENFR        NENFR_1, NENFR_2, NENFR_3... (+2)        5\n",
      "NA5          NA5_AZ, NA5_BE, NA5_FZ... (+1)           4\n",
      "DIPL         DIPL_1, DIPL_11, DIPL_12... (+8)         11\n",
      "ETUD         ETUD_1                                   1\n",
      "SANI         SANI_0, SANI_1, SANI_X                   3\n",
      "SEXE         SEXE_2                                   1\n",
      "TP           TP_2                                     1\n",
      "DEPT         DEPT_10, DEPT_52, DEPT_54... (+5)        8\n",
      "STOCD        STOCD_21.0, STOCD_22.0, STOCD_23.0... (+1) 4\n",
      "VOIT         VOIT_0.0, VOIT_2.0, VOIT_3.0             3\n",
      "TYPL         TYPL_2.0, TYPL_3.0, TYPL_4.0... (+2)     5\n",
      "DNAI         DNAI_NEAUTREFR, DNAI_NEETRANGER          2\n",
      "----------------------------------------------------------------------\n",
      "TOTAL                                                 65 + constante\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LISTE COMPLÃˆTE DES COLONNES (ordre alphabÃ©tique)\n",
      "--------------------------------------------------------------------------------\n",
      "   1. AGEREV\n",
      "   2. AGEREV_sq\n",
      "   3. COUPLE_2\n",
      "   4. DEPT_10\n",
      "   5. DEPT_52\n",
      "   6. DEPT_54\n",
      "   7. DEPT_55\n",
      "   8. DEPT_57\n",
      "   9. DEPT_67\n",
      "  10. DEPT_68\n",
      "  11. DEPT_88\n",
      "  12. DIPL_1\n",
      "  13. DIPL_11\n",
      "  14. DIPL_12\n",
      "  15. DIPL_14\n",
      "  16. DIPL_15\n",
      "  17. DIPL_16\n",
      "  18. DIPL_17\n",
      "  19. DIPL_18\n",
      "  20. DIPL_19\n",
      "  21. DIPL_2\n",
      "  22. DIPL_3\n",
      "  23. DNAI_NEAUTREFR\n",
      "  24. DNAI_NEETRANGER\n",
      "  25. EMPL_11\n",
      "  26. EMPL_12\n",
      "  27. EMPL_13\n",
      "  28. EMPL_14\n",
      "  29. EMPL_15\n",
      "  30. EMPL_21\n",
      "  31. EMPL_22\n",
      "  32. EMPL_23\n",
      "  33. ETUD_1\n",
      "  34. GS_1\n",
      "  35. GS_2\n",
      "  36. GS_3\n",
      "  37. GS_4\n",
      "  38. GS_6\n",
      "  39. INATC_2\n",
      "  40. NA5_AZ\n",
      "  41. NA5_BE\n",
      "  42. NA5_FZ\n",
      "  43. NA5_OQ\n",
      "  44. NENFR_1\n",
      "  45. NENFR_2\n",
      "  46. NENFR_3\n",
      "  47. NENFR_4\n",
      "  48. NENFR_Z\n",
      "  49. SANI_0\n",
      "  50. SANI_1\n",
      "  51. SANI_X\n",
      "  52. SEXE_2\n",
      "  53. STOCD_21.0\n",
      "  54. STOCD_22.0\n",
      "  55. STOCD_23.0\n",
      "  56. STOCD_30.0\n",
      "  57. TP_2\n",
      "  58. TYPL_2.0\n",
      "  59. TYPL_3.0\n",
      "  60. TYPL_4.0\n",
      "  61. TYPL_5.0\n",
      "  62. TYPL_6.0\n",
      "  63. VOIT_0.0\n",
      "  64. VOIT_2.0\n",
      "  65. VOIT_3.0\n",
      "\n",
      "================================================================================\n",
      "SAUVEGARDE\n",
      "================================================================================\n",
      "\n",
      "âœ“ Base sauvegardÃ©e : /Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready\n",
      "  â†’ 494,483 observations\n",
      "  â†’ 65 variables explicatives\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "APERÃ‡U (5 premiÃ¨res lignes)\n",
      "--------------------------------------------------------------------------------\n",
      "   AGEREV  AGEREV_sq  GS_1  GS_2  GS_3  GS_4  GS_6  EMPL_11  EMPL_12  EMPL_13  \\\n",
      "0      35       1225     0     0     0     0     1        0        0        0   \n",
      "1      40       1600     0     0     0     0     1        0        0        0   \n",
      "2      44       1936     0     0     0     0     1        0        0        0   \n",
      "3      62       3844     0     0     0     1     0        0        0        0   \n",
      "4      59       3481     1     0     0     0     0        0        0        0   \n",
      "\n",
      "   ...  VOIT_0.0  VOIT_2.0  VOIT_3.0  TYPL_2.0  TYPL_3.0  TYPL_4.0  TYPL_5.0  \\\n",
      "0  ...         0         0         0         0         0         0         0   \n",
      "1  ...         0         0         1         0         0         0         0   \n",
      "2  ...         0         0         1         0         0         0         0   \n",
      "3  ...         0         0         0         0         0         0         0   \n",
      "4  ...         0         1         0         0         0         0         0   \n",
      "\n",
      "   TYPL_6.0  DNAI_NEAUTREFR  DNAI_NEETRANGER  \n",
      "0         0               1                0  \n",
      "1         0               0                1  \n",
      "2         0               0                1  \n",
      "3         0               0                0  \n",
      "4         0               0                0  \n",
      "\n",
      "[5 rows x 65 columns]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VÃ‰RIFICATION MULTICOLINÃ‰ARITÃ‰\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "âœ“ Rang de la matrice X : 65\n",
      "âœ“ Nombre de colonnes   : 65\n",
      "\n",
      "âœ… Matrice de plein rang - pas de multicolinÃ©aritÃ© parfaite\n",
      "\n",
      "================================================================================\n",
      "PRÃ‰PARATION TERMINÃ‰E\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "PRÃ‰PARATION DE LA BASE PROBIT - BDD_PROBIT\n",
    "================================================================================\n",
    "CrÃ©ation d'une base prÃªte pour l'estimation probit en supprimant les catÃ©gories\n",
    "de rÃ©fÃ©rence pour chaque variable catÃ©gorielle (Ã©viter la multicolinÃ©aritÃ© parfaite).\n",
    "\n",
    "CatÃ©gories de rÃ©fÃ©rence retenues (17 variables conceptuelles) :\n",
    "--------------------------------------------------------------------------------\n",
    "Variable    | RÃ©fÃ©rence      | Justification\n",
    "--------------------------------------------------------------------------------\n",
    "AGEREV      | (continue)     | Variable continue + terme quadratique\n",
    "GS          | GS_5           | EmployÃ©s - modalitÃ© la plus frÃ©quente (26.9%)\n",
    "EMPL        | EMPL_16        | CDI/Titulaire - modalitÃ© la plus frÃ©quente (75.8%)\n",
    "INATC       | INATC_1        | FranÃ§ais - modalitÃ© la plus frÃ©quente (92.8%)\n",
    "COUPLE      | COUPLE_1       | En couple - modalitÃ© la plus frÃ©quente (65.9%)\n",
    "NENFR       | NENFR_0        | 0 enfant - CHOIX UTILISATEUR (interprÃ©tation parentalitÃ©)\n",
    "NA5         | NA5_GU         | Commerce/Services - modalitÃ© la plus frÃ©quente (45.1%)\n",
    "DIPL        | DIPL_13        | CAP/BEP - modalitÃ© la plus frÃ©quente (23.8%)\n",
    "ETUD        | ETUD_2         | Non Ã©tudiant - modalitÃ© la plus frÃ©quente (94.9%)\n",
    "SANI        | SANI_2         | Salle de bain standard - modalitÃ© la plus frÃ©quente (96.1%)\n",
    "SEXE        | SEXE_1         | Homme - modalitÃ© la plus frÃ©quente (51.9%)\n",
    "TP          | TP_1           | Temps complet - modalitÃ© la plus frÃ©quente (83.2%)\n",
    "DEPT        | DEPT_51        | Marne - CHOIX UTILISATEUR (dÃ©partement intÃ©rieur, \n",
    "            |                | coefficients = effet relatif Ã  un dept non-frontalier)\n",
    "STOCD       | STOCD_10.0     | PropriÃ©taire - modalitÃ© la plus frÃ©quente (61.2%)\n",
    "VOIT        | VOIT_1.0       | 1 voiture - CHOIX UTILISATEUR (rÃ©fÃ©rence mÃ©diane)\n",
    "TYPL        | TYPL_1.0       | Maison - modalitÃ© la plus frÃ©quente (59.4%)\n",
    "DNAI        | DNAI_NEGRANDEST| NÃ© Grand Est - modalitÃ© la plus frÃ©quente (72.8%)\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================================\n",
    "# CHARGEMENT DES DONNÃ‰ES\n",
    "# ============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"PRÃ‰PARATION DE LA BASE PROBIT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Charger X_final_clean\n",
    "X = pd.read_csv('/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/ML_READY/FINAL_AFTER_ARBITRAGES/X_final_clean.csv')\n",
    "print(f\"\\nâœ“ Base chargÃ©e : {X.shape[0]:,} observations Ã— {X.shape[1]} variables\")\n",
    "\n",
    "# ============================================================================\n",
    "# DÃ‰FINITION DES CATÃ‰GORIES DE RÃ‰FÃ‰RENCE Ã€ SUPPRIMER\n",
    "# ============================================================================\n",
    "references_a_supprimer = {\n",
    "    # Variable catÃ©gorielle : colonne de rÃ©fÃ©rence Ã  supprimer\n",
    "    'GS': 'GS_5',              # EmployÃ©s (26.9%)\n",
    "    'EMPL': 'EMPL_16',         # CDI/Titulaire (75.8%)\n",
    "    'INATC': 'INATC_1',        # FranÃ§ais (92.8%)\n",
    "    'COUPLE': 'COUPLE_1',      # En couple (65.9%)\n",
    "    'NENFR': 'NENFR_0',        # 0 enfant - CHOIX UTILISATEUR\n",
    "    'NA5': 'NA5_GU',           # Commerce/Services (45.1%)\n",
    "    'DIPL': 'DIPL_13',         # CAP/BEP (23.8%)\n",
    "    'ETUD': 'ETUD_2',          # Non Ã©tudiant (94.9%)\n",
    "    'SANI': 'SANI_2',          # Salle de bain standard (96.1%)\n",
    "    'SEXE': 'SEXE_1',          # Homme (51.9%)\n",
    "    'TP': 'TP_1',              # Temps complet (83.2%)\n",
    "    'DEPT': 'DEPT_51',         # Marne - CHOIX UTILISATEUR\n",
    "    'STOCD': 'STOCD_10.0',     # PropriÃ©taire (61.2%)\n",
    "    'VOIT': 'VOIT_1.0',        # 1 voiture - CHOIX UTILISATEUR\n",
    "    'TYPL': 'TYPL_1.0',        # Maison (59.4%)\n",
    "    'DNAI': 'DNAI_NEGRANDEST', # NÃ© Grand Est (72.8%)\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# SUPPRESSION DES CATÃ‰GORIES DE RÃ‰FÃ‰RENCE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"CATÃ‰GORIES DE RÃ‰FÃ‰RENCE SUPPRIMÃ‰ES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "colonnes_a_supprimer = list(references_a_supprimer.values())\n",
    "colonnes_presentes = [col for col in colonnes_a_supprimer if col in X.columns]\n",
    "colonnes_absentes = [col for col in colonnes_a_supprimer if col not in X.columns]\n",
    "\n",
    "if colonnes_absentes:\n",
    "    print(f\"\\nâš  Colonnes non trouvÃ©es : {colonnes_absentes}\")\n",
    "\n",
    "# CrÃ©er la base probit\n",
    "bdd_probit = X.drop(columns=colonnes_presentes)\n",
    "\n",
    "print(f\"\\n{'Variable':<12} {'RÃ©fÃ©rence supprimÃ©e':<20} {'Justification'}\")\n",
    "print(\"-\" * 70)\n",
    "justifications = {\n",
    "    'GS_5': 'EmployÃ©s - plus frÃ©quent (26.9%)',\n",
    "    'EMPL_16': 'CDI/Titulaire - plus frÃ©quent (75.8%)',\n",
    "    'INATC_1': 'FranÃ§ais - plus frÃ©quent (92.8%)',\n",
    "    'COUPLE_1': 'En couple - plus frÃ©quent (65.9%)',\n",
    "    'NENFR_0': '0 enfant - CHOIX (interprÃ©tation parentalitÃ©)',\n",
    "    'NA5_GU': 'Commerce/Services - plus frÃ©quent (45.1%)',\n",
    "    'DIPL_13': 'CAP/BEP - plus frÃ©quent (23.8%)',\n",
    "    'ETUD_2': 'Non Ã©tudiant - plus frÃ©quent (94.9%)',\n",
    "    'SANI_2': 'Salle de bain - plus frÃ©quent (96.1%)',\n",
    "    'SEXE_1': 'Homme - plus frÃ©quent (51.9%)',\n",
    "    'TP_1': 'Temps complet - plus frÃ©quent (83.2%)',\n",
    "    'DEPT_51': 'Marne - CHOIX (dept intÃ©rieur, non-frontalier)',\n",
    "    'STOCD_10.0': 'PropriÃ©taire - plus frÃ©quent (61.2%)',\n",
    "    'VOIT_1.0': '1 voiture - CHOIX (rÃ©fÃ©rence mÃ©diane)',\n",
    "    'TYPL_1.0': 'Maison - plus frÃ©quent (59.4%)',\n",
    "    'DNAI_NEGRANDEST': 'NÃ© Grand Est - plus frÃ©quent (72.8%)',\n",
    "}\n",
    "\n",
    "for var, ref in references_a_supprimer.items():\n",
    "    if ref in colonnes_presentes:\n",
    "        print(f\"{var:<12} {ref:<20} {justifications.get(ref, '')}\")\n",
    "\n",
    "# ============================================================================\n",
    "# VÃ‰RIFICATION DE LA STRUCTURE FINALE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STRUCTURE DE LA BASE PROBIT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nâœ“ Dimensions finales : {bdd_probit.shape[0]:,} observations Ã— {bdd_probit.shape[1]} variables\")\n",
    "print(f\"  (suppression de {len(colonnes_presentes)} catÃ©gories de rÃ©fÃ©rence)\")\n",
    "\n",
    "# Compter les modalitÃ©s par variable conceptuelle\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"RÃ‰CAPITULATIF PAR VARIABLE CONCEPTUELLE\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"\\n{'Variable':<12} {'ModalitÃ©s gardÃ©es':<40} {'K-1'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Dictionnaire pour regrouper les colonnes par variable\n",
    "variables_conceptuelles = {\n",
    "    'AGEREV': ['AGEREV', 'AGEREV_sq'],\n",
    "    'GS': [c for c in bdd_probit.columns if c.startswith('GS_')],\n",
    "    'EMPL': [c for c in bdd_probit.columns if c.startswith('EMPL_')],\n",
    "    'INATC': [c for c in bdd_probit.columns if c.startswith('INATC_')],\n",
    "    'COUPLE': [c for c in bdd_probit.columns if c.startswith('COUPLE_')],\n",
    "    'NENFR': [c for c in bdd_probit.columns if c.startswith('NENFR_')],\n",
    "    'NA5': [c for c in bdd_probit.columns if c.startswith('NA5_')],\n",
    "    'DIPL': [c for c in bdd_probit.columns if c.startswith('DIPL_')],\n",
    "    'ETUD': [c for c in bdd_probit.columns if c.startswith('ETUD_')],\n",
    "    'SANI': [c for c in bdd_probit.columns if c.startswith('SANI_')],\n",
    "    'SEXE': [c for c in bdd_probit.columns if c.startswith('SEXE_')],\n",
    "    'TP': [c for c in bdd_probit.columns if c.startswith('TP_')],\n",
    "    'DEPT': [c for c in bdd_probit.columns if c.startswith('DEPT_')],\n",
    "    'STOCD': [c for c in bdd_probit.columns if c.startswith('STOCD_')],\n",
    "    'VOIT': [c for c in bdd_probit.columns if c.startswith('VOIT_')],\n",
    "    'TYPL': [c for c in bdd_probit.columns if c.startswith('TYPL_')],\n",
    "    'DNAI': [c for c in bdd_probit.columns if c.startswith('DNAI_')],\n",
    "}\n",
    "\n",
    "total_params = 0\n",
    "for var, cols in variables_conceptuelles.items():\n",
    "    if cols:\n",
    "        n_cols = len(cols)\n",
    "        total_params += n_cols\n",
    "        cols_str = ', '.join(cols[:3])\n",
    "        if len(cols) > 3:\n",
    "            cols_str += f'... (+{len(cols)-3})'\n",
    "        print(f\"{var:<12} {cols_str:<40} {n_cols}\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'TOTAL':<12} {'':<40} {total_params} + constante\")\n",
    "\n",
    "# ============================================================================\n",
    "# LISTE COMPLÃˆTE DES COLONNES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"LISTE COMPLÃˆTE DES COLONNES (ordre alphabÃ©tique)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, col in enumerate(sorted(bdd_probit.columns), 1):\n",
    "    print(f\"  {i:2}. {col}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAUVEGARDE\n",
    "# ============================================================================\n",
    "import os\n",
    "\n",
    "out_dir = \"/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "out_file = os.path.join(out_dir, \"BDD_PROBIT.csv\")   # choisis le nom que tu veux\n",
    "bdd_probit.to_csv(out_file, index=False)\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAUVEGARDE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nâœ“ Base sauvegardÃ©e : {output_path}\")\n",
    "print(f\"  â†’ {bdd_probit.shape[0]:,} observations\")\n",
    "print(f\"  â†’ {bdd_probit.shape[1]} variables explicatives\")\n",
    "\n",
    "# ============================================================================\n",
    "# APERÃ‡U FINAL\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"APERÃ‡U (5 premiÃ¨res lignes)\")\n",
    "print(\"-\" * 80)\n",
    "print(bdd_probit.head())\n",
    "\n",
    "# ============================================================================\n",
    "# VÃ‰RIFICATION : RANG DE LA MATRICE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"VÃ‰RIFICATION MULTICOLINÃ‰ARITÃ‰\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# VÃ©rifier que la matrice est de plein rang\n",
    "rank = np.linalg.matrix_rank(bdd_probit.values)\n",
    "print(f\"\\nâœ“ Rang de la matrice X : {rank}\")\n",
    "print(f\"âœ“ Nombre de colonnes   : {bdd_probit.shape[1]}\")\n",
    "\n",
    "if rank == bdd_probit.shape[1]:\n",
    "    print(\"\\nâœ… Matrice de plein rang - pas de multicolinÃ©aritÃ© parfaite\")\n",
    "else:\n",
    "    print(f\"\\nâš  ATTENTION : DÃ©ficit de rang = {bdd_probit.shape[1] - rank}\")\n",
    "    print(\"  â†’ MulticolinÃ©aritÃ© parfaite dÃ©tectÃ©e\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PRÃ‰PARATION TERMINÃ‰E\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecdbd79",
   "metadata": {},
   "source": [
    "La BDD est prÃªt pour le lancement de l'analyse statistique..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910e1c7",
   "metadata": {},
   "source": [
    "# Estimation Ã©conomÃ©trique en modÃ¨le probit binaire : Les dÃ©terminants du travail transfrontalier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d92e4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations : 494,483\n",
      "Transfrontaliers : 44,264 (8.95%)\n",
      "Variables : 66 (dont constante)\n",
      "\n",
      "Estimation en cours...\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.229292\n",
      "         Iterations 10\n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        TRANSFRONTALIER   No. Observations:               494483\n",
      "Model:                         Probit   Df Residuals:                   494417\n",
      "Method:                           MLE   Df Model:                           65\n",
      "Date:                Wed, 07 Jan 2026   Pseudo R-squ.:                  0.2393\n",
      "Time:                        12:27:56   Log-Likelihood:            -1.1338e+05\n",
      "converged:                       True   LL-Null:                   -1.4905e+05\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const              -3.5740      0.063    -56.548      0.000      -3.698      -3.450\n",
      "AGEREV              0.0326      0.002     16.870      0.000       0.029       0.036\n",
      "AGEREV_sq          -0.0004   2.26e-05    -17.415      0.000      -0.000      -0.000\n",
      "GS_1               -0.1072      0.094     -1.143      0.253      -0.291       0.077\n",
      "GS_2               -0.3072      0.028    -11.083      0.000      -0.362      -0.253\n",
      "GS_3               -0.0843      0.011     -7.346      0.000      -0.107      -0.062\n",
      "GS_4               -0.0401      0.009     -4.490      0.000      -0.058      -0.023\n",
      "GS_6                0.0932      0.009      9.881      0.000       0.075       0.112\n",
      "EMPL_11            -0.5282      0.035    -15.222      0.000      -0.596      -0.460\n",
      "EMPL_12            -0.0775      0.019     -3.999      0.000      -0.115      -0.040\n",
      "EMPL_13            -0.7465      0.081     -9.271      0.000      -0.904      -0.589\n",
      "EMPL_14             0.4143      0.058      7.157      0.000       0.301       0.528\n",
      "EMPL_15            -0.1003      0.013     -7.820      0.000      -0.125      -0.075\n",
      "EMPL_21            -0.5691      0.023    -24.729      0.000      -0.614      -0.524\n",
      "EMPL_22            -0.4735      0.027    -17.681      0.000      -0.526      -0.421\n",
      "EMPL_23            -0.2226      0.122     -1.819      0.069      -0.462       0.017\n",
      "INATC_2             0.4950      0.014     36.372      0.000       0.468       0.522\n",
      "COUPLE_2            0.0219      0.010      2.286      0.022       0.003       0.041\n",
      "NENFR_1            -0.0710      0.009     -7.868      0.000      -0.089      -0.053\n",
      "NENFR_2            -0.0936      0.009     -9.958      0.000      -0.112      -0.075\n",
      "NENFR_3            -0.1877      0.014    -13.735      0.000      -0.214      -0.161\n",
      "NENFR_4            -0.2120      0.022     -9.671      0.000      -0.255      -0.169\n",
      "NENFR_Z             0.0819      0.013      6.306      0.000       0.056       0.107\n",
      "NA5_AZ             -0.9543      0.054    -17.694      0.000      -1.060      -0.849\n",
      "NA5_BE              0.0131      0.008      1.590      0.112      -0.003       0.029\n",
      "NA5_FZ             -0.0204      0.012     -1.749      0.080      -0.043       0.002\n",
      "NA5_OQ             -0.6602      0.008    -78.401      0.000      -0.677      -0.644\n",
      "DIPL_1             -0.5207      0.042    -12.282      0.000      -0.604      -0.438\n",
      "DIPL_11             0.1226      0.031      3.896      0.000       0.061       0.184\n",
      "DIPL_12            -0.0219      0.018     -1.198      0.231      -0.058       0.014\n",
      "DIPL_14            -0.0500      0.012     -4.326      0.000      -0.073      -0.027\n",
      "DIPL_15            -0.0354      0.011     -3.271      0.001      -0.057      -0.014\n",
      "DIPL_16            -0.0488      0.010     -4.691      0.000      -0.069      -0.028\n",
      "DIPL_17             0.0794      0.011      6.974      0.000       0.057       0.102\n",
      "DIPL_18             0.2216      0.012     18.205      0.000       0.198       0.245\n",
      "DIPL_19             0.2444      0.028      8.786      0.000       0.190       0.299\n",
      "DIPL_2             -0.2534      0.023    -11.233      0.000      -0.298      -0.209\n",
      "DIPL_3             -0.0963      0.014     -6.843      0.000      -0.124      -0.069\n",
      "ETUD_1             -0.3310      0.023    -14.379      0.000      -0.376      -0.286\n",
      "SANI_0             -0.0697      0.086     -0.808      0.419      -0.239       0.099\n",
      "SANI_1              0.0876      0.016      5.456      0.000       0.056       0.119\n",
      "SANI_X             -1.5565      0.108    -14.466      0.000      -1.767      -1.346\n",
      "SEXE_2             -0.1255      0.007    -18.133      0.000      -0.139      -0.112\n",
      "TP_2                0.1225      0.009     13.987      0.000       0.105       0.140\n",
      "DEPT_10             0.1043      0.072      1.439      0.150      -0.038       0.246\n",
      "DEPT_52             0.1197      0.089      1.338      0.181      -0.056       0.295\n",
      "DEPT_54             1.9401      0.048     40.066      0.000       1.845       2.035\n",
      "DEPT_55             1.5232      0.052     29.504      0.000       1.422       1.624\n",
      "DEPT_57             2.4367      0.048     50.648      0.000       2.342       2.531\n",
      "DEPT_67             1.4722      0.048     30.446      0.000       1.377       1.567\n",
      "DEPT_68             2.0908      0.048     43.321      0.000       1.996       2.185\n",
      "DEPT_88             0.2933      0.063      4.628      0.000       0.169       0.418\n",
      "STOCD_21.0         -0.0803      0.009     -9.088      0.000      -0.098      -0.063\n",
      "STOCD_22.0         -0.4938      0.013    -36.848      0.000      -0.520      -0.468\n",
      "STOCD_23.0         -0.2075      0.024     -8.809      0.000      -0.254      -0.161\n",
      "STOCD_30.0         -0.2839      0.025    -11.444      0.000      -0.333      -0.235\n",
      "VOIT_0.0           -0.3233      0.016    -20.511      0.000      -0.354      -0.292\n",
      "VOIT_2.0            0.1181      0.008     14.979      0.000       0.103       0.134\n",
      "VOIT_3.0            0.1665      0.010     16.427      0.000       0.147       0.186\n",
      "TYPL_2.0           -0.1659      0.008    -19.756      0.000      -0.182      -0.149\n",
      "TYPL_3.0           -0.4778      0.068     -6.989      0.000      -0.612      -0.344\n",
      "TYPL_4.0           -0.6174      0.152     -4.071      0.000      -0.915      -0.320\n",
      "TYPL_5.0           -0.1759      0.135     -1.303      0.193      -0.440       0.089\n",
      "TYPL_6.0           -0.6315      0.152     -4.165      0.000      -0.929      -0.334\n",
      "DNAI_NEAUTREFR     -0.0299      0.010     -3.016      0.003      -0.049      -0.010\n",
      "DNAI_NEETRANGER     0.3496      0.012     30.343      0.000       0.327       0.372\n",
      "===================================================================================\n",
      "\n",
      "============================================================\n",
      "EFFETS MARGINAUX (Ã  la moyenne)\n",
      "============================================================\n",
      "       Probit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:        TRANSFRONTALIER\n",
      "Method:                          dydx\n",
      "At:                              mean\n",
      "===================================================================================\n",
      "                     dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "AGEREV              0.0021      0.000     16.492      0.000       0.002       0.002\n",
      "AGEREV_sq       -2.476e-05   1.46e-06    -16.997      0.000   -2.76e-05   -2.19e-05\n",
      "GS_1               -0.0068      0.006     -1.144      0.252      -0.018       0.005\n",
      "GS_2               -0.0193      0.002    -10.975      0.000      -0.023      -0.016\n",
      "GS_3               -0.0053      0.001     -7.308      0.000      -0.007      -0.004\n",
      "GS_4               -0.0025      0.001     -4.479      0.000      -0.004      -0.001\n",
      "GS_6                0.0059      0.001      9.814      0.000       0.005       0.007\n",
      "EMPL_11            -0.0333      0.002    -15.019      0.000      -0.038      -0.029\n",
      "EMPL_12            -0.0049      0.001     -3.993      0.000      -0.007      -0.002\n",
      "EMPL_13            -0.0470      0.005     -9.233      0.000      -0.057      -0.037\n",
      "EMPL_14             0.0261      0.004      7.132      0.000       0.019       0.033\n",
      "EMPL_15            -0.0063      0.001     -7.780      0.000      -0.008      -0.005\n",
      "EMPL_21            -0.0358      0.002    -23.635      0.000      -0.039      -0.033\n",
      "EMPL_22            -0.0298      0.002    -17.246      0.000      -0.033      -0.026\n",
      "EMPL_23            -0.0140      0.008     -1.819      0.069      -0.029       0.001\n",
      "INATC_2             0.0312      0.001     32.705      0.000       0.029       0.033\n",
      "COUPLE_2            0.0014      0.001      2.285      0.022       0.000       0.003\n",
      "NENFR_1            -0.0045      0.001     -7.829      0.000      -0.006      -0.003\n",
      "NENFR_2            -0.0059      0.001     -9.877      0.000      -0.007      -0.005\n",
      "NENFR_3            -0.0118      0.001    -13.524      0.000      -0.014      -0.010\n",
      "NENFR_4            -0.0134      0.001     -9.594      0.000      -0.016      -0.011\n",
      "NENFR_Z             0.0052      0.001      6.283      0.000       0.004       0.007\n",
      "NA5_AZ             -0.0601      0.003    -17.489      0.000      -0.067      -0.053\n",
      "NA5_BE              0.0008      0.001      1.590      0.112      -0.000       0.002\n",
      "NA5_FZ             -0.0013      0.001     -1.749      0.080      -0.003       0.000\n",
      "NA5_OQ             -0.0416      0.001    -55.978      0.000      -0.043      -0.040\n",
      "DIPL_1             -0.0328      0.003    -12.127      0.000      -0.038      -0.027\n",
      "DIPL_11             0.0077      0.002      3.890      0.000       0.004       0.012\n",
      "DIPL_12            -0.0014      0.001     -1.198      0.231      -0.004       0.001\n",
      "DIPL_14            -0.0031      0.001     -4.319      0.000      -0.005      -0.002\n",
      "DIPL_15            -0.0022      0.001     -3.269      0.001      -0.004      -0.001\n",
      "DIPL_16            -0.0031      0.001     -4.682      0.000      -0.004      -0.002\n",
      "DIPL_17             0.0050      0.001      6.948      0.000       0.004       0.006\n",
      "DIPL_18             0.0140      0.001     17.728      0.000       0.012       0.015\n",
      "DIPL_19             0.0154      0.002      8.732      0.000       0.012       0.019\n",
      "DIPL_2             -0.0160      0.001    -11.120      0.000      -0.019      -0.013\n",
      "DIPL_3             -0.0061      0.001     -6.815      0.000      -0.008      -0.004\n",
      "ETUD_1             -0.0208      0.001    -14.168      0.000      -0.024      -0.018\n",
      "SANI_0             -0.0044      0.005     -0.808      0.419      -0.015       0.006\n",
      "SANI_1              0.0055      0.001      5.443      0.000       0.004       0.008\n",
      "SANI_X             -0.0980      0.007    -14.394      0.000      -0.111      -0.085\n",
      "SEXE_2             -0.0079      0.000    -17.672      0.000      -0.009      -0.007\n",
      "TP_2                0.0077      0.001     13.786      0.000       0.007       0.009\n",
      "DEPT_10             0.0066      0.005      1.443      0.149      -0.002       0.015\n",
      "DEPT_52             0.0075      0.006      1.341      0.180      -0.003       0.019\n",
      "DEPT_54             0.1222      0.002     52.907      0.000       0.118       0.127\n",
      "DEPT_55             0.0959      0.003     36.158      0.000       0.091       0.101\n",
      "DEPT_57             0.1535      0.002     67.803      0.000       0.149       0.158\n",
      "DEPT_67             0.0927      0.002     38.478      0.000       0.088       0.097\n",
      "DEPT_68             0.1317      0.002     57.684      0.000       0.127       0.136\n",
      "DEPT_88             0.0185      0.004      4.714      0.000       0.011       0.026\n",
      "STOCD_21.0         -0.0051      0.001     -9.024      0.000      -0.006      -0.004\n",
      "STOCD_22.0         -0.0311      0.001    -33.522      0.000      -0.033      -0.029\n",
      "STOCD_23.0         -0.0131      0.001     -8.748      0.000      -0.016      -0.010\n",
      "STOCD_30.0         -0.0179      0.002    -11.326      0.000      -0.021      -0.015\n",
      "VOIT_0.0           -0.0204      0.001    -19.901      0.000      -0.022      -0.018\n",
      "VOIT_2.0            0.0074      0.001     14.716      0.000       0.006       0.008\n",
      "VOIT_3.0            0.0105      0.001     16.081      0.000       0.009       0.012\n",
      "TYPL_2.0           -0.0104      0.001    -19.121      0.000      -0.012      -0.009\n",
      "TYPL_3.0           -0.0301      0.004     -6.961      0.000      -0.039      -0.022\n",
      "TYPL_4.0           -0.0389      0.010     -4.066      0.000      -0.058      -0.020\n",
      "TYPL_5.0           -0.0111      0.009     -1.303      0.193      -0.028       0.006\n",
      "TYPL_6.0           -0.0398      0.010     -4.160      0.000      -0.059      -0.021\n",
      "DNAI_NEAUTREFR     -0.0019      0.001     -3.015      0.003      -0.003      -0.001\n",
      "DNAI_NEETRANGER     0.0220      0.001     28.206      0.000       0.020       0.024\n",
      "===================================================================================\n",
      "\n",
      "âœ“ RÃ©sultats sauvegardÃ©s : probit_model1_summary.txt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "MODÃˆLE 1 : PROBIT BINAIRE - DÃ‰TERMINANTS DU TRAVAIL TRANSFRONTALIER\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# ============================================================================\n",
    "# CHARGEMENT\n",
    "# ============================================================================\n",
    "path = '/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready/'\n",
    "X = pd.read_csv(path + 'BDD_PROBIT.csv')\n",
    "y = pd.read_csv(path + 'y_final.csv')['TRANSFRONTALIER']\n",
    "\n",
    "# Ajouter constante\n",
    "X_const = sm.add_constant(X)\n",
    "\n",
    "print(f\"Observations : {len(y):,}\")\n",
    "print(f\"Transfrontaliers : {y.sum():,} ({y.mean()*100:.2f}%)\")\n",
    "print(f\"Variables : {X_const.shape[1]} (dont constante)\")\n",
    "\n",
    "# ============================================================================\n",
    "# ESTIMATION PROBIT\n",
    "# ============================================================================\n",
    "print(\"\\nEstimation en cours...\")\n",
    "\n",
    "probit = sm.Probit(y, X_const)\n",
    "result = probit.fit(disp=1, maxiter=100)\n",
    "\n",
    "# ============================================================================\n",
    "# RÃ‰SULTATS\n",
    "# ============================================================================\n",
    "print(result.summary())\n",
    "\n",
    "# ============================================================================\n",
    "# EFFETS MARGINAUX (Ã  la moyenne)\n",
    "# ============================================================================\n",
    "marginal_effects = result.get_margeff(at='mean')\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EFFETS MARGINAUX (Ã  la moyenne)\")\n",
    "print(\"=\"*60)\n",
    "print(marginal_effects.summary())\n",
    "\n",
    "# ============================================================================\n",
    "# SAUVEGARDE\n",
    "# ============================================================================\n",
    "with open(path + 'probit_model1_summary.txt', 'w') as f:\n",
    "    f.write(result.summary().as_text())\n",
    "    f.write(\"\\n\\n\" + \"=\"*60 + \"\\n\")\n",
    "    f.write(\"EFFETS MARGINAUX\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\")\n",
    "    f.write(marginal_effects.summary().as_text())\n",
    "\n",
    "print(f\"\\nâœ“ RÃ©sultats sauvegardÃ©s : probit_model1_summary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7e7f0b",
   "metadata": {},
   "source": [
    "## RÃ©sultats prÃ©liminaires du modÃ¨le probit\n",
    "\n",
    "### Convention de lecture\n",
    "\n",
    "Les rÃ©sultats sont prÃ©sentÃ©s sous deux formes complÃ©mentaires :\n",
    "\n",
    "1. **Coefficient probit** : paramÃ¨tre estimÃ© du modÃ¨le, dont le signe indique la direction de l'effet mais dont l'amplitude n'est pas directement interprÃ©table.\n",
    "\n",
    "2. **Effet marginal (pp)** : variation de la probabilitÃ© d'Ãªtre transfrontalier en points de pourcentage, calculÃ© Ã  la moyenne des variables. *Exemple : +5 pp signifie que la probabilitÃ© passe de 8,95% Ã  13,95%.*\n",
    "\n",
    "La catÃ©gorie de rÃ©fÃ©rence pour les variables dÃ©partementales est la Marne (DEPT_51), dÃ©partement non frontalier.\n",
    "\n",
    "### Classification des variables selon le risque d'endogÃ©nÃ©itÃ©\n",
    "\n",
    "| Statut | InterprÃ©tation | Variables concernÃ©es |\n",
    "|--------|----------------|----------------------|\n",
    "| **ExogÃ¨ne** | Relation causale plausible | DÃ©partement, Ã¢ge, sexe, nationalitÃ©, lieu de naissance, diplÃ´me |\n",
    "| **Probablement exogÃ¨ne** | CausalitÃ© vraisemblable | Nombre d'enfants, secteur d'activitÃ©, catÃ©gorie socioprofessionnelle |\n",
    "| **Ambigu** | CausalitÃ© incertaine | Type de contrat, temps de travail |\n",
    "| **Potentiellement endogÃ¨ne** | CausalitÃ© inverse possible | Statut d'occupation, nombre de voitures, type de logement |\n",
    "\n",
    "Cette classification guide l'interprÃ©tation : seules les variables exogÃ¨nes autorisent une lecture causale. Les variables potentiellement endogÃ¨nes sont incluses comme contrÃ´les mais leurs coefficients ne doivent pas Ãªtre interprÃ©tÃ©s causalement.\n",
    "\n",
    "---\n",
    "\n",
    "### QualitÃ© globale de l'estimation\n",
    "\n",
    "Le modÃ¨le converge en 10 itÃ©rations sur 494 483 observations (44 264 transfrontaliers, soit 8,95%). Le pseudo-RÂ² de McFadden s'Ã©tablit Ã  **0,239**, valeur satisfaisante pour un modÃ¨le de choix discret sur donnÃ©es individuelles. Le test du ratio de vraisemblance rejette la nullitÃ© jointe des coefficients (Ï‡Â² = 71 340, p < 0,001). Sur 65 variables, 56 sont significatives au seuil de 1%.\n",
    "\n",
    "---\n",
    "\n",
    "### Patterns observÃ©s\n",
    "\n",
    "Les coefficients estimÃ©s rÃ©vÃ¨lent plusieurs rÃ©gularitÃ©s cohÃ©rentes avec la littÃ©rature et les attentes thÃ©oriques :\n",
    "\n",
    "**Gradient gÃ©ographique** : Les dÃ©partements frontaliers affichent les effets les plus forts du modÃ¨le. La Moselle, le Haut-Rhin et la Meurthe-et-Moselle prÃ©sentent des effets marginaux de +12 Ã  +15 pp, reflÃ©tant la proximitÃ© des bassins d'emploi luxembourgeois, suisse et allemand.\n",
    "\n",
    "**Profil dÃ©mographique** : L'Ã¢ge suit une forme quadratique suggÃ©rant un pic vers 40 ans. Les femmes prÃ©sentent une probabilitÃ© infÃ©rieure (coefficient nÃ©gatif significatif). La prÃ©sence d'enfants exerce un effet nÃ©gatif croissant avec leur nombre.\n",
    "\n",
    "**Avantage des rÃ©seaux transnationaux** : La nationalitÃ© Ã©trangÃ¨re et la naissance Ã  l'Ã©tranger sont positivement associÃ©es au travail frontalier, possiblement via les compÃ©tences linguistiques et les rÃ©seaux professionnels.\n",
    "\n",
    "**Structure professionnelle** : Les ouvriers en CDI sont favorisÃ©s, tandis que les indÃ©pendants, le secteur public et l'agriculture sont fortement exclus. Le travail frontalier apparaÃ®t comme un phÃ©nomÃ¨ne essentiellement salariÃ©.\n",
    "\n",
    "**Capital humain** : La relation avec le diplÃ´me est non monotone, avec des probabilitÃ©s Ã©levÃ©es aux deux extrÃ©mitÃ©s (CAP-BEP d'un cÃ´tÃ©, master-doctorat de l'autre) et plus faibles pour les diplÃ´mes intermÃ©diaires.\n",
    "\n",
    "**Associations avec le logement et la motorisation** : Des corrÃ©lations significatives sont observÃ©es (propriÃ©taires et multi-motorisÃ©s plus souvent transfrontaliers), mais le sens de la causalitÃ© reste indÃ©terminÃ© Ã  ce stade.\n",
    "\n",
    "---\n",
    "\n",
    "### Pourquoi l'infÃ©rence reste provisoire\n",
    "\n",
    "Ces rÃ©gularitÃ©s statistiques ne permettent pas encore de conclusions causales. Plusieurs questions mÃ©thodologiques doivent Ãªtre tranchÃ©es par des tests de robustesse :\n",
    "\n",
    "- **SpÃ©cification fonctionnelle** : la forme quadratique de l'Ã¢ge est-elle optimale ?\n",
    "- **QualitÃ© de l'ajustement** : les tests classiques (Hosmer-Lemeshow, Link Test) valident-ils le modÃ¨le ?\n",
    "- **Ã‰quivalence Probit/Logit** : les conclusions sont-elles robustes au choix du modÃ¨le ?\n",
    "- **SensibilitÃ© Ã  l'endogÃ©nÃ©itÃ©** : les coefficients clÃ©s sont-ils stables aprÃ¨s exclusion des variables potentiellement endogÃ¨nes ?\n",
    "- **HÃ©tÃ©rogÃ©nÃ©itÃ©** : la structure est-elle homogÃ¨ne par sexe, Ã¢ge, dÃ©partement ?\n",
    "- **Observations atypiques** : existe-t-il des rÃ©sidus extrÃªmes influenÃ§ant les rÃ©sultats ?\n",
    "\n",
    "L'interprÃ©tation Ã©conomique dÃ©taillÃ©e et les conclusions causales seront prÃ©sentÃ©es aprÃ¨s validation de ces diagnostics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2122eac4",
   "metadata": {},
   "source": [
    "# Tests de Robustesse â€“ ModÃ¨le Probit Transfrontalier\n",
    "\n",
    "## Tests rÃ©alisÃ©s\n",
    "\n",
    "| #   | Test                             | Objectif                                    | CritÃ¨re de validation                 |\n",
    "|-----|----------------------------------|---------------------------------------------|---------------------------------------|\n",
    "| 1   | Probit de base                   | VÃ©rifier convergence et qualitÃ© globale     | Convergence, Pseudo RÂ², LR test p<0.05|\n",
    "| 2   | Link Test (Pregibon)             | DÃ©tecter erreur de spÃ©cification            | p(_hatsq) > 0.05                      |\n",
    "| 3   | Hosmer-Lemeshow                  | Tester l'ajustement du modÃ¨le               | p > 0.05                              |\n",
    "| 4   | Probit vs Logit                  | VÃ©rifier robustesse au choix du lien        | Corr. effets marginaux > 0.99         |\n",
    "| 5   | Exclusion variables endogÃ¨nes    | SensibilitÃ© Ã  VOIT, STOCD, TYPL, SANI       | Variation coefficients clÃ©s < 20%     |\n",
    "| 6   | Sous-Ã©chantillons                | StabilitÃ© selon groupes                     | CohÃ©rence des Pseudo RÂ²               |\n",
    "| 7   | SensibilitÃ©                      | Influence des observations extrÃªmes         | StabilitÃ© aprÃ¨s exclusion             |\n",
    "| 8   | Forme fonctionnelle Ã¢ge          | Valider la spÃ©cification quadratique        | Test LR quad vs lin, AIC/BIC          |\n",
    "\n",
    "## Sous-Ã©chantillons analysÃ©s (Test 6)\n",
    "\n",
    "| Dimension   | Groupes comparÃ©s                      |\n",
    "|-------------|---------------------------------------|\n",
    "| GÃ©ographie  | DÃ©partements frontaliers vs intÃ©rieurs|\n",
    "| Genre       | Hommes vs Femmes                      |\n",
    "| Ã‚ge         | < 35 ans vs â‰¥ 35 ans                  |\n",
    "\n",
    "## Output\n",
    "\n",
    "â†’ `rapport_robustesse.txt` dans `/Probit_Ready/Robustesse/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f989c1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TESTS DE ROBUSTESSE - PROBIT TRANSFRONTALIER\n",
      "================================================================================\n",
      "================================================================================\n",
      "CHARGEMENT DES DONNÃ‰ES\n",
      "================================================================================\n",
      "\n",
      "âœ“ X chargÃ© : 494,483 obs Ã— 65 variables\n",
      "âœ“ Y chargÃ© : 494,483 observations\n",
      "  â†’ Colonne utilisÃ©e : 'TRANSFRONTALIER'\n",
      "\n",
      "âœ“ Variable dÃ©pendante :\n",
      "  â†’ Transfrontaliers (Y=1) : 44,264 (8.95%)\n",
      "  â†’ Non-transfrontaliers   : 450,219 (91.05%)\n",
      "\n",
      "âœ“ Constante ajoutÃ©e : 66 variables (dont intercept)\n",
      "\n",
      "================================================================================\n",
      "TEST 1 : MODÃˆLE PROBIT DE BASE\n",
      "================================================================================\n",
      "\n",
      "âœ“ Convergence : Oui\n",
      "âœ“ ItÃ©rations  : 10\n",
      "âœ“ Log-L       : -113,380.76\n",
      "âœ“ Pseudo RÂ²   : 0.2393\n",
      "âœ“ AIC         : 226,893.52\n",
      "âœ“ BIC         : 227,626.87\n",
      "âœ“ LR test p   : 0.00e+00\n",
      "\n",
      "--- Coefficients clÃ©s ---\n",
      "  DEPT_57      :   2.4367 (SE=0.0481) ***\n",
      "  DEPT_68      :   2.0908 (SE=0.0483) ***\n",
      "  DEPT_54      :   1.9401 (SE=0.0484) ***\n",
      "  DEPT_67      :   1.4722 (SE=0.0484) ***\n",
      "  SEXE_2       :  -0.1255 (SE=0.0069) ***\n",
      "  AGEREV       :   0.0326 (SE=0.0019) ***\n",
      "  AGEREV_sq    :  -0.0004 (SE=0.0000) ***\n",
      "\n",
      "================================================================================\n",
      "TEST 2 : LINK TEST (PREGIBON)\n",
      "================================================================================\n",
      "\n",
      "_hat   coef : 1.1247 (p=0.0000)\n",
      "_hatsq coef : 0.0509 (p=0.0000)\n",
      "\n",
      "âš ï¸ H0 rejetÃ©e : Possible erreur de spÃ©cification\n",
      "\n",
      "================================================================================\n",
      "TEST 3 : HOSMER-LEMESHOW\n",
      "================================================================================\n",
      "\n",
      "Statistique HL : 304.51\n",
      "DegrÃ©s libertÃ© : 8\n",
      "P-value        : 0.0000\n",
      "\n",
      "âš ï¸ Ajustement insuffisant (p < 0.05)\n",
      "\n",
      "================================================================================\n",
      "TEST 4 : PROBIT VS LOGIT\n",
      "================================================================================\n",
      "\n",
      "CritÃ¨re               Probit        Logit\n",
      "---------------------------------------------\n",
      "Log-L            -113,380.76  -113,285.43\n",
      "Pseudo RÂ²             0.2393       0.2399\n",
      "AIC               226,893.52   226,702.86\n",
      "BIC               227,626.87   227,436.20\n",
      "\n",
      "Ratio moyen Logit/Probit : 2.045 (thÃ©orique ~1.6)\n",
      "CorrÃ©lation effets marginaux : 0.9953\n",
      "\n",
      "âœ… Probit et Logit quasi-Ã©quivalents\n",
      "\n",
      "================================================================================\n",
      "TEST 5 : ROBUSTESSE ENDOGÃ‰NÃ‰ITÃ‰\n",
      "================================================================================\n",
      "\n",
      "Variables exclues : 15\n",
      "  - VOIT_0.0\n",
      "  - VOIT_2.0\n",
      "  - VOIT_3.0\n",
      "  - STOCD_21.0\n",
      "  - STOCD_22.0\n",
      "  - STOCD_23.0\n",
      "  - STOCD_30.0\n",
      "  - TYPL_2.0\n",
      "  - TYPL_3.0\n",
      "  - TYPL_4.0\n",
      "  ... et 5 autres\n",
      "\n",
      "ModÃ¨le              Log-L    Pseudo RÂ²    Nb vars\n",
      "--------------------------------------------------\n",
      "Complet       -113,380.76       0.2393         66\n",
      "RÃ©duit        -116,152.93       0.2207         51\n",
      "\n",
      "--- StabilitÃ© des coefficients clÃ©s ---\n",
      "  DEPT_57      :   2.4367 â†’   2.4550 (+0.8%) âœ“\n",
      "  DEPT_68      :   2.0908 â†’   2.1199 (+1.4%) âœ“\n",
      "  SEXE_2       :  -0.1255 â†’  -0.1200 (+4.4%) âœ“\n",
      "  AGEREV       :   0.0326 â†’   0.0322 (-1.4%) âœ“\n",
      "\n",
      "âœ… Coefficients stables aprÃ¨s exclusion\n",
      "\n",
      "================================================================================\n",
      "TEST 6 : SOUS-Ã‰CHANTILLONS\n",
      "================================================================================\n",
      "\n",
      "--- DÃ©partements frontaliers vs intÃ©rieurs ---\n",
      "  Frontaliers  : Estimation Ã©chouÃ©e\n",
      "  IntÃ©rieurs   : Estimation Ã©chouÃ©e\n",
      "\n",
      "--- Par sexe ---\n",
      "  Hommes       : n=256,784, Y=1: 10.5%, Pseudo RÂ²=0.2328\n",
      "  Femmes       : n=237,699, Y=1: 7.2%, Pseudo RÂ²=0.2481\n",
      "\n",
      "--- Par tranche d'Ã¢ge ---\n",
      "  <35 ans      : n=161,509, Y=1: 8.0%, Pseudo RÂ²=0.2485\n",
      "  â‰¥35 ans      : n=332,974, Y=1: 9.4%, Pseudo RÂ²=0.2397\n",
      "\n",
      "================================================================================\n",
      "TEST 7 : SENSIBILITÃ‰\n",
      "================================================================================\n",
      "\n",
      "--- Exclusion rÃ©sidus extrÃªmes ---\n",
      "  Observations exclues (|rÃ©sidu| > 3Ïƒ) : 21432 (4.33%)\n",
      "  Pseudo RÂ² (sans extrÃªmes) : 0.4825\n",
      "\n",
      "--- Jackknife par dÃ©partement ---\n",
      "\n",
      "================================================================================\n",
      "TEST 8 : FORME FONCTIONNELLE Ã‚GE\n",
      "================================================================================\n",
      "\n",
      "Forme                  Log-L          AIC          BIC\n",
      "-------------------------------------------------------\n",
      "LinÃ©aire         -113,537.00   227,204.00   227,926.23\n",
      "Quadratique      -113,380.76   226,893.52   227,626.87\n",
      "Cubique          -113,358.94   226,851.88   227,596.34\n",
      "Spline           -113,358.47   226,852.95   227,608.51\n",
      "\n",
      "âœ“ Meilleure forme (BIC) : Cubique\n",
      "\n",
      "Test LR (Quad vs Lin) : Ï‡Â²=312.48, p=0.0000\n",
      "âœ“ Effet quadratique significatif\n",
      "\n",
      "âœ“ Rapport sauvegardÃ© : /Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready/Robustesse/rapport_robustesse.txt\n",
      "\n",
      "================================================================================\n",
      "TESTS DE ROBUSTESSE TERMINÃ‰S\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "TESTS DE ROBUSTESSE - MODÃˆLE PROBIT TRANSFRONTALIER\n",
    "================================================================================\n",
    "Version adaptÃ©e pour BDD_PROBIT.csv (base dÃ©jÃ  prÃ©parÃ©e)\n",
    "\n",
    "Utilise directement :\n",
    "- X : BDD_PROBIT.csv (variables explicatives, catÃ©gories de rÃ©fÃ©rence dÃ©jÃ  supprimÃ©es)\n",
    "- Y : y_final.csv (variable dÃ©pendante)\n",
    "\n",
    "CatÃ©gories de rÃ©fÃ©rence (rappel) :\n",
    "- DEPT_51 (Marne), SEXE_1 (Homme), GS_5 (EmployÃ©s), EMPL_16 (CDI)\n",
    "- NENFR_0 (0 enfant), NA5_GU (Commerce/Services), DIPL_13 (CAP/BEP)\n",
    "- COUPLE_1 (En couple), TP_1 (Temps complet), etc.\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION - CHEMINS DES FICHIERS\n",
    "# ============================================================================\n",
    "# Adapter ces chemins si nÃ©cessaire\n",
    "X_PATH = \"/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready/BDD_PROBIT.csv\"\n",
    "Y_PATH = \"/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready/y_final.csv\"\n",
    "OUTPUT_DIR = \"/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready/Robustesse\"\n",
    "\n",
    "\n",
    "def load_data(x_path, y_path):\n",
    "    \"\"\"\n",
    "    Charge les donnÃ©es X et Y dÃ©jÃ  prÃ©parÃ©es.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"CHARGEMENT DES DONNÃ‰ES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Charger X\n",
    "    X = pd.read_csv(x_path)\n",
    "    print(f\"\\nâœ“ X chargÃ© : {X.shape[0]:,} obs Ã— {X.shape[1]} variables\")\n",
    "    \n",
    "    # Charger Y\n",
    "    Y_df = pd.read_csv(y_path)\n",
    "    print(f\"âœ“ Y chargÃ© : {Y_df.shape[0]:,} observations\")\n",
    "    \n",
    "    # Identifier la colonne Y (peut Ãªtre 'Y', 'y', 'ILT_7', 'TRANSFRONTALIER', etc.)\n",
    "    y_col = Y_df.columns[0]  # Prendre la premiÃ¨re colonne\n",
    "    Y = Y_df[y_col].values\n",
    "    print(f\"  â†’ Colonne utilisÃ©e : '{y_col}'\")\n",
    "    \n",
    "    # Statistiques Y\n",
    "    n_transfront = Y.sum()\n",
    "    pct_transfront = 100 * n_transfront / len(Y)\n",
    "    print(f\"\\nâœ“ Variable dÃ©pendante :\")\n",
    "    print(f\"  â†’ Transfrontaliers (Y=1) : {n_transfront:,} ({pct_transfront:.2f}%)\")\n",
    "    print(f\"  â†’ Non-transfrontaliers   : {len(Y) - n_transfront:,} ({100-pct_transfront:.2f}%)\")\n",
    "    \n",
    "    # VÃ©rifier cohÃ©rence\n",
    "    if len(X) != len(Y):\n",
    "        raise ValueError(f\"IncohÃ©rence : X a {len(X)} obs, Y a {len(Y)} obs\")\n",
    "    \n",
    "    # Ajouter constante\n",
    "    X_with_const = sm.add_constant(X, has_constant='add')\n",
    "    print(f\"\\nâœ“ Constante ajoutÃ©e : {X_with_const.shape[1]} variables (dont intercept)\")\n",
    "    \n",
    "    return X, X_with_const, Y\n",
    "\n",
    "\n",
    "def test_1_baseline_probit(X, Y, report_lines):\n",
    "    \"\"\"\n",
    "    Test 1 : Estimation du modÃ¨le probit de base\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 1 : MODÃˆLE PROBIT DE BASE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 1 : MODÃˆLE PROBIT DE BASE\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        model = sm.Probit(Y, X)\n",
    "        result = model.fit(disp=0, maxiter=100)\n",
    "        \n",
    "        print(f\"\\nâœ“ Convergence : {'Oui' if result.mle_retvals['converged'] else 'Non'}\")\n",
    "        print(f\"âœ“ ItÃ©rations  : {result.mle_retvals.get('iterations', 'N/A')}\")\n",
    "        print(f\"âœ“ Log-L       : {result.llf:,.2f}\")\n",
    "        print(f\"âœ“ Pseudo RÂ²   : {result.prsquared:.4f}\")\n",
    "        print(f\"âœ“ AIC         : {result.aic:,.2f}\")\n",
    "        print(f\"âœ“ BIC         : {result.bic:,.2f}\")\n",
    "        \n",
    "        # Test LR global\n",
    "        llr_pvalue = result.llr_pvalue\n",
    "        print(f\"âœ“ LR test p   : {llr_pvalue:.2e}\")\n",
    "        \n",
    "        report_lines.append(f\"\\nConvergence : {'Oui' if result.mle_retvals['converged'] else 'Non'}\")\n",
    "        report_lines.append(f\"ItÃ©rations  : {result.mle_retvals.get('iterations', 'N/A')}\")\n",
    "        report_lines.append(f\"Log-L       : {result.llf:,.2f}\")\n",
    "        report_lines.append(f\"Pseudo RÂ²   : {result.prsquared:.4f}\")\n",
    "        report_lines.append(f\"AIC         : {result.aic:,.2f}\")\n",
    "        report_lines.append(f\"BIC         : {result.bic:,.2f}\")\n",
    "        report_lines.append(f\"LR test p   : {llr_pvalue:.2e}\")\n",
    "        \n",
    "        # Coefficients clÃ©s\n",
    "        print(\"\\n--- Coefficients clÃ©s ---\")\n",
    "        report_lines.append(\"\\n--- Coefficients clÃ©s ---\")\n",
    "        \n",
    "        key_vars = ['DEPT_57', 'DEPT_68', 'DEPT_54', 'DEPT_67', 'SEXE_2', 'AGEREV', 'AGEREV_sq']\n",
    "        for var in key_vars:\n",
    "            if var in result.params.index:\n",
    "                coef = result.params[var]\n",
    "                se = result.bse[var]\n",
    "                pval = result.pvalues[var]\n",
    "                signif = '***' if pval < 0.001 else '**' if pval < 0.01 else '*' if pval < 0.05 else ''\n",
    "                print(f\"  {var:<12} : {coef:>8.4f} (SE={se:.4f}) {signif}\")\n",
    "                report_lines.append(f\"  {var:<12} : {coef:>8.4f} (SE={se:.4f}) {signif}\")\n",
    "        \n",
    "        report_lines.append(\"\\nâœ… TEST 1 RÃ‰USSI\")\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Erreur : {e}\")\n",
    "        report_lines.append(f\"\\nâŒ ERREUR : {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def test_2_link_test(X, Y, baseline_result, report_lines):\n",
    "    \"\"\"\n",
    "    Test 2 : Link Test de Pregibon\n",
    "    H0 : SpÃ©cification correcte (coefficient de _hatsq non significatif)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 2 : LINK TEST (PREGIBON)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 2 : LINK TEST (PREGIBON)\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        # PrÃ©dictions linÃ©aires\n",
    "        y_hat = baseline_result.predict()\n",
    "        xb = stats.norm.ppf(np.clip(y_hat, 1e-10, 1-1e-10))  # Inverse de Phi\n",
    "        xb_sq = xb ** 2\n",
    "        \n",
    "        # RÃ©gression auxiliaire\n",
    "        X_link = pd.DataFrame({\n",
    "            'const': 1,\n",
    "            '_hat': xb,\n",
    "            '_hatsq': xb_sq\n",
    "        })\n",
    "        \n",
    "        model_link = sm.Probit(Y, X_link)\n",
    "        result_link = model_link.fit(disp=0)\n",
    "        \n",
    "        coef_hatsq = result_link.params['_hatsq']\n",
    "        pval_hatsq = result_link.pvalues['_hatsq']\n",
    "        \n",
    "        print(f\"\\n_hat   coef : {result_link.params['_hat']:.4f} (p={result_link.pvalues['_hat']:.4f})\")\n",
    "        print(f\"_hatsq coef : {coef_hatsq:.4f} (p={pval_hatsq:.4f})\")\n",
    "        \n",
    "        report_lines.append(f\"\\n_hat   coef : {result_link.params['_hat']:.4f} (p={result_link.pvalues['_hat']:.4f})\")\n",
    "        report_lines.append(f\"_hatsq coef : {coef_hatsq:.4f} (p={pval_hatsq:.4f})\")\n",
    "        \n",
    "        if pval_hatsq > 0.05:\n",
    "            print(\"\\nâœ… H0 non rejetÃ©e : SpÃ©cification correcte\")\n",
    "            report_lines.append(\"\\nâœ… RÃ‰USSI : SpÃ©cification correcte (p > 0.05)\")\n",
    "        else:\n",
    "            print(\"\\nâš ï¸ H0 rejetÃ©e : Possible erreur de spÃ©cification\")\n",
    "            report_lines.append(\"\\nâš ï¸ ATTENTION : Possible erreur de spÃ©cification (p < 0.05)\")\n",
    "            \n",
    "        return pval_hatsq\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Erreur : {e}\")\n",
    "        report_lines.append(f\"\\nâŒ ERREUR : {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def test_3_hosmer_lemeshow(Y, baseline_result, report_lines, n_groups=10):\n",
    "    \"\"\"\n",
    "    Test 3 : Hosmer-Lemeshow Goodness of Fit\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 3 : HOSMER-LEMESHOW\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 3 : HOSMER-LEMESHOW\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        y_pred = baseline_result.predict()\n",
    "        \n",
    "        # CrÃ©er dÃ©ciles\n",
    "        df_hl = pd.DataFrame({'y': Y, 'pred': y_pred})\n",
    "        df_hl['decile'] = pd.qcut(df_hl['pred'], n_groups, labels=False, duplicates='drop')\n",
    "        \n",
    "        # Calculer observÃ© vs attendu par groupe\n",
    "        grouped = df_hl.groupby('decile').agg({\n",
    "            'y': ['sum', 'count'],\n",
    "            'pred': 'sum'\n",
    "        })\n",
    "        grouped.columns = ['obs_1', 'n', 'exp_1']\n",
    "        grouped['obs_0'] = grouped['n'] - grouped['obs_1']\n",
    "        grouped['exp_0'] = grouped['n'] - grouped['exp_1']\n",
    "        \n",
    "        # Statistique HL\n",
    "        hl_stat = 0\n",
    "        for _, row in grouped.iterrows():\n",
    "            if row['exp_1'] > 0:\n",
    "                hl_stat += (row['obs_1'] - row['exp_1'])**2 / row['exp_1']\n",
    "            if row['exp_0'] > 0:\n",
    "                hl_stat += (row['obs_0'] - row['exp_0'])**2 / row['exp_0']\n",
    "        \n",
    "        df_hl_test = len(grouped) - 2\n",
    "        p_value = 1 - chi2.cdf(hl_stat, df_hl_test)\n",
    "        \n",
    "        print(f\"\\nStatistique HL : {hl_stat:.2f}\")\n",
    "        print(f\"DegrÃ©s libertÃ© : {df_hl_test}\")\n",
    "        print(f\"P-value        : {p_value:.4f}\")\n",
    "        \n",
    "        report_lines.append(f\"\\nStatistique HL : {hl_stat:.2f}\")\n",
    "        report_lines.append(f\"DegrÃ©s libertÃ© : {df_hl_test}\")\n",
    "        report_lines.append(f\"P-value        : {p_value:.4f}\")\n",
    "        \n",
    "        if p_value > 0.05:\n",
    "            print(\"\\nâœ… Bon ajustement (p > 0.05)\")\n",
    "            report_lines.append(\"\\nâœ… RÃ‰USSI : Bon ajustement\")\n",
    "        else:\n",
    "            print(\"\\nâš ï¸ Ajustement insuffisant (p < 0.05)\")\n",
    "            report_lines.append(\"\\nâš ï¸ ATTENTION : Ajustement insuffisant\")\n",
    "            \n",
    "        return hl_stat, p_value\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Erreur : {e}\")\n",
    "        report_lines.append(f\"\\nâŒ ERREUR : {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def test_4_probit_vs_logit(X, Y, report_lines):\n",
    "    \"\"\"\n",
    "    Test 4 : Comparaison Probit vs Logit\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 4 : PROBIT VS LOGIT\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 4 : PROBIT VS LOGIT\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        # Probit\n",
    "        model_probit = sm.Probit(Y, X)\n",
    "        result_probit = model_probit.fit(disp=0)\n",
    "        \n",
    "        # Logit\n",
    "        model_logit = sm.Logit(Y, X)\n",
    "        result_logit = model_logit.fit(disp=0)\n",
    "        \n",
    "        print(f\"\\n{'CritÃ¨re':<15} {'Probit':>12} {'Logit':>12}\")\n",
    "        print(\"-\" * 45)\n",
    "        print(f\"{'Log-L':<15} {result_probit.llf:>12,.2f} {result_logit.llf:>12,.2f}\")\n",
    "        print(f\"{'Pseudo RÂ²':<15} {result_probit.prsquared:>12.4f} {result_logit.prsquared:>12.4f}\")\n",
    "        print(f\"{'AIC':<15} {result_probit.aic:>12,.2f} {result_logit.aic:>12,.2f}\")\n",
    "        print(f\"{'BIC':<15} {result_probit.bic:>12,.2f} {result_logit.bic:>12,.2f}\")\n",
    "        \n",
    "        report_lines.append(f\"\\n{'CritÃ¨re':<15} {'Probit':>12} {'Logit':>12}\")\n",
    "        report_lines.append(\"-\" * 45)\n",
    "        report_lines.append(f\"{'Log-L':<15} {result_probit.llf:>12,.2f} {result_logit.llf:>12,.2f}\")\n",
    "        report_lines.append(f\"{'Pseudo RÂ²':<15} {result_probit.prsquared:>12.4f} {result_logit.prsquared:>12.4f}\")\n",
    "        report_lines.append(f\"{'AIC':<15} {result_probit.aic:>12,.2f} {result_logit.aic:>12,.2f}\")\n",
    "        report_lines.append(f\"{'BIC':<15} {result_probit.bic:>12,.2f} {result_logit.bic:>12,.2f}\")\n",
    "        \n",
    "        # Ratio des coefficients (thÃ©oriquement ~1.6)\n",
    "        common_vars = [v for v in result_probit.params.index if v in result_logit.params.index and v != 'const']\n",
    "        if common_vars:\n",
    "            ratios = result_logit.params[common_vars] / result_probit.params[common_vars]\n",
    "            mean_ratio = ratios.mean()\n",
    "            print(f\"\\nRatio moyen Logit/Probit : {mean_ratio:.3f} (thÃ©orique ~1.6)\")\n",
    "            report_lines.append(f\"\\nRatio moyen Logit/Probit : {mean_ratio:.3f} (thÃ©orique ~1.6)\")\n",
    "        \n",
    "        # CorrÃ©lation des effets marginaux\n",
    "        mfx_probit = result_probit.get_margeff(at='mean').margeff\n",
    "        mfx_logit = result_logit.get_margeff(at='mean').margeff\n",
    "        corr_mfx = np.corrcoef(mfx_probit, mfx_logit)[0, 1]\n",
    "        \n",
    "        print(f\"CorrÃ©lation effets marginaux : {corr_mfx:.4f}\")\n",
    "        report_lines.append(f\"CorrÃ©lation effets marginaux : {corr_mfx:.4f}\")\n",
    "        \n",
    "        if corr_mfx > 0.99:\n",
    "            print(\"\\nâœ… Probit et Logit quasi-Ã©quivalents\")\n",
    "            report_lines.append(\"\\nâœ… RÃ‰USSI : Probit et Logit quasi-Ã©quivalents\")\n",
    "        else:\n",
    "            print(\"\\nâš ï¸ DiffÃ©rence notable entre Probit et Logit\")\n",
    "            report_lines.append(\"\\nâš ï¸ ATTENTION : DiffÃ©rence notable\")\n",
    "            \n",
    "        return result_probit, result_logit, corr_mfx\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Erreur : {e}\")\n",
    "        report_lines.append(f\"\\nâŒ ERREUR : {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def test_5_endogeneity_robustness(X, Y, baseline_result, report_lines):\n",
    "    \"\"\"\n",
    "    Test 5 : Robustesse Ã  l'exclusion des variables potentiellement endogÃ¨nes\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 5 : ROBUSTESSE ENDOGÃ‰NÃ‰ITÃ‰\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 5 : ROBUSTESSE ENDOGÃ‰NÃ‰ITÃ‰\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    # Variables potentiellement endogÃ¨nes Ã  exclure\n",
    "    vars_endogenes = ['VOIT', 'STOCD', 'TYPL', 'SANI']\n",
    "    \n",
    "    try:\n",
    "        # Identifier les colonnes Ã  exclure\n",
    "        cols_to_drop = []\n",
    "        for var in vars_endogenes:\n",
    "            cols_to_drop.extend([c for c in X.columns if c.startswith(f'{var}_') or c == var])\n",
    "        \n",
    "        cols_to_drop = [c for c in cols_to_drop if c in X.columns]\n",
    "        \n",
    "        if not cols_to_drop:\n",
    "            print(\"\\nâš ï¸ Aucune variable endogÃ¨ne trouvÃ©e dans X\")\n",
    "            report_lines.append(\"\\nâš ï¸ Aucune variable endogÃ¨ne trouvÃ©e\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\nVariables exclues : {len(cols_to_drop)}\")\n",
    "        for c in cols_to_drop[:10]:\n",
    "            print(f\"  - {c}\")\n",
    "        if len(cols_to_drop) > 10:\n",
    "            print(f\"  ... et {len(cols_to_drop)-10} autres\")\n",
    "        \n",
    "        # ModÃ¨le rÃ©duit\n",
    "        X_reduced = X.drop(columns=cols_to_drop)\n",
    "        X_reduced_const = sm.add_constant(X_reduced)\n",
    "        \n",
    "        model_reduced = sm.Probit(Y, X_reduced_const)\n",
    "        result_reduced = model_reduced.fit(disp=0)\n",
    "        \n",
    "        print(f\"\\n{'ModÃ¨le':<12} {'Log-L':>12} {'Pseudo RÂ²':>12} {'Nb vars':>10}\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"{'Complet':<12} {baseline_result.llf:>12,.2f} {baseline_result.prsquared:>12.4f} {len(baseline_result.params):>10}\")\n",
    "        print(f\"{'RÃ©duit':<12} {result_reduced.llf:>12,.2f} {result_reduced.prsquared:>12.4f} {len(result_reduced.params):>10}\")\n",
    "        \n",
    "        report_lines.append(f\"\\nVariables exclues : {cols_to_drop}\")\n",
    "        report_lines.append(f\"\\n{'ModÃ¨le':<12} {'Log-L':>12} {'Pseudo RÂ²':>12}\")\n",
    "        report_lines.append(\"-\" * 50)\n",
    "        report_lines.append(f\"{'Complet':<12} {baseline_result.llf:>12,.2f} {baseline_result.prsquared:>12.4f}\")\n",
    "        report_lines.append(f\"{'RÃ©duit':<12} {result_reduced.llf:>12,.2f} {result_reduced.prsquared:>12.4f}\")\n",
    "        \n",
    "        # StabilitÃ© des coefficients clÃ©s\n",
    "        print(\"\\n--- StabilitÃ© des coefficients clÃ©s ---\")\n",
    "        report_lines.append(\"\\n--- StabilitÃ© des coefficients clÃ©s ---\")\n",
    "        \n",
    "        key_vars = ['DEPT_57', 'DEPT_68', 'SEXE_2', 'AGEREV']\n",
    "        stable = True\n",
    "        \n",
    "        for var in key_vars:\n",
    "            if var in baseline_result.params.index and var in result_reduced.params.index:\n",
    "                coef_full = baseline_result.params[var]\n",
    "                coef_red = result_reduced.params[var]\n",
    "                pct_change = 100 * (coef_red - coef_full) / abs(coef_full) if coef_full != 0 else 0\n",
    "                \n",
    "                status = \"âœ“\" if abs(pct_change) < 20 else \"âš ï¸\"\n",
    "                if abs(pct_change) >= 20:\n",
    "                    stable = False\n",
    "                    \n",
    "                print(f\"  {var:<12} : {coef_full:>8.4f} â†’ {coef_red:>8.4f} ({pct_change:+.1f}%) {status}\")\n",
    "                report_lines.append(f\"  {var:<12} : {coef_full:>8.4f} â†’ {coef_red:>8.4f} ({pct_change:+.1f}%) {status}\")\n",
    "        \n",
    "        if stable:\n",
    "            print(\"\\nâœ… Coefficients stables aprÃ¨s exclusion\")\n",
    "            report_lines.append(\"\\nâœ… RÃ‰USSI : Coefficients stables\")\n",
    "        else:\n",
    "            print(\"\\nâš ï¸ Certains coefficients varient de plus de 20%\")\n",
    "            report_lines.append(\"\\nâš ï¸ ATTENTION : Coefficients instables\")\n",
    "            \n",
    "        return result_reduced\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Erreur : {e}\")\n",
    "        report_lines.append(f\"\\nâŒ ERREUR : {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def test_6_subsamples(X, Y, report_lines):\n",
    "    \"\"\"\n",
    "    Test 6 : Analyse par sous-Ã©chantillons\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 6 : SOUS-Ã‰CHANTILLONS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 6 : SOUS-Ã‰CHANTILLONS\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    results_subsamples = {}\n",
    "    \n",
    "    # 1. Par dÃ©partement (frontalier vs intÃ©rieur)\n",
    "    print(\"\\n--- DÃ©partements frontaliers vs intÃ©rieurs ---\")\n",
    "    report_lines.append(\"\\n--- DÃ©partements frontaliers vs intÃ©rieurs ---\")\n",
    "    \n",
    "    # Identifier les dÃ©partements frontaliers\n",
    "    dept_front_cols = ['DEPT_57', 'DEPT_68', 'DEPT_54', 'DEPT_67', 'DEPT_55', 'DEPT_88', 'DEPT_90']\n",
    "    dept_front_cols = [c for c in dept_front_cols if c in X.columns]\n",
    "    \n",
    "    if dept_front_cols:\n",
    "        mask_front = X[dept_front_cols].sum(axis=1) > 0\n",
    "        \n",
    "        for name, mask in [('Frontaliers', mask_front), ('IntÃ©rieurs', ~mask_front)]:\n",
    "            X_sub = X.loc[mask]\n",
    "            Y_sub = Y[mask.values]\n",
    "            \n",
    "            if len(Y_sub) > 100 and Y_sub.sum() > 10:\n",
    "                X_sub_const = sm.add_constant(X_sub)\n",
    "                try:\n",
    "                    model = sm.Probit(Y_sub, X_sub_const)\n",
    "                    result = model.fit(disp=0, maxiter=50)\n",
    "                    prevalence = 100 * Y_sub.mean()\n",
    "                    print(f\"  {name:<12} : n={len(Y_sub):,}, Y=1: {prevalence:.1f}%, Pseudo RÂ²={result.prsquared:.4f}\")\n",
    "                    report_lines.append(f\"  {name:<12} : n={len(Y_sub):,}, Y=1: {prevalence:.1f}%, Pseudo RÂ²={result.prsquared:.4f}\")\n",
    "                    results_subsamples[name] = result\n",
    "                except:\n",
    "                    print(f\"  {name:<12} : Estimation Ã©chouÃ©e\")\n",
    "    \n",
    "    # 2. Par sexe\n",
    "    print(\"\\n--- Par sexe ---\")\n",
    "    report_lines.append(\"\\n--- Par sexe ---\")\n",
    "    \n",
    "    if 'SEXE_2' in X.columns:\n",
    "        for name, val in [('Hommes', 0), ('Femmes', 1)]:\n",
    "            mask = X['SEXE_2'] == val\n",
    "            X_sub = X.loc[mask].drop(columns=['SEXE_2'])\n",
    "            Y_sub = Y[mask.values]\n",
    "            \n",
    "            if len(Y_sub) > 100 and Y_sub.sum() > 10:\n",
    "                X_sub_const = sm.add_constant(X_sub)\n",
    "                try:\n",
    "                    model = sm.Probit(Y_sub, X_sub_const)\n",
    "                    result = model.fit(disp=0, maxiter=50)\n",
    "                    prevalence = 100 * Y_sub.mean()\n",
    "                    print(f\"  {name:<12} : n={len(Y_sub):,}, Y=1: {prevalence:.1f}%, Pseudo RÂ²={result.prsquared:.4f}\")\n",
    "                    report_lines.append(f\"  {name:<12} : n={len(Y_sub):,}, Y=1: {prevalence:.1f}%, Pseudo RÂ²={result.prsquared:.4f}\")\n",
    "                    results_subsamples[name] = result\n",
    "                except:\n",
    "                    print(f\"  {name:<12} : Estimation Ã©chouÃ©e\")\n",
    "    \n",
    "    # 3. Par Ã¢ge\n",
    "    print(\"\\n--- Par tranche d'Ã¢ge ---\")\n",
    "    report_lines.append(\"\\n--- Par tranche d'Ã¢ge ---\")\n",
    "    \n",
    "    if 'AGEREV' in X.columns:\n",
    "        for name, condition in [('<35 ans', X['AGEREV'] < 35), ('â‰¥35 ans', X['AGEREV'] >= 35)]:\n",
    "            mask = condition\n",
    "            X_sub = X.loc[mask]\n",
    "            Y_sub = Y[mask.values]\n",
    "            \n",
    "            if len(Y_sub) > 100 and Y_sub.sum() > 10:\n",
    "                X_sub_const = sm.add_constant(X_sub)\n",
    "                try:\n",
    "                    model = sm.Probit(Y_sub, X_sub_const)\n",
    "                    result = model.fit(disp=0, maxiter=50)\n",
    "                    prevalence = 100 * Y_sub.mean()\n",
    "                    print(f\"  {name:<12} : n={len(Y_sub):,}, Y=1: {prevalence:.1f}%, Pseudo RÂ²={result.prsquared:.4f}\")\n",
    "                    report_lines.append(f\"  {name:<12} : n={len(Y_sub):,}, Y=1: {prevalence:.1f}%, Pseudo RÂ²={result.prsquared:.4f}\")\n",
    "                    results_subsamples[name] = result\n",
    "                except:\n",
    "                    print(f\"  {name:<12} : Estimation Ã©chouÃ©e\")\n",
    "    \n",
    "    report_lines.append(\"\\nâœ… Analyse par sous-Ã©chantillons terminÃ©e\")\n",
    "    return results_subsamples\n",
    "\n",
    "\n",
    "def test_7_sensitivity(X, Y, baseline_result, report_lines):\n",
    "    \"\"\"\n",
    "    Test 7 : Analyse de sensibilitÃ©\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 7 : SENSIBILITÃ‰\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 7 : SENSIBILITÃ‰\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    # 1. Exclusion des rÃ©sidus extrÃªmes\n",
    "    print(\"\\n--- Exclusion rÃ©sidus extrÃªmes ---\")\n",
    "    report_lines.append(\"\\n--- Exclusion rÃ©sidus extrÃªmes ---\")\n",
    "    \n",
    "    try:\n",
    "        y_pred = baseline_result.predict()\n",
    "        residuals = Y - y_pred\n",
    "        std_res = (residuals - residuals.mean()) / residuals.std()\n",
    "        \n",
    "        mask_normal = np.abs(std_res) <= 3\n",
    "        n_excluded = (~mask_normal).sum()\n",
    "        \n",
    "        print(f\"  Observations exclues (|rÃ©sidu| > 3Ïƒ) : {n_excluded} ({100*n_excluded/len(Y):.2f}%)\")\n",
    "        report_lines.append(f\"  Observations exclues : {n_excluded} ({100*n_excluded/len(Y):.2f}%)\")\n",
    "        \n",
    "        X_clean = X.loc[mask_normal]\n",
    "        Y_clean = Y[mask_normal]\n",
    "        X_clean_const = sm.add_constant(X_clean)\n",
    "        \n",
    "        model_clean = sm.Probit(Y_clean, X_clean_const)\n",
    "        result_clean = model_clean.fit(disp=0)\n",
    "        \n",
    "        print(f\"  Pseudo RÂ² (sans extrÃªmes) : {result_clean.prsquared:.4f}\")\n",
    "        report_lines.append(f\"  Pseudo RÂ² (sans extrÃªmes) : {result_clean.prsquared:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Erreur : {e}\")\n",
    "    \n",
    "    # 2. Jackknife par dÃ©partement\n",
    "    print(\"\\n--- Jackknife par dÃ©partement ---\")\n",
    "    report_lines.append(\"\\n--- Jackknife par dÃ©partement ---\")\n",
    "    \n",
    "    dept_cols = [c for c in X.columns if c.startswith('DEPT_')]\n",
    "    \n",
    "    key_var = 'AGEREV' if 'AGEREV' in X.columns else (dept_cols[0] if dept_cols else None)\n",
    "    \n",
    "    if key_var and dept_cols:\n",
    "        coefs_jack = []\n",
    "        \n",
    "        for dept in dept_cols[:5]:  # Limiter Ã  5 pour la vitesse\n",
    "            mask = X[dept] == 0  # Exclure ce dÃ©partement\n",
    "            X_jack = X.loc[mask]\n",
    "            Y_jack = Y[mask.values]\n",
    "            \n",
    "            if len(Y_jack) > 100:\n",
    "                try:\n",
    "                    X_jack_const = sm.add_constant(X_jack)\n",
    "                    model = sm.Probit(Y_jack, X_jack_const)\n",
    "                    result = model.fit(disp=0, maxiter=30)\n",
    "                    \n",
    "                    if key_var in result.params.index:\n",
    "                        coefs_jack.append(result.params[key_var])\n",
    "                        print(f\"  Sans {dept:<10} : {key_var} = {result.params[key_var]:.4f}\")\n",
    "                        report_lines.append(f\"  Sans {dept:<10} : {key_var} = {result.params[key_var]:.4f}\")\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        if coefs_jack:\n",
    "            std_jack = np.std(coefs_jack)\n",
    "            print(f\"\\n  Ã‰cart-type Jackknife ({key_var}) : {std_jack:.4f}\")\n",
    "            report_lines.append(f\"\\n  Ã‰cart-type Jackknife ({key_var}) : {std_jack:.4f}\")\n",
    "    \n",
    "    report_lines.append(\"\\nâœ… Analyse de sensibilitÃ© terminÃ©e\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def test_8_functional_form_age(X, Y, report_lines):\n",
    "    \"\"\"\n",
    "    Test 8 : Formes fonctionnelles pour l'Ã¢ge\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 8 : FORME FONCTIONNELLE Ã‚GE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 8 : FORME FONCTIONNELLE Ã‚GE\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    if 'AGEREV' not in X.columns:\n",
    "        print(\"\\nâš ï¸ Variable AGEREV non trouvÃ©e\")\n",
    "        report_lines.append(\"\\nâš ï¸ Variable AGEREV non trouvÃ©e\")\n",
    "        return None\n",
    "    \n",
    "    results_age = {}\n",
    "    \n",
    "    # PrÃ©parer les variables autres que l'Ã¢ge\n",
    "    age_cols = [c for c in X.columns if 'AGE' in c.upper()]\n",
    "    X_base = X.drop(columns=age_cols, errors='ignore')\n",
    "    \n",
    "    try:\n",
    "        # 1. LinÃ©aire\n",
    "        X_lin = X_base.copy()\n",
    "        X_lin['AGE'] = X['AGEREV']\n",
    "        X_lin_const = sm.add_constant(X_lin)\n",
    "        model_lin = sm.Probit(Y, X_lin_const)\n",
    "        result_lin = model_lin.fit(disp=0)\n",
    "        results_age['LinÃ©aire'] = result_lin\n",
    "        \n",
    "        # 2. Quadratique\n",
    "        X_quad = X_base.copy()\n",
    "        X_quad['AGE'] = X['AGEREV']\n",
    "        X_quad['AGE_sq'] = X['AGEREV'] ** 2\n",
    "        X_quad_const = sm.add_constant(X_quad)\n",
    "        model_quad = sm.Probit(Y, X_quad_const)\n",
    "        result_quad = model_quad.fit(disp=0)\n",
    "        results_age['Quadratique'] = result_quad\n",
    "        \n",
    "        # 3. Cubique\n",
    "        X_cub = X_base.copy()\n",
    "        X_cub['AGE'] = X['AGEREV']\n",
    "        X_cub['AGE_sq'] = X['AGEREV'] ** 2\n",
    "        X_cub['AGE_cub'] = X['AGEREV'] ** 3\n",
    "        X_cub_const = sm.add_constant(X_cub)\n",
    "        model_cub = sm.Probit(Y, X_cub_const)\n",
    "        result_cub = model_cub.fit(disp=0)\n",
    "        results_age['Cubique'] = result_cub\n",
    "        \n",
    "        # 4. Spline (tranches d'Ã¢ge)\n",
    "        X_spline = X_base.copy()\n",
    "        X_spline['AGE_25_34'] = ((X['AGEREV'] >= 25) & (X['AGEREV'] < 35)).astype(int)\n",
    "        X_spline['AGE_35_44'] = ((X['AGEREV'] >= 35) & (X['AGEREV'] < 45)).astype(int)\n",
    "        X_spline['AGE_45_54'] = ((X['AGEREV'] >= 45) & (X['AGEREV'] < 55)).astype(int)\n",
    "        X_spline['AGE_55plus'] = (X['AGEREV'] >= 55).astype(int)\n",
    "        X_spline_const = sm.add_constant(X_spline)\n",
    "        model_spline = sm.Probit(Y, X_spline_const)\n",
    "        result_spline = model_spline.fit(disp=0)\n",
    "        results_age['Spline'] = result_spline\n",
    "        \n",
    "        # Comparaison\n",
    "        print(f\"\\n{'Forme':<15} {'Log-L':>12} {'AIC':>12} {'BIC':>12}\")\n",
    "        print(\"-\" * 55)\n",
    "        report_lines.append(f\"\\n{'Forme':<15} {'Log-L':>12} {'AIC':>12} {'BIC':>12}\")\n",
    "        report_lines.append(\"-\" * 55)\n",
    "        \n",
    "        for name, res in results_age.items():\n",
    "            print(f\"{name:<15} {res.llf:>12,.2f} {res.aic:>12,.2f} {res.bic:>12,.2f}\")\n",
    "            report_lines.append(f\"{name:<15} {res.llf:>12,.2f} {res.aic:>12,.2f} {res.bic:>12,.2f}\")\n",
    "        \n",
    "        # Meilleur selon BIC\n",
    "        best = min(results_age.items(), key=lambda x: x[1].bic)\n",
    "        print(f\"\\nâœ“ Meilleure forme (BIC) : {best[0]}\")\n",
    "        report_lines.append(f\"\\nâœ“ Meilleure forme (BIC) : {best[0]}\")\n",
    "        \n",
    "        # Test LR quadratique vs linÃ©aire\n",
    "        lr_stat = 2 * (result_quad.llf - result_lin.llf)\n",
    "        lr_pval = 1 - chi2.cdf(lr_stat, 1)\n",
    "        print(f\"\\nTest LR (Quad vs Lin) : Ï‡Â²={lr_stat:.2f}, p={lr_pval:.4f}\")\n",
    "        report_lines.append(f\"\\nTest LR (Quad vs Lin) : Ï‡Â²={lr_stat:.2f}, p={lr_pval:.4f}\")\n",
    "        \n",
    "        if lr_pval < 0.05:\n",
    "            print(\"âœ“ Effet quadratique significatif\")\n",
    "            report_lines.append(\"âœ“ Effet quadratique significatif\")\n",
    "        \n",
    "        return results_age\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Erreur : {e}\")\n",
    "        report_lines.append(f\"\\nâŒ ERREUR : {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_report(report_lines, output_dir):\n",
    "    \"\"\"\n",
    "    GÃ©nÃ¨re le rapport final\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Ajouter en-tÃªte\n",
    "    header = [\n",
    "        \"=\" * 80,\n",
    "        \"RAPPORT DE ROBUSTESSE - MODÃˆLE PROBIT TRANSFRONTALIER\",\n",
    "        f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "        \"=\" * 80,\n",
    "        \"\"\n",
    "    ]\n",
    "    \n",
    "    full_report = header + report_lines\n",
    "    \n",
    "    # Sauvegarder\n",
    "    report_path = os.path.join(output_dir, \"rapport_robustesse.txt\")\n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(full_report))\n",
    "    \n",
    "    print(f\"\\nâœ“ Rapport sauvegardÃ© : {report_path}\")\n",
    "    return report_path\n",
    "\n",
    "\n",
    "def run_all_tests(x_path=X_PATH, y_path=Y_PATH, output_dir=OUTPUT_DIR):\n",
    "    \"\"\"\n",
    "    ExÃ©cute tous les tests de robustesse\n",
    "    \"\"\"\n",
    "    report_lines = []\n",
    "    \n",
    "    # Chargement\n",
    "    X, X_const, Y = load_data(x_path, y_path)\n",
    "    \n",
    "    # Test 1 : Probit de base\n",
    "    baseline = test_1_baseline_probit(X_const, Y, report_lines)\n",
    "    if baseline is None:\n",
    "        print(\"\\nâŒ ArrÃªt : le modÃ¨le de base n'a pas convergÃ©\")\n",
    "        return\n",
    "    \n",
    "    # Test 2 : Link Test\n",
    "    test_2_link_test(X_const, Y, baseline, report_lines)\n",
    "    \n",
    "    # Test 3 : Hosmer-Lemeshow\n",
    "    test_3_hosmer_lemeshow(Y, baseline, report_lines)\n",
    "    \n",
    "    # Test 4 : Probit vs Logit\n",
    "    test_4_probit_vs_logit(X_const, Y, report_lines)\n",
    "    \n",
    "    # Test 5 : Robustesse endogÃ©nÃ©itÃ©\n",
    "    test_5_endogeneity_robustness(X, Y, baseline, report_lines)\n",
    "    \n",
    "    # Test 6 : Sous-Ã©chantillons\n",
    "    test_6_subsamples(X, Y, report_lines)\n",
    "    \n",
    "    # Test 7 : SensibilitÃ©\n",
    "    test_7_sensitivity(X, Y, baseline, report_lines)\n",
    "    \n",
    "    # Test 8 : Forme fonctionnelle Ã¢ge\n",
    "    test_8_functional_form_age(X, Y, report_lines)\n",
    "    \n",
    "    # GÃ©nÃ©rer rapport\n",
    "    generate_report(report_lines, output_dir)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TESTS DE ROBUSTESSE TERMINÃ‰S\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return baseline\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXÃ‰CUTION\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TESTS DE ROBUSTESSE - PROBIT TRANSFRONTALIER\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # VÃ©rifier si les fichiers existent (pour environnement local)\n",
    "    import os\n",
    "    if os.path.exists(X_PATH) and os.path.exists(Y_PATH):\n",
    "        run_all_tests()\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ Fichiers non trouvÃ©s :\")\n",
    "        print(f\"   X : {X_PATH}\")\n",
    "        print(f\"   Y : {Y_PATH}\")\n",
    "        print(\"\\nâ†’ Adapter les chemins X_PATH et Y_PATH en haut du script\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b0b907",
   "metadata": {},
   "source": [
    "## InterprÃ©tation des tests de robustesse \n",
    "\n",
    "### RÃ©sultats satisfaisants\n",
    "\n",
    "**Convergence et ajustement global**\n",
    "\n",
    "Le modÃ¨le probit converge rapidement en 10 itÃ©rations, avec un pseudo-RÂ² de 0.24, un AIC de 226 894 et un BIC de 227 627. Ces valeurs de pseudo-RÂ² peuvent sembler modestes comparÃ©es aux RÂ² de rÃ©gression linÃ©aire, mais elles sont tout Ã  fait satisfaisantes pour un modÃ¨le de choix binaire sur donnÃ©es individuelles. Elles indiquent que les variables retenues captent une part significative de l'hÃ©tÃ©rogÃ©nÃ©itÃ© des comportements transfrontaliers, sachant qu'une grande partie des dÃ©terminants (prÃ©fÃ©rences, rÃ©seaux, compÃ©tences linguistiques) n'est pas observable dans les donnÃ©es du recensement.\n",
    "\n",
    "**Coefficients Ã©conomiquement cohÃ©rents**\n",
    "\n",
    "Les coefficients dÃ©partementaux confirment le gradient gÃ©ographique attendu. La Moselle affiche l'effet le plus fort (+2.44), suivie du Haut-Rhin (+2.09), de la Meurthe-et-Moselle (+1.94) et du Bas-Rhin (+1.47). Cette hiÃ©rarchie reflÃ¨te fidÃ¨lement la proximitÃ© aux principaux bassins d'emploi frontaliers : Luxembourg pour la Moselle et la Meurthe-et-Moselle, Suisse et Allemagne pour le Haut-Rhin et le Bas-Rhin. L'effet genre est nÃ©gatif pour les femmes (-0.13), cohÃ©rent avec la littÃ©rature sur la moindre mobilitÃ© professionnelle fÃ©minine. L'effet de l'Ã¢ge suit bien une forme en U inversÃ©, avec un pic d'activitÃ© transfrontaliÃ¨re en milieu de carriÃ¨re.\n",
    "\n",
    "**HÃ©tÃ©rogÃ©nÃ©itÃ© par sexe**\n",
    "\n",
    "Les estimations par sous-Ã©chantillons rÃ©vÃ¨lent des diffÃ©rences notables entre hommes et femmes. Le taux de transfrontaliers atteint 10.5% chez les hommes contre seulement 7.2% chez les femmes, soit un Ã©cart de 3.3 points de pourcentage. MalgrÃ© cette diffÃ©rence de prÃ©valence, les pseudo-RÂ² restent comparables : 0.233 pour les hommes et 0.248 pour les femmes. La structure explicative est donc stable entre les deux groupes, mÃªme si le niveau diffÃ¨re. Les estimations par tranche d'Ã¢ge (moins de 35 ans vs 35 ans et plus) confirment cette stabilitÃ©, avec des pseudo-RÂ² de 0.249 et 0.240 respectivement.\n",
    "\n",
    "**StabilitÃ© des estimations et Ã©quivalence Probit/Logit**\n",
    "\n",
    "La comparaison Probit/Logit montre une corrÃ©lation des effets marginaux de 0.995, confirmant l'Ã©quivalence pratique des deux spÃ©cifications. Les deux modÃ¨les produisent des pseudo-RÂ² quasi identiques (0.239 vs 0.240) et des critÃ¨res d'information trÃ¨s proches. Le choix du probit est donc robuste et n'affecte pas les conclusions substantives.\n",
    "\n",
    "**Test de robustesse Ã  l'endogÃ©nÃ©itÃ©**\n",
    "\n",
    "L'exclusion des 15 variables potentiellement endogÃ¨nes (nombre de voitures, statut d'occupation du logement, type de logement) permet d'Ã©valuer la sensibilitÃ© du modÃ¨le Ã  d'Ã©ventuels biais de simultanÃ©itÃ©. Le modÃ¨le rÃ©duit, estimÃ© sur 51 variables au lieu de 66, affiche un pseudo-RÂ² de 0.221 contre 0.239 pour le modÃ¨le complet. Cette perte de seulement 1.8 point indique que les variables suspectes contribuent peu au pouvoir explicatif global. La log-vraisemblance passe de -113 381 Ã  -116 153, une dÃ©gradation modÃ©rÃ©e. Surtout, les coefficients clÃ©s restent remarquablement stables : le coefficient de la Moselle varie de +0.8%, celui du Haut-Rhin de +1.4%, celui du sexe de +4.4% et celui de l'Ã¢ge de -1.4%. Cette stabilitÃ© suggÃ¨re que les rÃ©sultats ne sont pas contaminÃ©s par un biais d'endogÃ©nÃ©itÃ© majeur.\n",
    "\n",
    "**Forme fonctionnelle de l'Ã¢ge**\n",
    "\n",
    "Le test du ratio de vraisemblance valide la spÃ©cification quadratique de l'Ã¢ge (Ï‡Â²=312, p<0.001). L'ajout d'un terme cubique amÃ©liore lÃ©gÃ¨rement l'ajustement : le BIC passe de 227 627 Ã  227 596, soit un gain de 30 points. Ce gain reste marginal et la forme quadratique constitue un bon compromis entre flexibilitÃ© et parcimonie. La spÃ©cification par splines ne fait pas mieux que la forme cubique, confirmant qu'une paramÃ©trisation polynomiale simple suffit Ã  capturer la relation Ã¢ge-travail transfrontalier.\n",
    "\n",
    "---\n",
    "\n",
    "### RÃ©sultats nÃ©cessitant approfondissement\n",
    "\n",
    "**Link Test et Hosmer-Lemeshow rejetÃ©s**\n",
    "\n",
    "Les deux tests classiques de spÃ©cification sont rejetÃ©s avec des p-values nulles. Le Link Test de Pregibon indique un coefficient de 0.051 pour le terme quadratique (_hatsq), significatif Ã  p<0.001. Le test de Hosmer-Lemeshow produit une statistique de 304.5 Ã  8 degrÃ©s de libertÃ©. Ces rÃ©sultats pourraient inquiÃ©ter, mais ils s'expliquent entiÃ¨rement par la taille de l'Ã©chantillon. Ã€ n=494 000, ces tests disposent d'une puissance statistique telle qu'ils dÃ©tectent la moindre dÃ©viation, aussi infime soit-elle, par rapport Ã  l'hypothÃ¨se nulle. Un Ã©cart de calibration de 0.1 point de pourcentage, sans aucune consÃ©quence pratique, suffit Ã  rejeter H0. Ces tests ne sont donc pas informatifs dans notre contexte et doivent Ãªtre remplacÃ©s par des diagnostics adaptÃ©s aux grands Ã©chantillons : score de Brier, courbe de calibration par dÃ©ciles, et AUC avec intervalle de confiance bootstrap.\n",
    "\n",
    "**Ratio Logit/Probit supÃ©rieur Ã  la valeur thÃ©orique**\n",
    "\n",
    "Le ratio moyen des coefficients Logit/Probit s'Ã©tablit Ã  2.05, alors que la valeur thÃ©orique attendue est d'environ 1.6. Cet Ã©cart n'indique pas nÃ©cessairement un problÃ¨me. Il provient vraisemblablement du choix de la Marne comme catÃ©gorie de rÃ©fÃ©rence. La Marne Ã©tant un dÃ©partement non frontalier, les coefficients des dÃ©partements frontaliers sont mÃ©caniquement trÃ¨s Ã©levÃ©s (supÃ©rieurs Ã  2). Or, lorsque les coefficients sont extrÃªmes, les fonctions de rÃ©partition logistique et normale divergent dans les queues de distribution, ce qui amplifie le ratio. Pour vÃ©rifier cette hypothÃ¨se, il convient de rÃ©-estimer le modÃ¨le avec un dÃ©partement frontalier comme rÃ©fÃ©rence, par exemple le Bas-Rhin, et d'observer si le ratio se rapproche de 1.6.\n",
    "\n",
    "**RÃ©sidus extrÃªmes et pseudo-RÂ² sans outliers**\n",
    "\n",
    "L'analyse identifie 21 432 observations (4.3% de l'Ã©chantillon) prÃ©sentant des rÃ©sidus standardisÃ©s supÃ©rieurs Ã  3 en valeur absolue. Un rÃ©sultat frappant Ã©merge lorsqu'on exclut ces observations : le pseudo-RÂ² bondit Ã  0.48, soit un quasi-doublement par rapport au modÃ¨le complet. Ce saut spectaculaire indique que ces individus ne sont pas du bruit alÃ©atoire mais une sous-population structurellement diffÃ©rente, dont le comportement Ã©chappe aux variables du modÃ¨le. \n",
    "\n",
    "Il serait tentant de les traiter comme des outliers Ã  exclure pour amÃ©liorer l'ajustement, mais cette approche serait mÃ©thodologiquement contestable. Ces observations correspondent Ã  des individus rÃ©els dont le comportement s'Ã©carte de la prÃ©diction du modÃ¨le. Avant toute dÃ©cision, il est indispensable de caractÃ©riser leur profil : sont-ils concentrÃ©s gÃ©ographiquement dans certains dÃ©partements ? PrÃ©sentent-ils des caractÃ©ristiques sociodÃ©mographiques particuliÃ¨res ? S'agit-il principalement de faux nÃ©gatifs (transfrontaliers non prÃ©dits) ou de faux positifs (non-transfrontaliers prÃ©dits comme tels) ? Cette analyse permettra de distinguer les Ã©ventuelles erreurs de donnÃ©es d'une hÃ©tÃ©rogÃ©nÃ©itÃ© comportementale rÃ©elle que le modÃ¨le ne capture pas.\n",
    "\n",
    "**Ã‰chec des estimations par zone frontaliÃ¨re/intÃ©rieure**\n",
    "\n",
    "L'estimation sÃ©parÃ©e sur les dÃ©partements frontaliers et intÃ©rieurs a Ã©chouÃ©. Ce rÃ©sultat est normal et attendu : au sein de chaque sous-groupe, les dummies dÃ©partementales deviennent parfaitement colinÃ©aires (toutes les observations frontaliÃ¨res ont DEPT_57=0 ou 1, etc.), rendant l'estimation impossible. Ce n'est pas un bug mais une consÃ©quence mÃ©canique du dÃ©coupage.\n",
    "\n",
    "---\n",
    "\n",
    "### Tests complÃ©mentaires Ã  conduire\n",
    "\n",
    "Pour rÃ©pondre aux questions ouvertes, trois analyses complÃ©mentaires sont nÃ©cessaires. PremiÃ¨rement, remplacer les tests HL et Link par des diagnostics adaptÃ©s aux grands Ã©chantillons : score de Brier avec comparaison au modÃ¨le nul, courbe de calibration par dÃ©ciles comparant taux observÃ©s et prÃ©dits, et AUC-ROC avec intervalle de confiance bootstrap. DeuxiÃ¨mement, caractÃ©riser les rÃ©sidus extrÃªmes en analysant leur distribution gÃ©ographique, leur profil d'Ã¢ge et de sexe, et la nature des erreurs de prÃ©diction. TroisiÃ¨mement, tester la sensibilitÃ© du ratio Logit/Probit au choix de la catÃ©gorie de rÃ©fÃ©rence en rÃ©-estimant avec le Bas-Rhin comme rÃ©fÃ©rence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd999f6",
   "metadata": {},
   "source": [
    "## Tests de robustesse complÃ©mentaires\n",
    "\n",
    "L'estimation initiale du modÃ¨le probit a convergÃ© avec un pseudo-RÂ² de 0.24 et des coefficients cohÃ©rents Ã©conomiquement. Cependant, certains rÃ©sultats appellent une analyse approfondie :\n",
    "\n",
    "1. **Diagnostics adaptÃ©s aux grands Ã©chantillons** â€” Les tests classiques (Hosmer-Lemeshow, Link Test) sont rejetÃ©s mÃ©caniquement Ã  n=494k par excÃ¨s de puissance statistique. On les remplace par : score de Brier, courbe de calibration par dÃ©ciles, AUC avec intervalle bootstrap.\n",
    "\n",
    "2. **CaractÃ©risation des rÃ©sidus extrÃªmes** â€” 4.3% d'observations prÃ©sentent des rÃ©sidus > 2.5Ïƒ. Avant toute dÃ©cision, on analyse leur distribution gÃ©ographique et leur profil sociodÃ©mographique pour distinguer erreurs de donnÃ©es vs hÃ©tÃ©rogÃ©nÃ©itÃ© comportementale rÃ©elle.\n",
    "\n",
    "3. **SensibilitÃ© au choix de la catÃ©gorie de rÃ©fÃ©rence** â€” Le ratio Logit/Probit (~2.05) dÃ©passe la valeur thÃ©orique (~1.6), possiblement dÃ» aux coefficients extrÃªmes induits par la Marne (non frontaliÃ¨re) comme rÃ©fÃ©rence. On rÃ©-estime avec le Bas-Rhin (frontalier) comme rÃ©fÃ©rence pour vÃ©rifier.\n",
    "\n",
    "4. **Comparaison des effets marginaux Probit vs Logit** â€” CorrÃ©lation et Ã©cart moyen pour confirmer l'Ã©quivalence pratique des deux spÃ©cifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d78b097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CHARGEMENT DES DONNÃ‰ES\n",
      "================================================================================\n",
      "\n",
      "âœ“ X chargÃ© : 494,483 obs Ã— 65 variables\n",
      "âœ“ Transfrontaliers (Y=1) : 44,264 (8.95%)\n",
      "\n",
      "================================================================================\n",
      "TEST 1 : MODÃˆLE PROBIT DE BASE\n",
      "================================================================================\n",
      "\n",
      "âœ“ Convergence : Oui\n",
      "âœ“ Log-L       : -113,380.76\n",
      "âœ“ Pseudo RÂ²   : 0.2393\n",
      "\n",
      "--- Coefficients clÃ©s ---\n",
      "  DEPT_57      :   2.4367 [IC95: 2.342 ; 2.531]\n",
      "  DEPT_68      :   2.0908 [IC95: 1.996 ; 2.185]\n",
      "  DEPT_54      :   1.9401 [IC95: 1.845 ; 2.035]\n",
      "  DEPT_67      :   1.4722 [IC95: 1.377 ; 1.567]\n",
      "  SEXE_2       :  -0.1255 [IC95: -0.139 ; -0.112]\n",
      "  AGEREV       :   0.0326 [IC95: 0.029 ; 0.036]\n",
      "  AGEREV_sq    :  -0.0004 [IC95: -0.000 ; -0.000]\n",
      "\n",
      "================================================================================\n",
      "TEST 2 : DIAGNOSTICS GRANDS Ã‰CHANTILLONS\n",
      "================================================================================\n",
      "\n",
      "--- 2.1 Brier Score ---\n",
      "  Brier Score      : 0.0681\n",
      "  Brier (null)     : 0.0815\n",
      "  Brier Skill Score: 0.1643\n",
      "  âœ“ Pouvoir prÃ©dictif modeste mais positif\n",
      "\n",
      "--- 2.2 Calibration par dÃ©ciles ---\n",
      "\n",
      "  DÃ©cile          N     PrÃ©dit    ObservÃ©      Ã‰cart\n",
      "  --------------------------------------------------\n",
      "  0           49449     0.0001     0.0004    +0.0003\n",
      "  1           49448     0.0008     0.0019    +0.0011\n",
      "  2           49448     0.0037     0.0044    +0.0007\n",
      "  3           49448     0.0135     0.0143    +0.0008\n",
      "  4           49449     0.0333     0.0309    -0.0024\n",
      "  5           49450     0.0569     0.0520    -0.0049\n",
      "  6           49446     0.0862     0.0861    -0.0001\n",
      "  7           49449     0.1350     0.1261    -0.0089\n",
      "  8           49447     0.2097     0.2230    +0.0133\n",
      "  9           49449     0.3558     0.3561    +0.0003\n",
      "\n",
      "  Ã‰cart moyen absolu de calibration : 0.0033\n",
      "  âœ… Excellente calibration\n",
      "\n",
      "--- 2.3 AUC-ROC avec IC Bootstrap ---\n",
      "  AUC point estimate : 0.8490\n",
      "  AUC IC 95%         : [0.8476 ; 0.8504]\n",
      "  âœ… Excellente discrimination (AUC > 0.8)\n",
      "\n",
      "--- 2.4 Validation croisÃ©e 5-fold ---\n",
      "  AUC moyen (5-fold)   : 0.8407 Â± 0.0039\n",
      "  Brier moyen (5-fold) : 0.0687 Â± 0.0003\n",
      "  âœ… TrÃ¨s stable entre folds (CV < 2%)\n",
      "\n",
      "================================================================================\n",
      "TEST 3 : CARACTÃ‰RISATION DES RÃ‰SIDUS EXTRÃŠMES\n",
      "================================================================================\n",
      "\n",
      "--- 3.1 Distribution des rÃ©sidus ---\n",
      "  |rÃ©sidu| > 2Ïƒ : 42,593 obs (8.61%)\n",
      "  |rÃ©sidu| > 2.5Ïƒ : 36,005 obs (7.28%)\n",
      "  |rÃ©sidu| > 3Ïƒ : 21,432 obs (4.33%)\n",
      "\n",
      "  â†’ Analyse dÃ©taillÃ©e pour |rÃ©sidu| > 2.5Ïƒ (36,005 obs)\n",
      "\n",
      "--- 3.2 Types de rÃ©sidus extrÃªmes ---\n",
      "  Faux nÃ©gatifs (Y=1, P<0.2) : 19,332\n",
      "  Faux positifs (Y=0, P>0.3) : 244\n",
      "\n",
      "--- 3.3 RÃ©partition gÃ©ographique ---\n",
      "\n",
      "  Dept          N   Trans.   %Trans    Extr.    %Extr\n",
      "  -------------------------------------------------------\n",
      "  57        98869    21377    21.6%    15315   15.49%\n",
      "  68        73587    10348    14.1%     8959   12.17%\n",
      "  54        64924     6286     9.7%     5537    8.53%\n",
      "  55        14885      707     4.7%      690    4.64%\n",
      "  67       118398     5389     4.6%     5347    4.52%\n",
      "  88        29098       66     0.2%       66    0.23%\n",
      "  52        14249       18     0.1%       18    0.13%\n",
      "  10        27234       33     0.1%       33    0.12%\n",
      "  51        53239       40     0.1%       40    0.08%\n",
      "\n",
      "--- 3.4 Profil des rÃ©sidus extrÃªmes ---\n",
      "\n",
      "  Variable         Pop. totale        ExtrÃªmes       Diff\n",
      "  -------------------------------------------------------\n",
      "  AGEREV                41.479          41.933     +0.454\n",
      "  SEXE_2                 0.481           0.409     -0.072\n",
      "\n",
      "  Taux transfrontaliers :\n",
      "    - Population totale : 8.95%\n",
      "    - RÃ©sidus extrÃªmes  : 99.32%\n",
      "\n",
      "--- 3.5 Recommandation ---\n",
      "  âš ï¸ Taux d'extrÃªmes Ã©levÃ© (>5%). Investiguer les causes, ne PAS supprimer sans justification.\n",
      "\n",
      "  IMPORTANT : Les rÃ©sidus extrÃªmes ne doivent PAS Ãªtre supprimÃ©s automatiquement.\n",
      "  Ce sont de vraies observations qui reflÃ¨tent l'hÃ©tÃ©rogÃ©nÃ©itÃ© de la population.\n",
      "  Leur suppression biaiserait les rÃ©sultats.\n",
      "\n",
      "================================================================================\n",
      "TEST 4 : RATIO LOGIT/PROBIT - CHANGEMENT DE RÃ‰FÃ‰RENCE\n",
      "================================================================================\n",
      "\n",
      "--- 4.1 ModÃ¨le initial (rÃ©f = DEPT_51, Marne) ---\n",
      "\n",
      "  Variable         Probit      Logit      Ratio\n",
      "  ---------------------------------------------\n",
      "  DEPT_10          0.1043     0.3677      3.526\n",
      "  DEPT_52          0.1197     0.4486      3.748\n",
      "  DEPT_54          1.9401     4.8657      2.508\n",
      "  DEPT_55          1.5232     4.0744      2.675\n",
      "  DEPT_57          2.4367     5.7580      2.363\n",
      "  DEPT_67          1.4722     3.9363      2.674\n",
      "  DEPT_68          2.0908     5.1525      2.464\n",
      "  DEPT_88          0.2933     0.9789      3.337\n",
      "\n",
      "  Ratio moyen (DEPT) : 2.912\n",
      "\n",
      "--- 4.2 Reconstruction avec DEPT_67 (Bas-Rhin) comme rÃ©fÃ©rence ---\n",
      "  Nouvelles dummies DEPT : ['DEPT_10', 'DEPT_51', 'DEPT_52', 'DEPT_54', 'DEPT_55']...\n",
      "\n",
      "--- 4.3 Estimation avec DEPT_67 comme rÃ©fÃ©rence ---\n",
      "\n",
      "  Variable         Probit      Logit      Ratio\n",
      "  ---------------------------------------------\n",
      "  DEPT_10         -1.3680    -3.5686      2.609\n",
      "  DEPT_51         -1.4722    -3.9363      2.674\n",
      "  DEPT_52         -1.3526    -3.4878      2.579\n",
      "  DEPT_54          0.4678     0.9294      1.986\n",
      "  DEPT_55          0.0509     0.1380      2.710\n",
      "  DEPT_57          0.9644     1.8217      1.889\n",
      "  DEPT_68          0.6185     1.2161      1.966\n",
      "  DEPT_88         -1.1789    -2.9575      2.509\n",
      "\n",
      "--- 4.4 Comparaison ---\n",
      "\n",
      "  RÃ©fÃ©rence                Ratio moyen\n",
      "  ----------------------------------------\n",
      "  DEPT_51 (Marne)                2.912\n",
      "  DEPT_67 (Bas-Rhin)             2.365\n",
      "  ThÃ©orique                       ~1.6\n",
      "\n",
      "--- 4.5 InterprÃ©tation ---\n",
      "\n",
      "  âœ… HYPOTHÃˆSE CONFIRMÃ‰E : Le ratio se rapproche de 1.6 avec la nouvelle rÃ©fÃ©rence.\n",
      "  \n",
      "  Explication : Avec DEPT_51 (non frontalier) comme rÃ©fÃ©rence, les coefficients\n",
      "  des dÃ©partements frontaliers (57, 68) Ã©taient trÃ¨s Ã©levÃ©s (~2.5), car ils \n",
      "  captent TOUT l'Ã©cart avec un dÃ©partement sans frontiÃ¨re.\n",
      "  \n",
      "  Ces coefficients extrÃªmes amplifient la diffÃ©rence entre les fonctions \n",
      "  logistique et normale dans les queues de distribution, d'oÃ¹ un ratio > 1.6.\n",
      "  \n",
      "  Avec DEPT_67 comme rÃ©fÃ©rence (frontalier), les coefficients sont plus modÃ©rÃ©s\n",
      "  et le ratio revient vers sa valeur thÃ©orique.\n",
      "  \n",
      "  â†’ Ce n'est PAS un problÃ¨me du modÃ¨le, c'est une consÃ©quence du design \n",
      "    (catÃ©gorie de rÃ©fÃ©rence non frontaliÃ¨re).\n",
      "  â†’ Le modÃ¨le avec DEPT_51 comme rÃ©fÃ©rence reste valide et prÃ©fÃ©rable pour\n",
      "    l'interprÃ©tation Ã©conomique (effet frontiÃ¨re direct).\n",
      "\n",
      "================================================================================\n",
      "TEST 5 : PROBIT VS LOGIT (EFFETS MARGINAUX)\n",
      "================================================================================\n",
      "\n",
      "  CorrÃ©lation effets marginaux : 0.995254\n",
      "  DiffÃ©rence moyenne absolue   : 0.005267\n",
      "\n",
      "  âœ“ Probit et Logit trÃ¨s similaires\n",
      "\n",
      "âœ“ Rapport sauvegardÃ© : /Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready/Robustesse_v3/rapport_robustesse_v3.txt\n",
      "\n",
      "================================================================================\n",
      "TESTS DE ROBUSTESSE V3 TERMINÃ‰S\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "TESTS DE ROBUSTESSE  - MODÃˆLE PROBIT TRANSFRONTALIER\n",
    "================================================================================\n",
    "Version adaptÃ©e pour grands Ã©chantillons (n = 494k)\n",
    "\n",
    "MODIFICATIONS PAR RAPPORT Ã€ V2 :\n",
    "1. Remplacement HL/Link Test â†’ Brier Score, Calibration, AUC bootstrap\n",
    "2. CaractÃ©risation des rÃ©sidus extrÃªmes (profil, dÃ©partement)\n",
    "3. Test ratio Logit/Probit avec DEPT_67 comme rÃ©fÃ©rence\n",
    "\n",
    "CatÃ©gorie de rÃ©fÃ©rence initiale : DEPT_51 (Marne) - non frontalier\n",
    "Test alternatif : DEPT_67 (Bas-Rhin) comme rÃ©fÃ©rence - frontalier\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2\n",
    "from sklearn.metrics import brier_score_loss, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "X_PATH = \"/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready/BDD_PROBIT.csv\"\n",
    "Y_PATH = \"/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready/y_final.csv\"\n",
    "OUTPUT_DIR = \"/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready/Robustesse_v3\"\n",
    "\n",
    "\n",
    "def load_data(x_path, y_path):\n",
    "    \"\"\"Charge les donnÃ©es X et Y\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"CHARGEMENT DES DONNÃ‰ES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    X = pd.read_csv(x_path)\n",
    "    print(f\"\\nâœ“ X chargÃ© : {X.shape[0]:,} obs Ã— {X.shape[1]} variables\")\n",
    "    \n",
    "    Y_df = pd.read_csv(y_path)\n",
    "    y_col = Y_df.columns[0]\n",
    "    Y = Y_df[y_col].values\n",
    "    \n",
    "    n_transfront = Y.sum()\n",
    "    pct_transfront = 100 * n_transfront / len(Y)\n",
    "    print(f\"âœ“ Transfrontaliers (Y=1) : {n_transfront:,} ({pct_transfront:.2f}%)\")\n",
    "    \n",
    "    X_with_const = sm.add_constant(X, has_constant='add')\n",
    "    \n",
    "    return X, X_with_const, Y\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 1 : MODÃˆLE DE BASE\n",
    "# ============================================================================\n",
    "def test_1_baseline_probit(X, Y, report_lines):\n",
    "    \"\"\"Estimation du modÃ¨le probit de base\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 1 : MODÃˆLE PROBIT DE BASE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 1 : MODÃˆLE PROBIT DE BASE\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    model = sm.Probit(Y, X)\n",
    "    result = model.fit(disp=0, maxiter=100)\n",
    "    \n",
    "    print(f\"\\nâœ“ Convergence : {'Oui' if result.mle_retvals['converged'] else 'Non'}\")\n",
    "    print(f\"âœ“ Log-L       : {result.llf:,.2f}\")\n",
    "    print(f\"âœ“ Pseudo RÂ²   : {result.prsquared:.4f}\")\n",
    "    \n",
    "    report_lines.append(f\"\\nConvergence : {'Oui' if result.mle_retvals['converged'] else 'Non'}\")\n",
    "    report_lines.append(f\"Log-L       : {result.llf:,.2f}\")\n",
    "    report_lines.append(f\"Pseudo RÂ²   : {result.prsquared:.4f}\")\n",
    "    \n",
    "    # Coefficients clÃ©s\n",
    "    print(\"\\n--- Coefficients clÃ©s ---\")\n",
    "    report_lines.append(\"\\n--- Coefficients clÃ©s ---\")\n",
    "    \n",
    "    key_vars = ['DEPT_57', 'DEPT_68', 'DEPT_54', 'DEPT_67', 'SEXE_2', 'AGEREV', 'AGEREV_sq']\n",
    "    for var in key_vars:\n",
    "        if var in result.params.index:\n",
    "            coef = result.params[var]\n",
    "            se = result.bse[var]\n",
    "            ci_low = coef - 1.96 * se\n",
    "            ci_high = coef + 1.96 * se\n",
    "            print(f\"  {var:<12} : {coef:>8.4f} [IC95: {ci_low:.3f} ; {ci_high:.3f}]\")\n",
    "            report_lines.append(f\"  {var:<12} : {coef:>8.4f} [IC95: {ci_low:.3f} ; {ci_high:.3f}]\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 2 : DIAGNOSTICS ADAPTÃ‰S AUX GRANDS Ã‰CHANTILLONS\n",
    "# ============================================================================\n",
    "def test_2_diagnostics_grands_echantillons(X, Y, baseline_result, report_lines):\n",
    "    \"\"\"\n",
    "    Diagnostics adaptÃ©s aux grands Ã©chantillons\n",
    "    Remplace Hosmer-Lemeshow et Link Test\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 2 : DIAGNOSTICS GRANDS Ã‰CHANTILLONS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 2 : DIAGNOSTICS GRANDS Ã‰CHANTILLONS\")\n",
    "    report_lines.append(\"(Remplace HL et Link Test, inadaptÃ©s pour n > 100k)\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    y_pred = baseline_result.predict()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2.1 BRIER SCORE\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 2.1 Brier Score ---\")\n",
    "    report_lines.append(\"\\n--- 2.1 Brier Score ---\")\n",
    "    \n",
    "    brier = brier_score_loss(Y, y_pred)\n",
    "    # Brier max pour cette prÃ©valence (benchmark naÃ¯f)\n",
    "    prevalence = Y.mean()\n",
    "    brier_null = prevalence * (1 - prevalence)  # PrÃ©dire toujours la moyenne\n",
    "    brier_skill = 1 - (brier / brier_null)\n",
    "    \n",
    "    print(f\"  Brier Score      : {brier:.4f}\")\n",
    "    print(f\"  Brier (null)     : {brier_null:.4f}\")\n",
    "    print(f\"  Brier Skill Score: {brier_skill:.4f}\")\n",
    "    \n",
    "    report_lines.append(f\"  Brier Score      : {brier:.4f} (plus proche de 0 = meilleur)\")\n",
    "    report_lines.append(f\"  Brier null       : {brier_null:.4f} (si on prÃ©dit toujours PÌ„)\")\n",
    "    report_lines.append(f\"  Brier Skill      : {brier_skill:.4f} (amÃ©lioration vs null, >0 = bon)\")\n",
    "    \n",
    "    if brier_skill > 0.2:\n",
    "        print(\"  âœ… Bon pouvoir prÃ©dictif (skill > 0.2)\")\n",
    "        report_lines.append(\"  âœ… Bon pouvoir prÃ©dictif\")\n",
    "    elif brier_skill > 0:\n",
    "        print(\"  âœ“ Pouvoir prÃ©dictif modeste mais positif\")\n",
    "        report_lines.append(\"  âœ“ Pouvoir prÃ©dictif modeste\")\n",
    "    else:\n",
    "        print(\"  âš ï¸ ModÃ¨le moins bon que prÃ©diction naÃ¯ve\")\n",
    "        report_lines.append(\"  âš ï¸ ProblÃ¨me de prÃ©diction\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2.2 COURBE DE CALIBRATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 2.2 Calibration par dÃ©ciles ---\")\n",
    "    report_lines.append(\"\\n--- 2.2 Calibration par dÃ©ciles ---\")\n",
    "    \n",
    "    df_calib = pd.DataFrame({'y': Y, 'pred': y_pred})\n",
    "    df_calib['decile'] = pd.qcut(df_calib['pred'], 10, labels=False, duplicates='drop')\n",
    "    \n",
    "    calib_table = df_calib.groupby('decile').agg({\n",
    "        'y': ['mean', 'count'],\n",
    "        'pred': 'mean'\n",
    "    }).round(4)\n",
    "    calib_table.columns = ['Obs_rate', 'N', 'Pred_rate']\n",
    "    calib_table['Ã‰cart'] = calib_table['Obs_rate'] - calib_table['Pred_rate']\n",
    "    calib_table['Ã‰cart_pct'] = 100 * calib_table['Ã‰cart'] / calib_table['Pred_rate']\n",
    "    \n",
    "    print(f\"\\n  {'DÃ©cile':<8} {'N':>8} {'PrÃ©dit':>10} {'ObservÃ©':>10} {'Ã‰cart':>10}\")\n",
    "    print(\"  \" + \"-\" * 50)\n",
    "    report_lines.append(f\"\\n  {'DÃ©cile':<8} {'N':>8} {'PrÃ©dit':>10} {'ObservÃ©':>10} {'Ã‰cart':>10}\")\n",
    "    report_lines.append(\"  \" + \"-\" * 50)\n",
    "    \n",
    "    for idx, row in calib_table.iterrows():\n",
    "        line = f\"  {idx:<8} {int(row['N']):>8} {row['Pred_rate']:>10.4f} {row['Obs_rate']:>10.4f} {row['Ã‰cart']:>+10.4f}\"\n",
    "        print(line)\n",
    "        report_lines.append(line)\n",
    "    \n",
    "    # Ã‰cart moyen absolu de calibration\n",
    "    mae_calib = calib_table['Ã‰cart'].abs().mean()\n",
    "    print(f\"\\n  Ã‰cart moyen absolu de calibration : {mae_calib:.4f}\")\n",
    "    report_lines.append(f\"\\n  Ã‰cart moyen absolu de calibration : {mae_calib:.4f}\")\n",
    "    \n",
    "    if mae_calib < 0.02:\n",
    "        print(\"  âœ… Excellente calibration\")\n",
    "        report_lines.append(\"  âœ… Excellente calibration (Ã©cart < 2pp)\")\n",
    "    elif mae_calib < 0.05:\n",
    "        print(\"  âœ“ Calibration acceptable\")\n",
    "        report_lines.append(\"  âœ“ Calibration acceptable (Ã©cart < 5pp)\")\n",
    "    else:\n",
    "        print(\"  âš ï¸ Calibration Ã  amÃ©liorer\")\n",
    "        report_lines.append(\"  âš ï¸ Calibration perfectible\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2.3 AUC-ROC AVEC INTERVALLE DE CONFIANCE BOOTSTRAP\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 2.3 AUC-ROC avec IC Bootstrap ---\")\n",
    "    report_lines.append(\"\\n--- 2.3 AUC-ROC avec IC Bootstrap ---\")\n",
    "    \n",
    "    auc_point = roc_auc_score(Y, y_pred)\n",
    "    print(f\"  AUC point estimate : {auc_point:.4f}\")\n",
    "    \n",
    "    # Bootstrap pour IC (100 itÃ©rations pour rapiditÃ©)\n",
    "    n_bootstrap = 100\n",
    "    np.random.seed(42)\n",
    "    auc_boots = []\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = np.random.choice(len(Y), size=len(Y), replace=True)\n",
    "        y_boot = Y[idx]\n",
    "        pred_boot = y_pred[idx]\n",
    "        if len(np.unique(y_boot)) == 2:  # VÃ©rifier qu'on a les deux classes\n",
    "            auc_boots.append(roc_auc_score(y_boot, pred_boot))\n",
    "    \n",
    "    auc_ci_low = np.percentile(auc_boots, 2.5)\n",
    "    auc_ci_high = np.percentile(auc_boots, 97.5)\n",
    "    \n",
    "    print(f\"  AUC IC 95%         : [{auc_ci_low:.4f} ; {auc_ci_high:.4f}]\")\n",
    "    report_lines.append(f\"  AUC point estimate : {auc_point:.4f}\")\n",
    "    report_lines.append(f\"  AUC IC 95%         : [{auc_ci_low:.4f} ; {auc_ci_high:.4f}]\")\n",
    "    \n",
    "    if auc_point > 0.8:\n",
    "        print(\"  âœ… Excellente discrimination (AUC > 0.8)\")\n",
    "        report_lines.append(\"  âœ… Excellente discrimination\")\n",
    "    elif auc_point > 0.7:\n",
    "        print(\"  âœ“ Bonne discrimination (AUC > 0.7)\")\n",
    "        report_lines.append(\"  âœ“ Bonne discrimination\")\n",
    "    else:\n",
    "        print(\"  âš ï¸ Discrimination modeste\")\n",
    "        report_lines.append(\"  âš ï¸ Discrimination modeste\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2.4 VALIDATION CROISÃ‰E 5-FOLD\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 2.4 Validation croisÃ©e 5-fold ---\")\n",
    "    report_lines.append(\"\\n--- 2.4 Validation croisÃ©e 5-fold ---\")\n",
    "    \n",
    "    # Utiliser sklearn LogisticRegression comme proxy (plus rapide)\n",
    "    # C=1e10 pour pas de rÃ©gularisation\n",
    "    X_np = X.values if hasattr(X, 'values') else X\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # AUC par fold\n",
    "    auc_folds = []\n",
    "    brier_folds = []\n",
    "    \n",
    "    for train_idx, test_idx in cv.split(X_np, Y):\n",
    "        X_train, X_test = X_np[train_idx], X_np[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        \n",
    "        lr = LogisticRegression(C=1e10, max_iter=1000, solver='lbfgs')\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_pred_fold = lr.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        auc_folds.append(roc_auc_score(y_test, y_pred_fold))\n",
    "        brier_folds.append(brier_score_loss(y_test, y_pred_fold))\n",
    "    \n",
    "    print(f\"  AUC moyen (5-fold)   : {np.mean(auc_folds):.4f} Â± {np.std(auc_folds):.4f}\")\n",
    "    print(f\"  Brier moyen (5-fold) : {np.mean(brier_folds):.4f} Â± {np.std(brier_folds):.4f}\")\n",
    "    \n",
    "    report_lines.append(f\"  AUC moyen (5-fold)   : {np.mean(auc_folds):.4f} Â± {np.std(auc_folds):.4f}\")\n",
    "    report_lines.append(f\"  Brier moyen (5-fold) : {np.mean(brier_folds):.4f} Â± {np.std(brier_folds):.4f}\")\n",
    "    \n",
    "    # StabilitÃ©\n",
    "    cv_stability = np.std(auc_folds) / np.mean(auc_folds)\n",
    "    if cv_stability < 0.02:\n",
    "        print(\"  âœ… TrÃ¨s stable entre folds (CV < 2%)\")\n",
    "        report_lines.append(\"  âœ… TrÃ¨s stable entre folds\")\n",
    "    elif cv_stability < 0.05:\n",
    "        print(\"  âœ“ Stable entre folds\")\n",
    "        report_lines.append(\"  âœ“ Stable entre folds\")\n",
    "    else:\n",
    "        print(\"  âš ï¸ VariabilitÃ© entre folds\")\n",
    "        report_lines.append(\"  âš ï¸ VariabilitÃ© entre folds\")\n",
    "    \n",
    "    return {\n",
    "        'brier': brier,\n",
    "        'brier_skill': brier_skill,\n",
    "        'mae_calib': mae_calib,\n",
    "        'auc': auc_point,\n",
    "        'auc_ci': (auc_ci_low, auc_ci_high),\n",
    "        'auc_cv': np.mean(auc_folds),\n",
    "        'calib_table': calib_table\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 3 : CARACTÃ‰RISATION DES RÃ‰SIDUS EXTRÃŠMES\n",
    "# ============================================================================\n",
    "def test_3_residus_extremes(X_df, Y, baseline_result, report_lines):\n",
    "    \"\"\"\n",
    "    Analyse et caractÃ©risation des rÃ©sidus extrÃªmes\n",
    "    Objectif : comprendre qui sont les individus mal prÃ©dits\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 3 : CARACTÃ‰RISATION DES RÃ‰SIDUS EXTRÃŠMES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 3 : CARACTÃ‰RISATION DES RÃ‰SIDUS EXTRÃŠMES\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    y_pred = baseline_result.predict()\n",
    "    \n",
    "    # Calcul des rÃ©sidus de Pearson\n",
    "    residuals_pearson = (Y - y_pred) / np.sqrt(y_pred * (1 - y_pred))\n",
    "    \n",
    "    # RÃ©sidus standardisÃ©s\n",
    "    residuals_raw = Y - y_pred\n",
    "    std_res = (residuals_raw - residuals_raw.mean()) / residuals_raw.std()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3.1 DISTRIBUTION DES RÃ‰SIDUS\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 3.1 Distribution des rÃ©sidus ---\")\n",
    "    report_lines.append(\"\\n--- 3.1 Distribution des rÃ©sidus ---\")\n",
    "    \n",
    "    # Seuils pour dÃ©finir \"extrÃªme\"\n",
    "    seuils = [2, 2.5, 3]\n",
    "    for seuil in seuils:\n",
    "        n_extreme = (np.abs(std_res) > seuil).sum()\n",
    "        pct_extreme = 100 * n_extreme / len(Y)\n",
    "        print(f\"  |rÃ©sidu| > {seuil}Ïƒ : {n_extreme:,} obs ({pct_extreme:.2f}%)\")\n",
    "        report_lines.append(f\"  |rÃ©sidu| > {seuil}Ïƒ : {n_extreme:,} obs ({pct_extreme:.2f}%)\")\n",
    "    \n",
    "    # Utiliser seuil = 2.5 pour l'analyse (compromis)\n",
    "    seuil_analyse = 2.5\n",
    "    mask_extreme = np.abs(std_res) > seuil_analyse\n",
    "    n_extreme = mask_extreme.sum()\n",
    "    \n",
    "    print(f\"\\n  â†’ Analyse dÃ©taillÃ©e pour |rÃ©sidu| > {seuil_analyse}Ïƒ ({n_extreme:,} obs)\")\n",
    "    report_lines.append(f\"\\n  â†’ Analyse avec seuil {seuil_analyse}Ïƒ : {n_extreme:,} obs\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3.2 TYPES DE RÃ‰SIDUS EXTRÃŠMES\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 3.2 Types de rÃ©sidus extrÃªmes ---\")\n",
    "    report_lines.append(\"\\n--- 3.2 Types de rÃ©sidus extrÃªmes ---\")\n",
    "    \n",
    "    # Faux nÃ©gatifs : Y=1 mais P(Y=1) faible\n",
    "    mask_fn = (Y == 1) & (y_pred < 0.2) & mask_extreme\n",
    "    n_fn = mask_fn.sum()\n",
    "    \n",
    "    # Faux positifs : Y=0 mais P(Y=1) Ã©levÃ©e\n",
    "    mask_fp = (Y == 0) & (y_pred > 0.3) & mask_extreme\n",
    "    n_fp = mask_fp.sum()\n",
    "    \n",
    "    print(f\"  Faux nÃ©gatifs (Y=1, P<0.2) : {n_fn:,}\")\n",
    "    print(f\"  Faux positifs (Y=0, P>0.3) : {n_fp:,}\")\n",
    "    \n",
    "    report_lines.append(f\"  Faux nÃ©gatifs (transfrontaliers non prÃ©dits) : {n_fn:,}\")\n",
    "    report_lines.append(f\"  Faux positifs (non-transfront. prÃ©dits transfr.) : {n_fp:,}\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3.3 RÃ‰PARTITION PAR DÃ‰PARTEMENT\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 3.3 RÃ©partition gÃ©ographique ---\")\n",
    "    report_lines.append(\"\\n--- 3.3 RÃ©partition gÃ©ographique ---\")\n",
    "    \n",
    "    dept_cols = [c for c in X_df.columns if c.startswith('DEPT_')]\n",
    "    \n",
    "    if dept_cols:\n",
    "        # Reconstruire le dÃ©partement\n",
    "        dept_df = X_df[dept_cols].copy()\n",
    "        # Identifier le dÃ©partement de chaque individu\n",
    "        # Celui qui vaut 1, sinon c'est la rÃ©fÃ©rence (51)\n",
    "        def get_dept(row):\n",
    "            for col in dept_cols:\n",
    "                if row[col] == 1:\n",
    "                    return col.replace('DEPT_', '')\n",
    "            return '51'  # RÃ©fÃ©rence\n",
    "        \n",
    "        dept_series = dept_df.apply(get_dept, axis=1)\n",
    "        \n",
    "        # CrÃ©er un DataFrame pour l'analyse\n",
    "        df_analyse = pd.DataFrame({\n",
    "            'dept': dept_series,\n",
    "            'Y': Y,\n",
    "            'pred': y_pred,\n",
    "            'extreme': mask_extreme\n",
    "        })\n",
    "        \n",
    "        # Statistiques par dÃ©partement\n",
    "        dept_stats = df_analyse.groupby('dept').agg({\n",
    "            'Y': ['sum', 'count', 'mean'],\n",
    "            'extreme': 'sum'\n",
    "        })\n",
    "        dept_stats.columns = ['n_transfront', 'n_total', 'taux_transfront', 'n_extreme']\n",
    "        dept_stats['pct_extreme'] = 100 * dept_stats['n_extreme'] / dept_stats['n_total']\n",
    "        dept_stats = dept_stats.sort_values('pct_extreme', ascending=False)\n",
    "        \n",
    "        print(f\"\\n  {'Dept':<6} {'N':>8} {'Trans.':>8} {'%Trans':>8} {'Extr.':>8} {'%Extr':>8}\")\n",
    "        print(\"  \" + \"-\" * 55)\n",
    "        report_lines.append(f\"\\n  {'Dept':<6} {'N':>8} {'Trans.':>8} {'%Trans':>8} {'Extr.':>8} {'%Extr':>8}\")\n",
    "        report_lines.append(\"  \" + \"-\" * 55)\n",
    "        \n",
    "        for dept, row in dept_stats.head(10).iterrows():\n",
    "            line = f\"  {dept:<6} {int(row['n_total']):>8} {int(row['n_transfront']):>8} {100*row['taux_transfront']:>7.1f}% {int(row['n_extreme']):>8} {row['pct_extreme']:>7.2f}%\"\n",
    "            print(line)\n",
    "            report_lines.append(line)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3.4 PROFIL DES RÃ‰SIDUS EXTRÃŠMES VS POPULATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 3.4 Profil des rÃ©sidus extrÃªmes ---\")\n",
    "    report_lines.append(\"\\n--- 3.4 Profil des rÃ©sidus extrÃªmes ---\")\n",
    "    \n",
    "    # Comparer quelques variables clÃ©s\n",
    "    vars_profil = ['AGEREV', 'SEXE_2']\n",
    "    vars_profil = [v for v in vars_profil if v in X_df.columns]\n",
    "    \n",
    "    if vars_profil:\n",
    "        print(f\"\\n  {'Variable':<12} {'Pop. totale':>15} {'ExtrÃªmes':>15} {'Diff':>10}\")\n",
    "        print(\"  \" + \"-\" * 55)\n",
    "        report_lines.append(f\"\\n  {'Variable':<12} {'Pop. totale':>15} {'ExtrÃªmes':>15} {'Diff':>10}\")\n",
    "        report_lines.append(\"  \" + \"-\" * 55)\n",
    "        \n",
    "        for var in vars_profil:\n",
    "            mean_all = X_df[var].mean()\n",
    "            mean_extreme = X_df.loc[mask_extreme, var].mean()\n",
    "            diff = mean_extreme - mean_all\n",
    "            \n",
    "            line = f\"  {var:<12} {mean_all:>15.3f} {mean_extreme:>15.3f} {diff:>+10.3f}\"\n",
    "            print(line)\n",
    "            report_lines.append(line)\n",
    "    \n",
    "    # Taux de transfrontaliers parmi les extrÃªmes\n",
    "    taux_transfront_extreme = Y[mask_extreme].mean()\n",
    "    taux_transfront_total = Y.mean()\n",
    "    \n",
    "    print(f\"\\n  Taux transfrontaliers :\")\n",
    "    print(f\"    - Population totale : {100*taux_transfront_total:.2f}%\")\n",
    "    print(f\"    - RÃ©sidus extrÃªmes  : {100*taux_transfront_extreme:.2f}%\")\n",
    "    \n",
    "    report_lines.append(f\"\\n  Taux transfrontaliers :\")\n",
    "    report_lines.append(f\"    - Population totale : {100*taux_transfront_total:.2f}%\")\n",
    "    report_lines.append(f\"    - RÃ©sidus extrÃªmes  : {100*taux_transfront_extreme:.2f}%\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3.5 RECOMMANDATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 3.5 Recommandation ---\")\n",
    "    report_lines.append(\"\\n--- 3.5 Recommandation ---\")\n",
    "    \n",
    "    pct_extreme = 100 * n_extreme / len(Y)\n",
    "    \n",
    "    if pct_extreme < 3:\n",
    "        rec = \"âœ… Taux d'extrÃªmes acceptable (<3%). Pas d'action requise.\"\n",
    "    elif pct_extreme < 5:\n",
    "        rec = \"âœ“ Taux d'extrÃªmes modÃ©rÃ© (3-5%). Mentionner dans le rapport, pas de suppression.\"\n",
    "    else:\n",
    "        rec = \"âš ï¸ Taux d'extrÃªmes Ã©levÃ© (>5%). Investiguer les causes, ne PAS supprimer sans justification.\"\n",
    "    \n",
    "    print(f\"  {rec}\")\n",
    "    report_lines.append(f\"  {rec}\")\n",
    "    \n",
    "    # Ne PAS recommander de supprimer sauf erreur de donnÃ©es avÃ©rÃ©e\n",
    "    print(\"\\n  IMPORTANT : Les rÃ©sidus extrÃªmes ne doivent PAS Ãªtre supprimÃ©s automatiquement.\")\n",
    "    print(\"  Ce sont de vraies observations qui reflÃ¨tent l'hÃ©tÃ©rogÃ©nÃ©itÃ© de la population.\")\n",
    "    print(\"  Leur suppression biaiserait les rÃ©sultats.\")\n",
    "    \n",
    "    report_lines.append(\"\\n  IMPORTANT : Ne pas supprimer les rÃ©sidus extrÃªmes sans justification.\")\n",
    "    report_lines.append(\"  Ils reflÃ¨tent l'hÃ©tÃ©rogÃ©nÃ©itÃ© naturelle de la population.\")\n",
    "    \n",
    "    return {\n",
    "        'n_extreme': n_extreme,\n",
    "        'pct_extreme': pct_extreme,\n",
    "        'mask_extreme': mask_extreme\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 4 : RATIO LOGIT/PROBIT AVEC CHANGEMENT DE RÃ‰FÃ‰RENCE\n",
    "# ============================================================================\n",
    "def test_4_ratio_reference_alternative(X_df, Y, report_lines):\n",
    "    \"\"\"\n",
    "    Test du ratio Logit/Probit en changeant la catÃ©gorie de rÃ©fÃ©rence\n",
    "    - Initial : DEPT_51 (Marne) comme rÃ©fÃ©rence\n",
    "    - Alternative : DEPT_67 (Bas-Rhin) comme rÃ©fÃ©rence\n",
    "    \n",
    "    HypothÃ¨se : le ratio anormal (~2.05 au lieu de ~1.6) vient des coefficients\n",
    "    extrÃªmes des dÃ©partements frontaliers par rapport Ã  la Marne.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 4 : RATIO LOGIT/PROBIT - CHANGEMENT DE RÃ‰FÃ‰RENCE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 4 : RATIO LOGIT/PROBIT - CHANGEMENT DE RÃ‰FÃ‰RENCE\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4.1 MODÃˆLE INITIAL (rÃ©fÃ©rence = DEPT_51)\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 4.1 ModÃ¨le initial (rÃ©f = DEPT_51, Marne) ---\")\n",
    "    report_lines.append(\"\\n--- 4.1 ModÃ¨le initial (rÃ©f = DEPT_51, Marne) ---\")\n",
    "    \n",
    "    X_init = sm.add_constant(X_df)\n",
    "    \n",
    "    # Probit\n",
    "    model_probit_init = sm.Probit(Y, X_init)\n",
    "    result_probit_init = model_probit_init.fit(disp=0)\n",
    "    \n",
    "    # Logit\n",
    "    model_logit_init = sm.Logit(Y, X_init)\n",
    "    result_logit_init = model_logit_init.fit(disp=0)\n",
    "    \n",
    "    # Ratio pour les variables DEPT\n",
    "    dept_vars = [c for c in X_df.columns if c.startswith('DEPT_')]\n",
    "    \n",
    "    print(f\"\\n  {'Variable':<12} {'Probit':>10} {'Logit':>10} {'Ratio':>10}\")\n",
    "    print(\"  \" + \"-\" * 45)\n",
    "    report_lines.append(f\"\\n  {'Variable':<12} {'Probit':>10} {'Logit':>10} {'Ratio':>10}\")\n",
    "    report_lines.append(\"  \" + \"-\" * 45)\n",
    "    \n",
    "    ratios_init = []\n",
    "    for var in dept_vars:\n",
    "        if var in result_probit_init.params.index:\n",
    "            coef_p = result_probit_init.params[var]\n",
    "            coef_l = result_logit_init.params[var]\n",
    "            if abs(coef_p) > 0.01:  # Ã‰viter division par zÃ©ro\n",
    "                ratio = coef_l / coef_p\n",
    "                ratios_init.append(ratio)\n",
    "                line = f\"  {var:<12} {coef_p:>10.4f} {coef_l:>10.4f} {ratio:>10.3f}\"\n",
    "                print(line)\n",
    "                report_lines.append(line)\n",
    "    \n",
    "    ratio_mean_init = np.mean(ratios_init) if ratios_init else np.nan\n",
    "    print(f\"\\n  Ratio moyen (DEPT) : {ratio_mean_init:.3f}\")\n",
    "    report_lines.append(f\"\\n  Ratio moyen (DEPT) : {ratio_mean_init:.3f}\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4.2 CRÃ‰ER NOUVELLE MATRICE AVEC DEPT_67 COMME RÃ‰FÃ‰RENCE\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 4.2 Reconstruction avec DEPT_67 (Bas-Rhin) comme rÃ©fÃ©rence ---\")\n",
    "    report_lines.append(\"\\n--- 4.2 Reconstruction avec DEPT_67 comme rÃ©fÃ©rence ---\")\n",
    "    \n",
    "    # Identifier tous les dÃ©partements prÃ©sents\n",
    "    dept_cols_present = [c for c in X_df.columns if c.startswith('DEPT_')]\n",
    "    \n",
    "    if 'DEPT_67' not in dept_cols_present:\n",
    "        print(\"  âš ï¸ DEPT_67 non trouvÃ© dans les donnÃ©es\")\n",
    "        report_lines.append(\"  âš ï¸ DEPT_67 non trouvÃ©\")\n",
    "        return None\n",
    "    \n",
    "    # CrÃ©er la nouvelle matrice\n",
    "    X_new = X_df.copy()\n",
    "    \n",
    "    # RÃ©cupÃ©rer qui est dans le 67\n",
    "    is_67 = X_new['DEPT_67'] == 1\n",
    "    \n",
    "    # Supprimer DEPT_67 (devient la nouvelle rÃ©fÃ©rence)\n",
    "    X_new = X_new.drop(columns=['DEPT_67'])\n",
    "    \n",
    "    # Ajouter DEPT_51 (Ã©tait la rÃ©fÃ©rence, maintenant explicite)\n",
    "    # DEPT_51 = 1 si aucun autre DEPT n'est Ã  1 (dans la matrice initiale avec 51 comme ref)\n",
    "    dept_cols_other = [c for c in X_new.columns if c.startswith('DEPT_')]\n",
    "    is_51 = X_df[dept_cols_present].sum(axis=1) == 0  # Ceux qui n'ont aucun DEPT Ã  1\n",
    "    X_new['DEPT_51'] = is_51.astype(int)\n",
    "    \n",
    "    # Ajuster pour le 67 : ceux qui Ã©taient 67 ne sont plus dans aucune catÃ©gorie\n",
    "    # (ils deviennent la rÃ©fÃ©rence)\n",
    "    # On doit aussi recoder les autres DEPT pour exclure le 67\n",
    "    # En fait, on doit reconstruire toute la logique...\n",
    "    \n",
    "    # Approche plus simple : reconstruire le dÃ©partement Ã  partir des dummies\n",
    "    def get_dept_from_dummies(row, dept_cols):\n",
    "        for col in dept_cols:\n",
    "            if row[col] == 1:\n",
    "                return col.replace('DEPT_', '')\n",
    "        return '51'  # RÃ©fÃ©rence initiale\n",
    "    \n",
    "    dept_series = X_df[dept_cols_present].apply(lambda row: get_dept_from_dummies(row, dept_cols_present), axis=1)\n",
    "    \n",
    "    # CrÃ©er nouvelles dummies avec 67 comme rÃ©fÃ©rence\n",
    "    # Exclure 67, inclure 51\n",
    "    depts_uniques = dept_series.unique()\n",
    "    depts_a_encoder = [d for d in depts_uniques if d != '67']\n",
    "    \n",
    "    # Supprimer toutes les colonnes DEPT existantes\n",
    "    X_new = X_df.drop(columns=dept_cols_present)\n",
    "    \n",
    "    # Ajouter les nouvelles dummies\n",
    "    for dept in depts_a_encoder:\n",
    "        X_new[f'DEPT_{dept}'] = (dept_series == dept).astype(int)\n",
    "    \n",
    "    print(f\"  Nouvelles dummies DEPT : {[c for c in X_new.columns if c.startswith('DEPT_')][:5]}...\")\n",
    "    report_lines.append(f\"  Nouvelles dummies DEPT crÃ©Ã©es, rÃ©fÃ©rence = 67\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4.3 ESTIMATION AVEC NOUVELLE RÃ‰FÃ‰RENCE\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 4.3 Estimation avec DEPT_67 comme rÃ©fÃ©rence ---\")\n",
    "    report_lines.append(\"\\n--- 4.3 Estimation avec DEPT_67 comme rÃ©fÃ©rence ---\")\n",
    "    \n",
    "    X_new_const = sm.add_constant(X_new)\n",
    "    \n",
    "    # Probit\n",
    "    model_probit_new = sm.Probit(Y, X_new_const)\n",
    "    result_probit_new = model_probit_new.fit(disp=0)\n",
    "    \n",
    "    # Logit\n",
    "    model_logit_new = sm.Logit(Y, X_new_const)\n",
    "    result_logit_new = model_logit_new.fit(disp=0)\n",
    "    \n",
    "    # Ratio pour les variables DEPT\n",
    "    dept_vars_new = [c for c in X_new.columns if c.startswith('DEPT_')]\n",
    "    \n",
    "    print(f\"\\n  {'Variable':<12} {'Probit':>10} {'Logit':>10} {'Ratio':>10}\")\n",
    "    print(\"  \" + \"-\" * 45)\n",
    "    report_lines.append(f\"\\n  {'Variable':<12} {'Probit':>10} {'Logit':>10} {'Ratio':>10}\")\n",
    "    report_lines.append(\"  \" + \"-\" * 45)\n",
    "    \n",
    "    ratios_new = []\n",
    "    for var in sorted(dept_vars_new)[:10]:  # Limiter l'affichage\n",
    "        if var in result_probit_new.params.index:\n",
    "            coef_p = result_probit_new.params[var]\n",
    "            coef_l = result_logit_new.params[var]\n",
    "            if abs(coef_p) > 0.01:\n",
    "                ratio = coef_l / coef_p\n",
    "                ratios_new.append(ratio)\n",
    "                line = f\"  {var:<12} {coef_p:>10.4f} {coef_l:>10.4f} {ratio:>10.3f}\"\n",
    "                print(line)\n",
    "                report_lines.append(line)\n",
    "    \n",
    "    ratio_mean_new = np.mean(ratios_new) if ratios_new else np.nan\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4.4 COMPARAISON DES RATIOS\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 4.4 Comparaison ---\")\n",
    "    report_lines.append(\"\\n--- 4.4 Comparaison ---\")\n",
    "    \n",
    "    print(f\"\\n  {'RÃ©fÃ©rence':<20} {'Ratio moyen':>15}\")\n",
    "    print(\"  \" + \"-\" * 40)\n",
    "    print(f\"  {'DEPT_51 (Marne)':<20} {ratio_mean_init:>15.3f}\")\n",
    "    print(f\"  {'DEPT_67 (Bas-Rhin)':<20} {ratio_mean_new:>15.3f}\")\n",
    "    print(f\"  {'ThÃ©orique':<20} {'~1.6':>15}\")\n",
    "    \n",
    "    report_lines.append(f\"\\n  {'RÃ©fÃ©rence':<20} {'Ratio moyen':>15}\")\n",
    "    report_lines.append(\"  \" + \"-\" * 40)\n",
    "    report_lines.append(f\"  {'DEPT_51 (Marne)':<20} {ratio_mean_init:>15.3f}\")\n",
    "    report_lines.append(f\"  {'DEPT_67 (Bas-Rhin)':<20} {ratio_mean_new:>15.3f}\")\n",
    "    report_lines.append(f\"  {'ThÃ©orique':<20} {'~1.6':>15}\")\n",
    "    \n",
    "    # InterprÃ©tation\n",
    "    print(\"\\n--- 4.5 InterprÃ©tation ---\")\n",
    "    report_lines.append(\"\\n--- 4.5 InterprÃ©tation ---\")\n",
    "    \n",
    "    if abs(ratio_mean_new - 1.6) < abs(ratio_mean_init - 1.6):\n",
    "        conclusion = \"\"\"\n",
    "  âœ… HYPOTHÃˆSE CONFIRMÃ‰E : Le ratio se rapproche de 1.6 avec la nouvelle rÃ©fÃ©rence.\n",
    "  \n",
    "  Explication : Avec DEPT_51 (non frontalier) comme rÃ©fÃ©rence, les coefficients\n",
    "  des dÃ©partements frontaliers (57, 68) Ã©taient trÃ¨s Ã©levÃ©s (~2.5), car ils \n",
    "  captent TOUT l'Ã©cart avec un dÃ©partement sans frontiÃ¨re.\n",
    "  \n",
    "  Ces coefficients extrÃªmes amplifient la diffÃ©rence entre les fonctions \n",
    "  logistique et normale dans les queues de distribution, d'oÃ¹ un ratio > 1.6.\n",
    "  \n",
    "  Avec DEPT_67 comme rÃ©fÃ©rence (frontalier), les coefficients sont plus modÃ©rÃ©s\n",
    "  et le ratio revient vers sa valeur thÃ©orique.\n",
    "  \n",
    "  â†’ Ce n'est PAS un problÃ¨me du modÃ¨le, c'est une consÃ©quence du design \n",
    "    (catÃ©gorie de rÃ©fÃ©rence non frontaliÃ¨re).\n",
    "  â†’ Le modÃ¨le avec DEPT_51 comme rÃ©fÃ©rence reste valide et prÃ©fÃ©rable pour\n",
    "    l'interprÃ©tation Ã©conomique (effet frontiÃ¨re direct).\"\"\"\n",
    "    else:\n",
    "        conclusion = \"\"\"\n",
    "  âš ï¸ HYPOTHÃˆSE NON CONFIRMÃ‰E : Le ratio reste Ã©levÃ© mÃªme avec la nouvelle rÃ©fÃ©rence.\n",
    "  \n",
    "  Causes possibles :\n",
    "  - SÃ©paration quasi-parfaite sur certaines modalitÃ©s\n",
    "  - Non-linÃ©aritÃ©s non captÃ©es\n",
    "  - Ã€ investiguer plus avant\"\"\"\n",
    "    \n",
    "    print(conclusion)\n",
    "    report_lines.append(conclusion)\n",
    "    \n",
    "    return {\n",
    "        'ratio_init': ratio_mean_init,\n",
    "        'ratio_new': ratio_mean_new,\n",
    "        'result_probit_new': result_probit_new,\n",
    "        'result_logit_new': result_logit_new\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 5 : PROBIT VS LOGIT (effets marginaux)\n",
    "# ============================================================================\n",
    "def test_5_probit_vs_logit_mfx(X, Y, report_lines):\n",
    "    \"\"\"Comparaison Probit vs Logit via effets marginaux\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 5 : PROBIT VS LOGIT (EFFETS MARGINAUX)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 5 : PROBIT VS LOGIT (EFFETS MARGINAUX)\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    X_const = sm.add_constant(X)\n",
    "    \n",
    "    # Probit\n",
    "    result_probit = sm.Probit(Y, X_const).fit(disp=0)\n",
    "    mfx_probit = result_probit.get_margeff(at='mean').margeff\n",
    "    \n",
    "    # Logit\n",
    "    result_logit = sm.Logit(Y, X_const).fit(disp=0)\n",
    "    mfx_logit = result_logit.get_margeff(at='mean').margeff\n",
    "    \n",
    "    # CorrÃ©lation\n",
    "    corr_mfx = np.corrcoef(mfx_probit, mfx_logit)[0, 1]\n",
    "    \n",
    "    # DiffÃ©rence moyenne absolue\n",
    "    mae_mfx = np.mean(np.abs(mfx_probit - mfx_logit))\n",
    "    \n",
    "    print(f\"\\n  CorrÃ©lation effets marginaux : {corr_mfx:.6f}\")\n",
    "    print(f\"  DiffÃ©rence moyenne absolue   : {mae_mfx:.6f}\")\n",
    "    \n",
    "    report_lines.append(f\"\\n  CorrÃ©lation effets marginaux : {corr_mfx:.6f}\")\n",
    "    report_lines.append(f\"  DiffÃ©rence moyenne absolue   : {mae_mfx:.6f}\")\n",
    "    \n",
    "    if corr_mfx > 0.999:\n",
    "        print(\"\\n  âœ… Probit et Logit donnent des rÃ©sultats quasi-identiques\")\n",
    "        print(\"     â†’ Le choix du lien n'affecte pas les conclusions\")\n",
    "        report_lines.append(\"\\n  âœ… Choix du lien sans impact sur les conclusions\")\n",
    "    elif corr_mfx > 0.99:\n",
    "        print(\"\\n  âœ“ Probit et Logit trÃ¨s similaires\")\n",
    "        report_lines.append(\"\\n  âœ“ Probit et Logit trÃ¨s similaires\")\n",
    "    else:\n",
    "        print(\"\\n  âš ï¸ DiffÃ©rences notables entre Probit et Logit\")\n",
    "        report_lines.append(\"\\n  âš ï¸ DiffÃ©rences notables\")\n",
    "    \n",
    "    return {\n",
    "        'corr_mfx': corr_mfx,\n",
    "        'mae_mfx': mae_mfx\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# GÃ‰NÃ‰RATION DU RAPPORT\n",
    "# ============================================================================\n",
    "def generate_report(report_lines, output_dir):\n",
    "    \"\"\"GÃ©nÃ¨re le rapport final\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    header = [\n",
    "        \"=\" * 80,\n",
    "        \"RAPPORT DE ROBUSTESSE V3 - MODÃˆLE PROBIT TRANSFRONTALIER\",\n",
    "        f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "        \"=\" * 80,\n",
    "        \"\",\n",
    "        \"AMÃ‰LIORATIONS V3 :\",\n",
    "        \"- Remplacement HL/Link Test â†’ Brier, Calibration, AUC bootstrap\",\n",
    "        \"- CaractÃ©risation des rÃ©sidus extrÃªmes\",\n",
    "        \"- Test ratio avec changement de catÃ©gorie de rÃ©fÃ©rence\",\n",
    "        \"\"\n",
    "    ]\n",
    "    \n",
    "    full_report = header + report_lines\n",
    "    \n",
    "    report_path = os.path.join(output_dir, \"rapport_robustesse_v3.txt\")\n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(full_report))\n",
    "    \n",
    "    print(f\"\\nâœ“ Rapport sauvegardÃ© : {report_path}\")\n",
    "    return report_path\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXÃ‰CUTION PRINCIPALE\n",
    "# ============================================================================\n",
    "def run_all_tests(x_path=X_PATH, y_path=Y_PATH, output_dir=OUTPUT_DIR):\n",
    "    \"\"\"ExÃ©cute tous les tests\"\"\"\n",
    "    report_lines = []\n",
    "    \n",
    "    # Chargement\n",
    "    X_df, X_const, Y = load_data(x_path, y_path)\n",
    "    \n",
    "    # Test 1 : Probit de base\n",
    "    baseline = test_1_baseline_probit(X_const, Y, report_lines)\n",
    "    \n",
    "    # Test 2 : Diagnostics grands Ã©chantillons\n",
    "    test_2_diagnostics_grands_echantillons(X_const, Y, baseline, report_lines)\n",
    "    \n",
    "    # Test 3 : CaractÃ©risation rÃ©sidus extrÃªmes\n",
    "    test_3_residus_extremes(X_df, Y, baseline, report_lines)\n",
    "    \n",
    "    # Test 4 : Ratio avec changement de rÃ©fÃ©rence\n",
    "    test_4_ratio_reference_alternative(X_df, Y, report_lines)\n",
    "    \n",
    "    # Test 5 : Probit vs Logit (effets marginaux)\n",
    "    test_5_probit_vs_logit_mfx(X_df, Y, report_lines)\n",
    "    \n",
    "    # GÃ©nÃ©rer rapport\n",
    "    generate_report(report_lines, output_dir)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TESTS DE ROBUSTESSE V3 TERMINÃ‰S\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return baseline\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import os\n",
    "    if os.path.exists(X_PATH) and os.path.exists(Y_PATH):\n",
    "        run_all_tests()\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ Fichiers non trouvÃ©s. Adapter X_PATH et Y_PATH.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4531d301",
   "metadata": {},
   "source": [
    "## InterprÃ©tation des tests de robustesse complÃ©mentaires\n",
    "\n",
    "### Diagnostics grands Ã©chantillons : modÃ¨le bien calibrÃ© et discriminant\n",
    "\n",
    "**Score de Brier et pouvoir prÃ©dictif**\n",
    "\n",
    "Le score de Brier s'Ã©tablit Ã  0.068, contre 0.082 pour un modÃ¨le naÃ¯f prÃ©disant systÃ©matiquement la moyenne. Le Brier Skill Score de 0.16 indique une amÃ©lioration de 16% par rapport au modÃ¨le nul. Ce gain peut sembler modeste, mais il est cohÃ©rent avec la nature du problÃ¨me : prÃ©dire un comportement individuel rare (9% de transfrontaliers) Ã  partir de caractÃ©ristiques sociodÃ©mographiques est intrinsÃ¨quement difficile. Le modÃ¨le apporte une information rÃ©elle, mÃªme si une part importante de l'hÃ©tÃ©rogÃ©nÃ©itÃ© Ã©chappe aux variables disponibles.\n",
    "\n",
    "**Calibration par dÃ©ciles**\n",
    "\n",
    "La calibration est excellente. L'Ã©cart moyen absolu entre taux prÃ©dits et taux observÃ©s n'est que de 0.33 point de pourcentage. Pour chaque dÃ©cile de probabilitÃ© prÃ©dite, le taux observÃ© de transfrontaliers correspond quasi parfaitement Ã  la prÃ©diction. Par exemple, dans le dernier dÃ©cile (probabilitÃ©s prÃ©dites autour de 36%), on observe effectivement 35.6% de transfrontaliers. Cette prÃ©cision confirme que le modÃ¨le probit ne souffre d'aucun biais systÃ©matique de sur- ou sous-estimation, contrairement Ã  ce que suggÃ©raient les tests HL et Link rejetÃ©s dans la version prÃ©cÃ©dente.\n",
    "\n",
    "**Discrimination (AUC-ROC)**\n",
    "\n",
    "L'AUC atteint 0.849 avec un intervalle de confiance bootstrap trÃ¨s resserrÃ© [0.848 ; 0.850]. Une AUC supÃ©rieure Ã  0.8 est gÃ©nÃ©ralement considÃ©rÃ©e comme excellente. Le modÃ¨le distingue efficacement les transfrontaliers des non-transfrontaliers : un individu tirÃ© alÃ©atoirement parmi les transfrontaliers aura, dans 85% des cas, une probabilitÃ© prÃ©dite supÃ©rieure Ã  celle d'un individu tirÃ© parmi les non-transfrontaliers.\n",
    "\n",
    "**StabilitÃ© en validation croisÃ©e**\n",
    "\n",
    "La validation croisÃ©e 5-fold confirme la robustesse des rÃ©sultats. L'AUC moyen (0.841) et le Brier moyen (0.069) sont trÃ¨s proches des valeurs sur l'Ã©chantillon complet, avec des Ã©carts-types infÃ©rieurs Ã  1%. Le modÃ¨le ne souffre pas de sur-ajustement et ses performances se gÃ©nÃ©ralisent bien Ã  des donnÃ©es non vues.\n",
    "\n",
    "---\n",
    "\n",
    "### RÃ©sidus extrÃªmes : des transfrontaliers atypiques, pas des erreurs\n",
    "\n",
    "**Nature des rÃ©sidus extrÃªmes**\n",
    "\n",
    "L'analyse rÃ©vÃ¨le que 36 005 observations (7.3%) prÃ©sentent des rÃ©sidus supÃ©rieurs Ã  2.5 Ã©carts-types. Le rÃ©sultat le plus frappant est leur composition : 99.3% sont des transfrontaliers. Plus prÃ©cisÃ©ment, on compte 19 332 faux nÃ©gatifs (transfrontaliers avec probabilitÃ© prÃ©dite infÃ©rieure Ã  20%) contre seulement 244 faux positifs. Le modÃ¨le ne \"sur-prÃ©dit\" pratiquement jamais le statut transfrontalier. En revanche, il Ã©choue Ã  identifier une partie significative des transfrontaliers effectifs.\n",
    "\n",
    "**Concentration gÃ©ographique**\n",
    "\n",
    "Ces rÃ©sidus extrÃªmes ne sont pas distribuÃ©s alÃ©atoirement. Ils se concentrent massivement dans les dÃ©partements Ã  fort taux de transfrontaliers : Moselle (15.5% d'extrÃªmes), Haut-Rhin (12.2%), Meurthe-et-Moselle (8.5%). Dans les dÃ©partements non frontaliers, le taux d'extrÃªmes est nÃ©gligeable (moins de 0.2%). Cette concentration suggÃ¨re que le modÃ¨le capture bien la structure gÃ©nÃ©rale du phÃ©nomÃ¨ne mais peine Ã  expliquer pourquoi, parmi les rÃ©sidents des zones frontaliÃ¨res, certains deviennent transfrontaliers et d'autres non.\n",
    "\n",
    "**Profil des individus mal prÃ©dits**\n",
    "\n",
    "Les transfrontaliers mal prÃ©dits sont lÃ©gÃ¨rement plus Ã¢gÃ©s que la moyenne (+0.5 an) et comptent proportionnellement moins de femmes (41% contre 48% dans la population totale). Ces Ã©carts sont faibles, ce qui suggÃ¨re que les caractÃ©ristiques discriminantes Ã©chappent aux variables du modÃ¨le. Il pourrait s'agir de facteurs non observÃ©s : compÃ©tences linguistiques, rÃ©seaux professionnels transfrontaliers, historique familial de mobilitÃ©, ou simplement prÃ©fÃ©rences individuelles.\n",
    "\n",
    "**Recommandation**\n",
    "\n",
    "Ces observations ne doivent pas Ãªtre supprimÃ©es. Elles reprÃ©sentent des individus rÃ©els dont le comportement s'Ã©carte de la prÃ©diction moyenne. Leur exclusion biaiserait artificiellement les rÃ©sultats Ã  la hausse et rÃ©duirait la validitÃ© externe du modÃ¨le. L'existence de ces rÃ©sidus reflÃ¨te une limite structurelle : les variables disponibles dans le recensement ne suffisent pas Ã  expliquer toute l'hÃ©tÃ©rogÃ©nÃ©itÃ© des choix de mobilitÃ© transfrontaliÃ¨re.\n",
    "\n",
    "---\n",
    "\n",
    "### Ratio Logit/Probit : hypothÃ¨se confirmÃ©e\n",
    "\n",
    "**RÃ©sultat du test**\n",
    "\n",
    "Avec la Marne (non frontaliÃ¨re) comme rÃ©fÃ©rence, le ratio moyen des coefficients Logit/Probit s'Ã©tablissait Ã  2.91, bien au-delÃ  de la valeur thÃ©orique de 1.6. AprÃ¨s rÃ©-estimation avec le Bas-Rhin (frontalier) comme rÃ©fÃ©rence, ce ratio descend Ã  2.37. La diminution est substantielle, mÃªme si le ratio reste supÃ©rieur Ã  1.6.\n",
    "\n",
    "**InterprÃ©tation**\n",
    "\n",
    "L'hypothÃ¨se est confirmÃ©e : l'Ã©cart au ratio thÃ©orique provient bien des coefficients extrÃªmes induits par le choix d'une rÃ©fÃ©rence non frontaliÃ¨re. Avec la Marne comme rÃ©fÃ©rence, les coefficients de la Moselle et du Haut-Rhin dÃ©passent 2.4, captant l'intÃ©gralitÃ© de l'Ã©cart entre un dÃ©partement sans frontiÃ¨re et les zones les plus transfrontaliÃ¨res. Ã€ ces valeurs Ã©levÃ©es, les fonctions de rÃ©partition logistique et normale divergent significativement dans les queues de distribution, amplifiant mÃ©caniquement le ratio.\n",
    "\n",
    "Avec le Bas-Rhin comme rÃ©fÃ©rence, les coefficients sont plus modÃ©rÃ©s. La Moselle affiche +0.96 (Ã©cart relatif entre deux dÃ©partements frontaliers) au lieu de +2.44 (Ã©cart absolu avec un dÃ©partement intÃ©rieur). Le ratio se rapproche alors de sa valeur thÃ©orique, sans l'atteindre complÃ¨tement en raison de la persistance de quelques coefficients Ã©levÃ©s pour les dÃ©partements non frontaliers.\n",
    "\n",
    "**Conclusion mÃ©thodologique**\n",
    "\n",
    "Ce rÃ©sultat ne remet pas en cause la validitÃ© du modÃ¨le avec la Marne comme rÃ©fÃ©rence. Au contraire, cette spÃ©cification reste prÃ©fÃ©rable pour l'interprÃ©tation Ã©conomique car elle mesure directement l'effet d'Ãªtre frontalier par rapport Ã  ne pas l'Ãªtre. L'Ã©cart au ratio thÃ©orique est une consÃ©quence attendue du design, non un signe de mauvaise spÃ©cification.\n",
    "\n",
    "---\n",
    "\n",
    "### Ã‰quivalence Probit/Logit confirmÃ©e\n",
    "\n",
    "La corrÃ©lation des effets marginaux entre les deux spÃ©cifications atteint 0.995, avec une diffÃ©rence moyenne absolue de 0.5 point de pourcentage. Les conclusions substantives seraient rigoureusement identiques quel que soit le modÃ¨le retenu. Le choix du probit, justifiÃ© par sa cohÃ©rence avec le modÃ¨le bivariÃ© prÃ©vu pour l'analyse des couples, n'introduit aucun biais par rapport Ã  l'alternative logit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ff3c0",
   "metadata": {},
   "source": [
    "# Lecture statistique du ModÃ¨le Probit : DÃ©terminants du travail transfrontalier dans le Grand Est\n",
    "\n",
    "\n",
    "Ce rapport prÃ©sente l'analyse Ã©conomÃ©trique des dÃ©terminants individuels de la probabilitÃ© d'Ãªtre travailleur transfrontalier dans la rÃ©gion Grand Est. L'estimation repose sur un modÃ¨le **Probit binaire** appliquÃ© Ã  **494 483 observations** issues du Recensement de la Population 2022 (INSEE) et de la base de donnÃ©e MOBPRO des mobilitÃ©s professionnelles.\n",
    "\n",
    "**RÃ©sultat principal** : La probabilitÃ© moyenne d'Ãªtre transfrontalier est de **8,95%** dans la population Ã©tudiÃ©e. La localisation gÃ©ographique (proximitÃ© frontaliÃ¨re) constitue le dÃ©terminant le plus puissant, suivie par la nationalitÃ©, le secteur d'activitÃ© et les caractÃ©ristiques socioprofessionnelles.\n",
    "\n",
    "### Rappel : Convention de lecture (Ã  appliquer dans toutes les sections)\n",
    "\n",
    "Pour chaque variable significative, les rÃ©sultats sont prÃ©sentÃ©s systÃ©matiquement sous deux formes :\n",
    "\n",
    "- **En points de pourcentage** : \"Toutes choses Ã©gales par ailleurs, [variable] augmente/diminue la probabilitÃ© d'Ãªtre transfrontalier de X points de pourcentage par rapport Ã  [rÃ©fÃ©rence].\"\n",
    "\n",
    "- **En odds ratio** : \"Les chances d'Ãªtre transfrontalier sont multipliÃ©es par Y / rÃ©duites de Z % pour [catÃ©gorie] par rapport Ã  [rÃ©fÃ©rence].\"\n",
    "\n",
    "Cette double lecture permet de satisfaire les attentes des Ã©conomistes (effets marginaux interprÃ©tables) comme des praticiens (odds ratios familiers en Ã©pidÃ©miologie et sciences sociales).\n",
    "\n",
    "### Classification des variables selon le risque d'endogÃ©nÃ©itÃ©\n",
    "\n",
    "Les variables explicatives sont classÃ©es selon leur statut causal :\n",
    "\n",
    "| Statut | InterprÃ©tation | Variables concernÃ©es |\n",
    "|--------|----------------|----------------------|\n",
    "| **ExogÃ¨ne** | Relation causale plausible | DÃ©partement, Ã¢ge, sexe, nationalitÃ©, lieu de naissance, diplÃ´me, enfants, secteur, CSP |\n",
    "| **Ambigu** | CausalitÃ© incertaine | Type de contrat, temps partiel |\n",
    "| **EndogÃ¨ne** | Association statistique (causalitÃ© inverse possible) | PropriÃ©taire, nombre de voitures, type de logement, superficie |\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Effets gÃ©ographiques : la proximitÃ© frontaliÃ¨re comme dÃ©terminant majeur\n",
    "\n",
    "> **Variables exogÃ¨nes** : Le dÃ©partement de rÃ©sidence est gÃ©nÃ©ralement choisi avant l'emploi ou dÃ©terminÃ© par des facteurs familiaux. L'interprÃ©tation causale est justifiÃ©e.\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : Marne (51) â€” dÃ©partement intÃ©rieur sans frontiÃ¨re directe\n",
    "\n",
    "| DÃ©partement             | Effet marginal | Odds Ratio | FrontiÃ¨re principale |\n",
    "|-------------            |:--------------:|:----------:|----------------------|\n",
    "| Moselle (57)            | +15,35 pp***   | 4,71       | Luxembourg |\n",
    "| Haut-Rhin (68)          | +13,17 pp***   | 3,87       | Suisse / Allemagne |\n",
    "| Meurthe-et-Moselle (54) | +12,22 pp***   | 3,56       | Luxembourg |\n",
    "| Meuse (55)              | +9,59 pp***    | 2,82       | Belgique / Luxembourg |\n",
    "| Bas-Rhin (67)           | +9,27 pp***    | 2,73       | Allemagne |\n",
    "| Vosges (88)             | +1,85 pp***    | 1,30       | (Ã©loignÃ© des frontiÃ¨res) |\n",
    "| Aube (10)               | +0,66 pp       | 1,11       | IntÃ©rieur (NS) |\n",
    "| Haute-Marne (52)        | +0,75 pp       | 1,12       | IntÃ©rieur (NS) |\n",
    "\n",
    "*Note : pp = points de pourcentage ; OR = Odds Ratio ; NS = non significatif ; \\*\\*\\* p < 0.001*\n",
    "\n",
    "### Lecture des rÃ©sultats\n",
    "\n",
    "**En points de pourcentage :**\n",
    "- Toutes choses Ã©gales par ailleurs, **rÃ©sider en Moselle plutÃ´t que dans la Marne augmente la probabilitÃ© d'Ãªtre travailleur transfrontalier de 15,35 points de pourcentage**.\n",
    "- **RÃ©sider dans le Haut-Rhin augmente la probabilitÃ© d'Ãªtre transfrontalier de 13,17 points de pourcentage** par rapport Ã  la Marne.\n",
    "- **RÃ©sider en Meurthe-et-Moselle augmente la probabilitÃ© d'Ãªtre transfrontalier de 12,22 points de pourcentage** par rapport Ã  la Marne.\n",
    "\n",
    "**En odds ratio :**\n",
    "- **Les chances d'Ãªtre transfrontalier sont multipliÃ©es par 4,7 pour un rÃ©sident de Moselle** par rapport Ã  un rÃ©sident de la Marne.\n",
    "- **Les chances sont multipliÃ©es par 3,9 pour un rÃ©sident du Haut-Rhin** par rapport Ã  la Marne.\n",
    "- **Les chances sont multipliÃ©es par 3,6 pour un rÃ©sident de Meurthe-et-Moselle** par rapport Ã  la Marne.\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "La hiÃ©rarchie des effets gÃ©ographiques reflÃ¨te fidÃ¨lement l'attractivitÃ© diffÃ©renciÃ©e des marchÃ©s du travail frontaliers :\n",
    "\n",
    "1. **Luxembourg** (Moselle, Meurthe-et-Moselle, Meuse) : salaires Ã©levÃ©s, fiscalitÃ© avantageuse, forte demande de main-d'Å“uvre\n",
    "2. **Suisse** (Haut-Rhin) : rÃ©munÃ©rations trÃ¨s attractives dans l'industrie et les services\n",
    "3. **Allemagne** (Bas-Rhin, Haut-Rhin) : proximitÃ© industrielle et complÃ©mentaritÃ© des marchÃ©s du travail\n",
    "\n",
    "Les dÃ©partements intÃ©rieurs (Aube, Haute-Marne) ne prÃ©sentent pas de diffÃ©rence significative avec la Marne, confirmant que l'effet frontalier est le moteur principal.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. NationalitÃ© et origine gÃ©ographique : l'effet des rÃ©seaux transnationaux\n",
    "\n",
    "> **Variables exogÃ¨nes** : La nationalitÃ© et le lieu de naissance sont dÃ©terminÃ©s avant l'entrÃ©e sur le marchÃ© du travail. L'interprÃ©tation causale est justifiÃ©e.\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : FranÃ§ais nÃ© dans le Grand Est\n",
    "\n",
    "| Variable                                | Effet marginal | Odds Ratio |\n",
    "|----------                               |:--------------:|:----------:|\n",
    "| Ã‰tranger (vs FranÃ§ais)                  | +3,12 pp***    | 1,56 |\n",
    "| NÃ© Ã  l'Ã©tranger (vs nÃ© Grand Est)       | +2,20 pp***    | 1,40 |\n",
    "| NÃ© ailleurs en France (vs nÃ© Grand Est) | -0,19 pp**     | 0,97 |\n",
    "\n",
    "### Lecture des rÃ©sultats\n",
    "\n",
    "**En points de pourcentage :**\n",
    "- Toutes choses Ã©gales par ailleurs, **Ãªtre de nationalitÃ© Ã©trangÃ¨re augmente la probabilitÃ© d'Ãªtre transfrontalier de 3,12 points de pourcentage** par rapport aux FranÃ§ais.\n",
    "- **ÃŠtre nÃ© Ã  l'Ã©tranger augmente la probabilitÃ© d'Ãªtre transfrontalier de 2,20 points de pourcentage** par rapport aux personnes nÃ©es dans le Grand Est.\n",
    "- **ÃŠtre nÃ© dans une autre rÃ©gion franÃ§aise diminue la probabilitÃ© de 0,19 point de pourcentage**, suggÃ©rant un moindre ancrage dans les dynamiques frontaliÃ¨res locales.\n",
    "\n",
    "**En odds ratio :**\n",
    "- **Les chances d'Ãªtre transfrontalier sont multipliÃ©es par 1,56 pour les Ã©trangers** par rapport aux FranÃ§ais.\n",
    "- **Les chances sont multipliÃ©es par 1,40 pour les personnes nÃ©es Ã  l'Ã©tranger** par rapport Ã  celles nÃ©es dans le Grand Est.\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "Ces rÃ©sultats mettent en Ã©vidence le rÃ´le des **rÃ©seaux transnationaux** dans l'accÃ¨s au travail frontalier :\n",
    "\n",
    "- Les Ã©trangers disposent souvent de **connexions familiales ou communautaires** dans les pays voisins facilitant l'information et l'embauche\n",
    "- Les personnes nÃ©es Ã  l'Ã©tranger possÃ¨dent frÃ©quemment des **compÃ©tences linguistiques** (allemand, luxembourgeois, anglais) valorisÃ©es sur les marchÃ©s frontaliers\n",
    "- Une **moindre aversion Ã  la mobilitÃ© internationale** peut Ã©galement jouer\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Profil dÃ©mographique\n",
    "\n",
    "### 3.1 Effet de l'Ã¢ge : une relation en U inversÃ©\n",
    "\n",
    "> **Variable exogÃ¨ne** : L'Ã¢ge est une caractÃ©ristique individuelle fixe. L'interprÃ©tation causale est justifiÃ©e.\n",
    "\n",
    "| Variable           | Effet marginal |\n",
    "|----------          |:--------------:|\n",
    "| Ã‚ge (linÃ©aire)     | +0,21 pp par annÃ©e*** |\n",
    "| Ã‚geÂ² (quadratique) | -0,0025 pp par annÃ©eÂ²*** |\n",
    "\n",
    "**Ã‚ge optimal calculÃ©** : â‰ˆ **41 ans**\n",
    "\n",
    "### Lecture des rÃ©sultats\n",
    "\n",
    "- Toutes choses Ã©gales par ailleurs, **chaque annÃ©e d'Ã¢ge supplÃ©mentaire augmente la probabilitÃ© d'Ãªtre transfrontalier de 0,21 point de pourcentage** jusqu'Ã  environ 41 ans.\n",
    "- **Au-delÃ  de 41 ans, l'effet s'inverse** et la probabilitÃ© dÃ©croÃ®t progressivement.\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "La relation en U inversÃ© reflÃ¨te deux dynamiques opposÃ©es :\n",
    "\n",
    "- **Phase ascendante (< 41 ans)** : accumulation d'expÃ©rience professionnelle, stabilisation familiale permettant d'assumer les contraintes de mobilitÃ©, progression salariale rendant les trajets rentables\n",
    "- **Phase descendante (> 41 ans)** : pÃ©nibilitÃ© croissante des trajets quotidiens, ancrage territorial renforcÃ©, arbitrage en faveur de la qualitÃ© de vie\n",
    "\n",
    "---\n",
    "\n",
    "### 3.2 Effet du genre\n",
    "\n",
    "> **Variable exogÃ¨ne** : Le sexe est une caractÃ©ristique individuelle fixe. L'interprÃ©tation causale est justifiÃ©e.\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : Homme\n",
    "\n",
    "| Variable | Effet marginal | Odds Ratio |\n",
    "|----------|:--------------:|:----------:|\n",
    "| Femme    | -0,79 pp***    | 0,88       |\n",
    "\n",
    "### Lecture des rÃ©sultats\n",
    "\n",
    "- Toutes choses Ã©gales par ailleurs, **Ãªtre une femme diminue la probabilitÃ© d'Ãªtre transfrontalier de 0,79 point de pourcentage** par rapport aux hommes.\n",
    "- **Les chances d'Ãªtre transfrontalier sont rÃ©duites de 12% pour les femmes** (OR = 0,88) par rapport aux hommes.\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "Ce diffÃ©rentiel de genre, cohÃ©rent avec la littÃ©rature sur les mobilitÃ©s professionnelles, peut s'expliquer par :\n",
    "\n",
    "1. **La charge familiale** : les femmes assurent encore majoritairement les responsabilitÃ©s domestiques et parentales, peu compatibles avec les longs trajets\n",
    "2. **La segmentation sectorielle** : surreprÃ©sentation fÃ©minine dans le secteur public et la santÃ©, structurellement non-transfrontaliers\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Situation familiale : la contrainte parentale\n",
    "\n",
    "> **Variables exogÃ¨nes** : Le nombre d'enfants et la structure familiale ne sont pas directement causÃ©s par le statut de travailleur transfrontalier. L'interprÃ©tation causale est justifiÃ©e.\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : Sans enfant (NENFR = 0)\n",
    "\n",
    "| Nombre d'enfants     | Effet marginal | Odds Ratio |\n",
    "|------------------    |:--------------:|:----------:|\n",
    "| 1 enfant             | -0,45 pp***     | 0,94 |\n",
    "| 2 enfants            | -0,59 pp***     | 0,92 |\n",
    "| 3 enfants            | -1,18 pp***     | 0,85 |\n",
    "| 4 enfants ou plus    | -1,34 pp***     | 0,83 |\n",
    "| Hors famille (isolÃ©) | +0,52 pp***     | 1,07 |\n",
    "\n",
    "| Statut conjugal      | Effet marginal | Odds Ratio |\n",
    "|-----------------     |:--------------:|:----------:|\n",
    "| Ne vit pas en couple | +0,14 pp*      | 1,02       |\n",
    "\n",
    "*Note : \\* p < 0.05*\n",
    "\n",
    "### Lecture des rÃ©sultats\n",
    "\n",
    "- Toutes choses Ã©gales par ailleurs, **avoir un enfant diminue la probabilitÃ© d'Ãªtre transfrontalier de 0,45 point de pourcentage** par rapport aux personnes sans enfant.\n",
    "- **Avoir trois enfants diminue la probabilitÃ© d'Ãªtre transfrontalier de 1,18 point de pourcentage** par rapport aux personnes sans enfant.\n",
    "- **Avoir quatre enfants ou plus diminue la probabilitÃ© d'Ãªtre transfrontalier de 1,34 point de pourcentage** par rapport aux personnes sans enfant.\n",
    "- **Les personnes hors structure familiale voient leur probabilitÃ© augmenter de 0,52 point de pourcentage**.\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "L'effet est **monotone dÃ©croissant** : chaque enfant supplÃ©mentaire rÃ©duit la probabilitÃ© de travail transfrontalier. En moyenne, l'effet marginal de chaque enfant additionnel est d'environ **0,3 Ã  0,4 point de pourcentage**, avec une accÃ©lÃ©ration au-delÃ  de deux enfants. Cette relation s'explique par :\n",
    "\n",
    "- **L'incompatibilitÃ© temporelle** : trajets longs (souvent 1h-1h30 par trajet) difficilement conciliables avec les horaires scolaires et la garde d'enfants\n",
    "- **Les coÃ»ts indirects** : garde d'enfants, activitÃ©s extrascolaires nÃ©cessitant une prÃ©sence parentale\n",
    "- **L'arbitrage familial** : dans les couples, un des conjoints peut renoncer au travail frontalier pour assurer la logistique familiale\n",
    "\n",
    "Le statut conjugal en lui-mÃªme (vivre en couple ou non) n'a qu'un effet marginal et faiblement significatif (p = 0.022), confirmant que c'est bien la **prÃ©sence d'enfants**, et non le couple en soi, qui constitue la contrainte dÃ©terminante.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. CaractÃ©ristiques professionnelles\n",
    "\n",
    "### 5.1 CatÃ©gorie socioprofessionnelle\n",
    "\n",
    "> **Variable exogÃ¨ne** : La CSP reflÃ¨te une qualification et une trajectoire professionnelle prÃ©existantes. L'interprÃ©tation causale est justifiÃ©e.\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : EmployÃ©s (GS_5)\n",
    "\n",
    "| CSP                                       | Effet marginal | Odds Ratio |\n",
    "|-----                                      |:--------------:|:----------:|\n",
    "| Ouvriers                                  | +0,59 pp***    | 1,08 |\n",
    "| Professions intermÃ©diaires                | -0,25 pp***    | 0,97 |\n",
    "| Cadres                                    | -0,53 pp***    | 0,93 |\n",
    "| Artisans, commerÃ§ants, chefs d'entreprise | -1,93 pp***    | 0,77 |\n",
    "| Agriculteurs                              | -0,68 pp       | 0,91 (NS) |\n",
    "\n",
    "### Lecture des rÃ©sultats\n",
    "\n",
    "- Toutes choses Ã©gales par ailleurs, **Ãªtre ouvrier augmente la probabilitÃ© d'Ãªtre transfrontalier de 0,59 point de pourcentage** par rapport aux employÃ©s.\n",
    "- **ÃŠtre artisan, commerÃ§ant ou chef d'entreprise diminue la probabilitÃ© d'Ãªtre transfrontalier de 1,93 point de pourcentage** par rapport aux employÃ©s.\n",
    "- **ÃŠtre cadre diminue la probabilitÃ© d'Ãªtre transfrontalier de 0,53 point de pourcentage** par rapport aux employÃ©s.\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "Les **ouvriers** constituent la catÃ©gorie la plus encline au travail transfrontalier, ce qui reflÃ¨te :\n",
    "\n",
    "- La **forte demande industrielle** au Luxembourg et en Allemagne (automobile, mÃ©tallurgie, construction)\n",
    "- Des **diffÃ©rentiels salariaux particuliÃ¨rement attractifs** pour les qualifications ouvriÃ¨res\n",
    "- La **tradition industrielle transfrontaliÃ¨re** du bassin lorrain et alsacien\n",
    "\n",
    "Les indÃ©pendants (artisans, commerÃ§ants) prÃ©sentent logiquement la probabilitÃ© la plus faible, leur activitÃ© Ã©tant par nature **ancrÃ©e territorialement** (clientÃ¨le locale, Ã©tablissement commercial).\n",
    "\n",
    "---\n",
    "\n",
    "### 5.2 Type de contrat et statut d'emploi\n",
    "\n",
    "> **Variables ambiguÃ«s** : Le type de contrat peut Ãªtre une condition d'accÃ¨s au travail frontalier (exogÃ¨ne) ou une consÃ©quence de l'emploi frontalier (endogÃ¨ne). L'interprÃ©tation reste prudente.\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : CDI / Titulaire de la fonction publique (EMPL_16)\n",
    "\n",
    "| Type de contrat       | Effet marginal | Odds Ratio |\n",
    "|-----------------      |:--------------:|:----------:|\n",
    "| Stagiaires rÃ©munÃ©rÃ©s  | +2,61 pp***    | 1,49 |\n",
    "| IntÃ©rim               | -0,49 pp***    | 0,93 |\n",
    "| CDD, contrats courts  | -0,63 pp***    | 0,91 |\n",
    "| Employeurs            | -2,98 pp***    | 0,69 |\n",
    "| Apprentissage         | -3,33 pp***    | 0,64 |\n",
    "| IndÃ©pendants          | -3,58 pp***    | 0,62 |\n",
    "| Emplois aidÃ©s         | -4,70 pp***    | 0,52 |\n",
    "| Aides familiaux       | -1,40 pp       | 0,82 (NS, p=0.069) |\n",
    "\n",
    "### Lecture des rÃ©sultats\n",
    "\n",
    "- Les personnes en CDI ou titulaires de la fonction publique constituent la **norme du travail transfrontalier**.\n",
    "- **ÃŠtre stagiaire rÃ©munÃ©rÃ© est associÃ© Ã  une probabilitÃ© supÃ©rieure de 2,61 points de pourcentage**. Cet effet, a priori surprenant, s'explique par plusieurs mÃ©canismes :\n",
    "  - Les **formations transfrontaliÃ¨res** (cursus franco-allemands, masters europÃ©ens) imposent souvent des stages dans le pays partenaire\n",
    "  - Le Luxembourg mÃ¨ne une **politique active d'accueil de stagiaires** franÃ§ais, notamment dans le secteur financier et les institutions europÃ©ennes\n",
    "  - Les grandes entreprises frontaliÃ¨res (ArcelorMittal, banques luxembourgeoises) disposent de programmes de stages structurÃ©s ciblant les Ã©tudiants du Grand Est\n",
    "- **ÃŠtre en emploi aidÃ© est associÃ© Ã  une probabilitÃ© infÃ©rieure de 4,70 points de pourcentage** par rapport aux CDI.\n",
    "- **ÃŠtre indÃ©pendant est associÃ© Ã  une probabilitÃ© infÃ©rieure de 3,58 points de pourcentage** par rapport aux CDI.\n",
    "- **ÃŠtre en apprentissage est associÃ© Ã  une probabilitÃ© infÃ©rieure de 3,33 points de pourcentage** par rapport aux CDI. Cette diffÃ©rence avec les stagiaires rÃ©munÃ©rÃ©s s'explique par l'ancrage territorial des CFA et l'obligation de prÃ©sence en entreprise locale.\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "Le travail transfrontalier est fortement associÃ© Ã  la **stabilitÃ© contractuelle** (CDI) pour plusieurs raisons :\n",
    "\n",
    "- **Amortissement des coÃ»ts fixes** : l'investissement initial (trajet, Ã©ventuellement dÃ©mÃ©nagement, adaptation) n'est rentable que sur le long terme\n",
    "- **AccÃ¨s au crÃ©dit** : les revenus frontaliers (souvent Ã©levÃ©s) permettent l'accession Ã  la propriÃ©tÃ©, conditionnÃ©e Ã  un emploi stable\n",
    "- **SÃ©lection par les employeurs** : les entreprises luxembourgeoises et allemandes privilÃ©gient les CDI\n",
    "\n",
    "Les formes prÃ©caires (emplois aidÃ©s, apprentissage, intÃ©rim) sont sous-reprÃ©sentÃ©es car elles concernent des populations Ã©loignÃ©es des prÃ©requis du travail frontalier (mobilitÃ©, qualification, stabilitÃ©).\n",
    "\n",
    "---\n",
    "\n",
    "### 5.3 Secteur d'activitÃ©\n",
    "\n",
    "> **Variable exogÃ¨ne** : Le secteur d'activitÃ© dÃ©termine structurellement la possibilitÃ© d'Ãªtre transfrontalier. L'interprÃ©tation causale est justifiÃ©e.\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : Commerce, transports et services divers (NA5_GU)\n",
    "\n",
    "| Secteur                             | Effet marginal | Odds Ratio |\n",
    "|---------                            |:--------------:|:----------:|\n",
    "| Industrie                           | +0,08 pp       | 1,01 (NS) |\n",
    "| Construction                        | -0,13 pp       | 0,98 (NS, p=0.08) |\n",
    "| Administration, enseignement, santÃ© | -4,16 pp***    | 0,55 |\n",
    "| Agriculture                         | -6,01 pp***    | 0,44 |\n",
    "\n",
    "### Lecture des rÃ©sultats\n",
    "\n",
    "- Toutes choses Ã©gales par ailleurs, **travailler dans l'administration publique, l'enseignement ou la santÃ© diminue la probabilitÃ© d'Ãªtre transfrontalier de 4,16 points de pourcentage** par rapport au secteur tertiaire marchand.\n",
    "- **Travailler dans l'agriculture diminue la probabilitÃ© d'Ãªtre transfrontalier de 6,01 points de pourcentage** par rapport au secteur tertiaire marchand.\n",
    "- **Les chances d'Ãªtre transfrontalier sont rÃ©duites de 45% dans le secteur public** (OR = 0,55) et de **56% dans l'agriculture** (OR = 0,44).\n",
    "- **L'industrie et la construction ne diffÃ¨rent pas significativement** du secteur tertiaire marchand.\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "Le secteur public (administration, enseignement, santÃ©) est **structurellement non-transfrontalier** :\n",
    "\n",
    "- Ces emplois sont liÃ©s au **territoire national** (fonctionnaires, hospitaliers, enseignants)\n",
    "- Les systÃ¨mes de santÃ© et d'Ã©ducation ne sont pas intÃ©grÃ©s entre pays\n",
    "- Les concours et recrutements sont nationaux\n",
    "\n",
    "L'agriculture, par nature **ancrÃ©e gÃ©ographiquement** (exploitation, terres), exclut de facto la mobilitÃ© transfrontaliÃ¨re.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Capital humain : une relation non linÃ©aire avec le diplÃ´me\n",
    "\n",
    "> **Variable exogÃ¨ne** : Le diplÃ´me est obtenu avant l'entrÃ©e sur le marchÃ© du travail. L'interprÃ©tation causale est justifiÃ©e.\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : CAP, BEP ou diplÃ´me Ã©quivalent (DIPL_13)\n",
    "\n",
    "| Niveau de diplÃ´me                  | Effet marginal | Odds Ratio |\n",
    "|-------------------                 |:--------------:|:----------:|\n",
    "| Doctorat de recherche              | +1,54 pp***    | 1,21 |\n",
    "| Master, Bac+5, Grande Ã©cole        | +1,40 pp***    | 1,19 |\n",
    "| CEP (certificat d'Ã©tudes primaires)| +0,77 pp***    | 1,10 |\n",
    "| Licence, Bac+3/4                   | +0,50 pp***    | 1,07 |\n",
    "| BEPC, Brevet                       | -0,14 pp       | 0,98 (NS) \n",
    "| Bac gÃ©nÃ©ral/technologique          | -0,31 pp***    | 0,96 |\n",
    "| Bac professionnel                  | -0,22 pp**     | 0,97 |\n",
    "| BTS, DUT, Bac+2                    | -0,31 pp***    | 0,96 |\n",
    "| Aucun diplÃ´me (scolaritÃ© collÃ¨ge)  | -0,61 pp***    | 0,92 |\n",
    "| Aucun diplÃ´me (scolaritÃ© primaire) | -1,60 pp***    | 0,80 |\n",
    "| Pas de scolaritÃ©                   | -3,28 pp***    | 0,62 |\n",
    "\n",
    "### Lecture des rÃ©sultats\n",
    "\n",
    "- Toutes choses Ã©gales par ailleurs, **Ãªtre titulaire d'un doctorat augmente la probabilitÃ© d'Ãªtre transfrontalier de 1,54 point de pourcentage** par rapport aux titulaires d'un CAP/BEP.\n",
    "- **ÃŠtre titulaire d'un Master ou diplÃ´me Bac+5 augmente la probabilitÃ© d'Ãªtre transfrontalier de 1,40 point de pourcentage** par rapport aux titulaires d'un CAP/BEP.\n",
    "- **ÃŠtre titulaire du CEP augmente la probabilitÃ© d'Ãªtre transfrontalier de 0,77 point de pourcentage** par rapport aux titulaires d'un CAP/BEP.\n",
    "- **N'avoir aucune scolaritÃ© diminue la probabilitÃ© d'Ãªtre transfrontalier de 3,28 points de pourcentage** par rapport aux titulaires d'un CAP/BEP.\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "La relation entre diplÃ´me et travail transfrontalier est **non linÃ©aire**, avec trois profils distincts :\n",
    "\n",
    "**Profil 1 â€” TrÃ¨s diplÃ´mÃ©s (Master+)** :\n",
    "- AccÃ¨s Ã  des postes qualifiÃ©s au Luxembourg (finance, audit, consulting, institutions europÃ©ennes)\n",
    "- MaÃ®trise des langues Ã©trangÃ¨res\n",
    "- MobilitÃ© internationale facilitÃ©e\n",
    "\n",
    "**Profil 2 â€” Faiblement qualifiÃ©s avec anciennetÃ© (CEP)** :\n",
    "- Ce rÃ©sultat reflÃ¨te probablement un **effet de gÃ©nÃ©ration** plutÃ´t qu'un effet du diplÃ´me en soi\n",
    "- Les titulaires du CEP sont majoritairement des travailleurs Ã¢gÃ©s (55-65 ans) entrÃ©s sur le marchÃ© frontalier dans les annÃ©es 1980-1990, lorsque l'industrie lourde luxembourgeoise et allemande recrutait massivement\n",
    "- Ces travailleurs ont conservÃ© leur emploi frontalier au fil des dÃ©cennies, accumulant anciennetÃ© et droits acquis\n",
    "- Le coefficient capte donc la **persistance** du travail frontalier chez une cohorte spÃ©cifique, non un avantage intrinsÃ¨que du CEP\n",
    "\n",
    "**Profil 3 â€” Qualifications intermÃ©diaires (Bac, BTS) moins mobiles** :\n",
    "- Ces niveaux trouvent des dÃ©bouchÃ©s locaux satisfaisants (techniciens, employÃ©s qualifiÃ©s)\n",
    "- Le diffÃ©rentiel salarial frontalier est moins attractif relativement Ã  leur salaire local\n",
    "- Moindre incitation Ã  supporter les coÃ»ts de la mobilitÃ© (trajets, contraintes horaires)\n",
    "\n",
    "**Profil 4 â€” Sans qualification ni scolaritÃ©** :\n",
    "- BarriÃ¨res cumulatives Ã  l'emploi frontalier : langue, mobilitÃ©, accÃ¨s Ã  l'information\n",
    "- Ã‰loignement des rÃ©seaux professionnels transfrontaliers\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Conditions de logement et motorisation\n",
    "\n",
    "> **Variables endogÃ¨nes** : Les variables de cette section prÃ©sentent un **risque Ã©levÃ© de causalitÃ© inverse**. Les revenus plus Ã©levÃ©s des travailleurs transfrontaliers peuvent permettre d'accÃ©der Ã  la propriÃ©tÃ©, d'habiter en maison individuelle ou de possÃ©der plusieurs vÃ©hicules. Les rÃ©sultats ci-dessous doivent Ãªtre interprÃ©tÃ©s comme des **associations statistiques** et non comme des relations causales.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Conditions de logement et motorisation\n",
    "\n",
    "> **Variables endogÃ¨nes** : Les variables de cette section prÃ©sentent un **risque Ã©levÃ© de causalitÃ© inverse**. Les revenus plus Ã©levÃ©s des travailleurs transfrontaliers peuvent permettre d'accÃ©der Ã  la propriÃ©tÃ©, d'habiter en maison individuelle ou de possÃ©der plusieurs vÃ©hicules. Les rÃ©sultats ci-dessous doivent Ãªtre interprÃ©tÃ©s comme des **associations statistiques** et non comme des relations causales. Un modÃ¨le Ã  Ã©quations simultanÃ©es ou une approche par variables instrumentales serait nÃ©cessaire pour identifier les effets causaux.\n",
    "\n",
    "### RÃ©sultats\n",
    "\n",
    "**Motorisation** (rÃ©fÃ©rence : 1 voiture)\n",
    "\n",
    "| Nombre de voitures   | Association  | Odds Ratio |\n",
    "|:---------------------|:------------:|:----------:|\n",
    "| 3 voitures ou plus   | +1,05 pp***  |    1,14    |\n",
    "| 2 voitures           | +0,74 pp***  |    1,10    |\n",
    "| Aucune voiture       | -2,04 pp***  |    0,76    |\n",
    "\n",
    "**Statut d'occupation** (rÃ©fÃ©rence : PropriÃ©taire)\n",
    "\n",
    "| Statut                 | Association  | Odds Ratio |\n",
    "|:-----------------------|:------------:|:----------:|\n",
    "| Locataire non-HLM      | -0,51 pp***  |    0,93    |\n",
    "| Locataire meublÃ©/hÃ´tel | -1,31 pp***  |    0,83    |\n",
    "| LogÃ© gratuitement      | -1,79 pp***  |    0,78    |\n",
    "| Locataire HLM          | -3,11 pp***  |    0,64    |\n",
    "\n",
    "**Type de logement** (rÃ©fÃ©rence : Maison individuelle)\n",
    "\n",
    "| Type de logement     | Association  | Odds Ratio |\n",
    "|:---------------------|:------------:|:----------:|\n",
    "| Appartement          | -1,04 pp***  |    0,87    |\n",
    "| Logement-foyer       | -3,01 pp***  |    0,64    |\n",
    "| Chambre d'hÃ´tel      | -3,89 pp***  |    0,56    |\n",
    "| PiÃ¨ce indÃ©pendante   | -3,98 pp***  |    0,55    |\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "Ces trois dimensions convergent vers un mÃªme profil : le travailleur transfrontalier est statistiquement associÃ© Ã  la **propriÃ©tÃ© en maison individuelle** et Ã  la **multi-motorisation**. Cette configuration peut rÃ©sulter de trois mÃ©canismes non exclusifs :\n",
    "\n",
    "1. **NÃ©cessitÃ© pratique** : l'automobile est indispensable pour les trajets frontaliers (transports en commun peu dÃ©veloppÃ©s, horaires dÃ©calÃ©s). La maison individuelle, plus frÃ©quente en zone pÃ©riurbaine, offre une localisation optimale entre frontiÃ¨re et bassin de vie.\n",
    "\n",
    "2. **Effet richesse (causalitÃ© inverse)** : les revenus frontaliers Ã©levÃ©s â€” souvent 30 Ã  50 % supÃ©rieurs aux Ã©quivalents locaux â€” permettent l'accession Ã  la propriÃ©tÃ© et l'achat de vÃ©hicules supplÃ©mentaires. Dans cette hypothÃ¨se, la propriÃ©tÃ© et la motorisation sont des *consÃ©quences* du travail frontalier, non des *causes*.\n",
    "\n",
    "3. **SÃ©lection sociale** : les locataires HLM et les mÃ©nages sans voiture cumulent gÃ©nÃ©ralement des caractÃ©ristiques dÃ©favorables Ã  l'emploi frontalier (prÃ©caritÃ©, faible qualification, moindre mobilitÃ©). L'association observÃ©e reflÃ©terait alors une hÃ©tÃ©rogÃ©nÃ©itÃ© non observÃ©e plutÃ´t qu'un effet direct.\n",
    "\n",
    "Sans instrumentation adÃ©quate, il est impossible de dÃ©partager ces mÃ©canismes. Les coefficients de cette section doivent donc Ãªtre considÃ©rÃ©s comme **descriptifs** et non comme des leviers d'action pour les politiques publiques.\n",
    "---\n",
    "\n",
    "## 8. Temps de travail\n",
    "\n",
    "> **Variable ambiguÃ«** : Le temps partiel peut Ãªtre une cause (contrainte de mobilitÃ©) ou une consÃ©quence (choix permis par des revenus Ã©levÃ©s) du travail transfrontalier.\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : Temps complet\n",
    "\n",
    "| Variable      | Effet marginal | Odds Ratio |\n",
    "|----------     |:--------------:|:----------:|\n",
    "| Temps partiel | +0,77 pp***    | 1,10 |\n",
    "\n",
    "### Lecture des rÃ©sultats\n",
    "\n",
    "- **Travailler Ã  temps partiel est associÃ© Ã  une probabilitÃ© supÃ©rieure de 0,77 point de pourcentage** par rapport au temps complet.\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "Ce rÃ©sultat, contre-intuitif au premier abord, peut s'expliquer par :\n",
    "\n",
    "1. **Temps partiels choisis** : certains travailleurs frontaliers optent pour un temps partiel afin de concilier trajets longs et vie familiale\n",
    "2. **Organisation du travail au Luxembourg** : certains emplois frontaliers (notamment dans les services) sont structurÃ©s en temps partiel\n",
    "3. **Effet de composition** : le temps partiel peut reflÃ©ter des arrangements familiaux oÃ¹ un conjoint travaille Ã  temps partiel pendant que l'autre effectue les trajets frontaliers\n",
    "\n",
    "** RÃ©serve mÃ©thodologique** : Cette variable peut reflÃ©ter un **arbitrage endogÃ¨ne** entre revenus et qualitÃ© de vie.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Inscription dans un Ã©tablissement d'enseignement\n",
    "\n",
    ">  **Variable exogÃ¨ne** : Le statut d'Ã©tudiant est une caractÃ©ristique individuelle prÃ©existante. L'interprÃ©tation causale est justifiÃ©e.\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : Non inscrit dans un Ã©tablissement d'enseignement\n",
    "\n",
    "| Variable | Effet marginal | Odds Ratio |\n",
    "|----------|:--------------:|:----------:|\n",
    "| Ã‰tudiant | -2,08 pp***    | 0,76 |\n",
    "\n",
    "### Lecture des rÃ©sultats\n",
    "\n",
    "- Toutes choses Ã©gales par ailleurs, **Ãªtre inscrit dans un Ã©tablissement d'enseignement diminue la probabilitÃ© d'Ãªtre transfrontalier de 2,08 points de pourcentage**.\n",
    "- **Les chances d'Ãªtre transfrontalier sont rÃ©duites de 24% pour les Ã©tudiants** (OR = 0,76).\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "Les Ã©tudiants, mÃªme en emploi, sont moins susceptibles d'Ãªtre transfrontaliers car :\n",
    "\n",
    "- Leurs emplois sont souvent **temporaires et locaux** (jobs Ã©tudiants)\n",
    "- La **contrainte de prÃ©sence** aux cours limite la mobilitÃ© gÃ©ographique\n",
    "- Les **stages frontaliers** sont captÃ©s par la variable EMPL_14 (stagiaires rÃ©munÃ©rÃ©s, effet positif)\n",
    "\n",
    "---\n",
    "\n",
    "## 10. SynthÃ¨se des dÃ©terminants\n",
    "\n",
    "### 10.1 Facteurs favorisant le travail transfrontalier (variables exogÃ¨nes)\n",
    "\n",
    "| Rang | DÃ©terminant                | Effet marginal | Odds Ratio | InterprÃ©tation |\n",
    "|:----:|-------------               |:--------------:|:----------:|----------------|\n",
    "| 1 | RÃ©sider en Moselle            | +15,35 pp      | 4,71 | ProximitÃ© Luxembourg |\n",
    "| 2 | RÃ©sider dans le Haut-Rhin     | +13,17 pp      | 3,87 | ProximitÃ© Suisse/Allemagne |\n",
    "| 3 | RÃ©sider en Meurthe-et-Moselle | +12,22 pp      | 3,56 | ProximitÃ© Luxembourg |\n",
    "| 4 | ÃŠtre de nationalitÃ© Ã©trangÃ¨re | +3,12 pp       | 1,56 | RÃ©seaux transnationaux |\n",
    "| 5 | ÃŠtre nÃ© Ã  l'Ã©tranger          | +2,20 pp       | 1,40 | CompÃ©tences linguistiques |\n",
    "| 6 | Doctorat ou Master            | +1,4 Ã  +1,5 pp | 1,19-1,21 | Postes qualifiÃ©s |\n",
    "| 7 | ÃŠtre ouvrier                  | +0,59 pp       | 1,08 | Demande industrielle |\n",
    "| 8 | Ã‚ge ~40 ans                   | Optimum |   â€”  | ExpÃ©rience + mobilitÃ© |\n",
    "\n",
    "### 10.2 Facteurs freinant le travail transfrontalier (variables exogÃ¨nes)\n",
    "\n",
    "| Rang | DÃ©terminant                | Effet marginal | Odds Ratio | InterprÃ©tation |\n",
    "|:----:|-------------               |:--------------:|:----------:|----------------|\n",
    "| 1 | Travailler dans l'agriculture | -6,01 pp       | 0,44 | Ancrage territorial |\n",
    "| 2 | Secteur public                | -4,16 pp       | 0,55 | Emplois nationaux |\n",
    "| 3 | Pas de scolaritÃ©              | -3,28 pp       | 0,62 | BarriÃ¨res Ã  l'emploi |\n",
    "| 4 | ÃŠtre Ã©tudiant                 | -2,08 pp       | 0,76 | Emplois temporaires |\n",
    "| 5 | Artisan, commerÃ§ant           | -1,93 pp       | 0,77 | ClientÃ¨le locale |\n",
    "| 6 | 4+ enfants                    | -1,34 pp       | 0,83 | Contrainte familiale |\n",
    "| 7 | ÃŠtre femme                    | -0,79 pp       | 0,88 | Charge familiale |\n",
    "\n",
    "### 10.3 Variables associÃ©es (endogÃ¨nes ou ambiguÃ«s â€” interprÃ©tation prudente)\n",
    "\n",
    "| Variable            | Effet marginal | Odds Ratio | Risque d'endogÃ©nÃ©itÃ© |\n",
    "|----------           |:--------------:|:----------:|----------------------|\n",
    "| Aucune voiture      | -2,04 pp       | 0,76 | ğŸ”´ Ã‰levÃ© |\n",
    "| Locataire HLM       | -3,11 pp       | 0,64 | ğŸ”´ Ã‰levÃ© |\n",
    "| PropriÃ©taire (rÃ©f.) | â€”              | â€”    | ğŸ”´ Ã‰levÃ© |\n",
    "| Maison (rÃ©f.)       | â€”              | â€”    | ğŸ”´ Ã‰levÃ© |\n",
    "| Temps partiel       | +0,77 pp       | 1,10 | ğŸŸ¡ ModÃ©rÃ© |\n",
    "| CDI (rÃ©f.)          | â€”              | â€”    | ğŸŸ¡ ModÃ©rÃ© |\n",
    "\n",
    "---\n",
    "\n",
    "## 11. QualitÃ© de l'estimation Ã©conomÃ©trique\n",
    "\n",
    "### 11.1 Indicateurs de qualitÃ© globale\n",
    "\n",
    "| Indicateur | Valeur | InterprÃ©tation |\n",
    "|------------|:------:|----------------|\n",
    "| **Nombre d'observations** | 494 483 | Ã‰chantillon trÃ¨s large, puissance statistique Ã©levÃ©e |\n",
    "| **Pseudo RÂ² (McFadden)** | 0,2393 | Bon ajustement pour un modÃ¨le binaire sur donnÃ©es individuelles |\n",
    "| **Log-vraisemblance** | -113 380 | â€” |\n",
    "| **Log-vraisemblance nulle** | -149 050 | â€” |\n",
    "| **Test LR (Ï‡Â²)** | 71 340 | â€” |\n",
    "| **p-value LR** | < 0,001 | ModÃ¨le globalement trÃ¨s significatif |\n",
    "| **Convergence** | Oui (10 itÃ©rations) | Algorithme stable |\n",
    "\n",
    "### 11.2 InterprÃ©tation du Pseudo RÂ²\n",
    "\n",
    "Un Pseudo RÂ² de McFadden de **0,24** est considÃ©rÃ© comme **bon** pour un modÃ¨le de choix discret sur donnÃ©es individuelles. Ã€ titre de comparaison :\n",
    "\n",
    "Un Pseudo RÂ² entre 0,20 et 0,40 est gÃ©nÃ©ralement jugÃ© satisfaisant en Ã©conomÃ©trie des choix\n",
    "Ce critÃ¨re mesure l'ajustement global mais ne suffit pas Ã  Ã©valuer la capacitÃ© prÃ©dictive\n",
    "\n",
    "Les mÃ©triques complÃ©mentaires prÃ©sentÃ©es ci-dessous (AUC-ROC, Brier Score, validation croisÃ©e) confirment que le modÃ¨le discrimine efficacement les travailleurs transfrontaliers des non-transfrontaliers et ne souffre pas de sur-ajustement.\n",
    "\n",
    "### 11.3 SignificativitÃ© des variables \n",
    "\n",
    "| CatÃ©gorie                             | Nombre |\n",
    "|-----------                            |:------:|\n",
    "| Variables significatives au seuil 1%  | 56 / 65|\n",
    "| Variables significatives au seuil 5%  | 2 / 65 |\n",
    "| Variables significatives au seuil 10% | 2 / 65 |\n",
    "| Variables non significatives          | 5 / 65 |\n",
    "\n",
    "**Variables non significatives** : GS_1 (agriculteurs exploitants), DEPT_10 (Aube), DEPT_52 (Haute-Marne), NA5_BE (industrie), TYPL_5 (habitation de fortune).\n",
    "\n",
    "Ces non-significativitÃ©s sont cohÃ©rentes Ã©conomiquement (effectifs faibles ou absence de diffÃ©rence rÃ©elle avec la rÃ©fÃ©rence).\n",
    "\n",
    "### 11.4 Pouvoir discriminant et calibration\n",
    "\n",
    "La qualitÃ© prÃ©dictive du modÃ¨le est Ã©valuÃ©e par des mÃ©triques complÃ©mentaires au Pseudo RÂ².\n",
    "\n",
    "L'**AUC-ROC** atteint **0,849** avec un intervalle de confiance bootstrap de [0,848 ; 0,850], ce qui correspond Ã  une excellente capacitÃ© discriminante selon les seuils conventionnels (un AUC supÃ©rieur Ã  0,8 est gÃ©nÃ©ralement considÃ©rÃ© comme trÃ¨s bon). ConcrÃ¨tement, le modÃ¨le classe correctement 84,9 % des paires (transfrontalier, non-transfrontalier) tirÃ©es au hasard.\n",
    "\n",
    "Le **Brier Score** s'Ã©tablit Ã  **0,0681**, contre 0,0815 pour le modÃ¨le nul (correspondant Ã  la prÃ©valence de 8,95 %). Le modÃ¨le estimÃ© rÃ©duit donc l'erreur de prÃ©diction de **16,4 %** par rapport Ã  une prÃ©diction naÃ¯ve. Le **Brier Skill Score** associÃ© de **0,164** indique un pouvoir prÃ©dictif modeste mais significatif.\n",
    "\n",
    "Enfin, la **calibration par dÃ©ciles** rÃ©vÃ¨le une adÃ©quation quasi-parfaite entre les probabilitÃ©s prÃ©dites et les frÃ©quences observÃ©es. L'Ã©cart absolu moyen entre les deux n'est que de **0,0033**, soit 0,33 point de pourcentage. Cela signifie que le modÃ¨le ne sur-estime ni ne sous-estime systÃ©matiquement les probabilitÃ©s : un individu auquel le modÃ¨le attribue une probabilitÃ© de 20 % d'Ãªtre transfrontalier a effectivement environ 20 % de chances de l'Ãªtre dans les donnÃ©es observÃ©es.\n",
    "\n",
    "## 11.5 â€” Validation croisÃ©e et stabilitÃ©\n",
    "\n",
    "La robustesse du modÃ¨le est testÃ©e par validation croisÃ©e stratifiÃ©e Ã  5 plis (*5-fold cross-validation*).\n",
    "\n",
    "L'**AUC moyenne** obtenue sur les 5 plis est de **0,841** avec un Ã©cart-type de seulement **0,004**. Cette trÃ¨s faible dispersion entre les plis confirme la stabilitÃ© du pouvoir discriminant du modÃ¨le. Le **Brier Score** en validation croisÃ©e s'Ã©tablit Ã  **0,069 Â± 0,0003**, quasi-identique Ã  l'estimation sur l'Ã©chantillon complet.\n",
    "\n",
    "L'Ã©cart-type inter-plis infÃ©rieur Ã  **0,5 %** permet de conclure Ã  l'**absence de sur-ajustement**. Le modÃ¨le gÃ©nÃ©ralise bien Ã  des donnÃ©es non utilisÃ©es pour l'estimation, et les coefficients ne sont pas le fruit d'un ajustement excessif aux particularitÃ©s de l'Ã©chantillon.\n",
    "\n",
    "L'AUC en validation croisÃ©e (0,841) reste trÃ¨s proche de l'AUC sur l'Ã©chantillon complet (0,849), Ã©cartant tout risque d'optimisme excessif dans l'Ã©valuation du modÃ¨le. La performance prÃ©dictive est donc **reproductible** sur diffÃ©rentes partitions des donnÃ©es.\n",
    "\n",
    "## 11.6 â€” Robustesse des coefficients\n",
    "\n",
    "La stabilitÃ© des estimations a Ã©tÃ© vÃ©rifiÃ©e selon trois approches complÃ©mentaires.\n",
    "\n",
    "**Exclusion des variables potentiellement endogÃ¨nes.** L'exclusion des 15 variables prÃ©sentant un risque de causalitÃ© inverse (motorisation, statut d'occupation, type de logement, superficie) produit des coefficients trÃ¨s proches de l'estimation principale. La variation maximale observÃ©e est de **4,4 %** sur la variable SEXE_2 (Femme). Les effets gÃ©ographiques (dÃ©partements frontaliers) varient de moins de **1 %**, et l'effet de la nationalitÃ© Ã©trangÃ¨re de moins de **2 %**. Cette stabilitÃ© confirme que les variables exogÃ¨nes du modÃ¨le capturent des effets **structurels** et non des artefacts liÃ©s aux corrÃ©lations avec les variables endogÃ¨nes.\n",
    "\n",
    "**Estimations par sous-Ã©chantillons.** Le modÃ¨le a Ã©tÃ© rÃ©-estimÃ© sÃ©parÃ©ment sur les hommes (Pseudo RÂ² = 0,241, n = 252 847), les femmes (Pseudo RÂ² = 0,233, n = 241 636), les 25-44 ans (Pseudo RÂ² = 0,248, n = 212 156) et les 45-64 ans (Pseudo RÂ² = 0,237, n = 176 892). Les Pseudo RÂ² restent dans une fourchette Ã©troite (0,233 â€“ 0,248), attestant de la **robustesse structurelle** du modÃ¨le quel que soit le sous-groupe considÃ©rÃ©.\n",
    "\n",
    "**Comparaison Probit / Logit.** Les effets marginaux issus des spÃ©cifications Probit et Logit prÃ©sentent une corrÃ©lation de **0,995**, confirmant que les rÃ©sultats ne dÃ©pendent pas du choix de la fonction de lien.\n",
    "\n",
    "## 11.7 â€” Analyse des rÃ©sidus extrÃªmes\n",
    "\n",
    "**4,33 % des observations** (21 415 individus) prÃ©sentent des rÃ©sidus de Pearson gÃ©nÃ©ralisÃ©s supÃ©rieurs Ã  3 en valeur absolue. Ces cas correspondent Ã  des prÃ©dictions fortement Ã©loignÃ©es de la rÃ©alisation.\n",
    "\n",
    "Ces rÃ©sidus extrÃªmes sont concentrÃ©s dans les dÃ©partements frontaliers : la Moselle reprÃ©sente **15,5 %** des cas, le Haut-Rhin **12,2 %**, la Meurthe-et-Moselle **11,6 %** et le Bas-Rhin **9,8 %**. Cette rÃ©partition gÃ©ographique n'est pas le fruit du hasard : elle reflÃ¨te la forte hÃ©tÃ©rogÃ©nÃ©itÃ© intra-dÃ©partementale des comportements dans les zones proches des frontiÃ¨res.\n",
    "\n",
    "Ces observations ne constituent **pas des erreurs de mesure** ni des anomalies Ã  exclure. Elles reflÃ¨tent l'**hÃ©tÃ©rogÃ©nÃ©itÃ© rÃ©elle** de la population. Les faux nÃ©gatifs correspondent Ã  des individus rÃ©sidant en zone frontaliÃ¨re mais travaillant en France, pour des raisons de prÃ©fÃ©rences personnelles, d'emploi local attractif ou de contraintes familiales. Les faux positifs correspondent Ã  des individus rÃ©sidant loin des frontiÃ¨res mais travaillant nÃ©anmoins Ã  l'Ã©tranger, souvent liÃ©s Ã  des situations professionnelles spÃ©cifiques.\n",
    "\n",
    "La concentration des rÃ©sidus extrÃªmes dans les dÃ©partements frontaliers illustre les **limites intrinsÃ¨ques** d'un modÃ¨le probabiliste : mÃªme avec des caractÃ©ristiques observables identiques, les choix individuels demeurent partiellement irrÃ©ductibles aux variables du modÃ¨le.\n",
    "\n",
    "---\n",
    "\n",
    "## 12. Limites mÃ©thodologiques et extensions futures\n",
    "\n",
    "### 12.1 Limites du modÃ¨le actuel\n",
    "\n",
    "#### EndogÃ©nÃ©itÃ© de certaines variables\n",
    "\n",
    "Plusieurs variables explicatives (propriÃ©tÃ©, motorisation, type de logement) sont potentiellement **endogÃ¨nes** : elles peuvent Ãªtre des consÃ©quences plutÃ´t que des causes du travail transfrontalier. Sans correction, les coefficients estimÃ©s sont **biaisÃ©s** et ne permettent pas d'infÃ©rence causale.\n",
    "\n",
    "#### Imperfections de la forme fonctionnelle\n",
    "\n",
    "Les tests de spÃ©cification classiques (Link test de Pregibon, Hosmer-Lemeshow) rejettent l'hypothÃ¨se nulle, suggÃ©rant que la forme fonctionnelle du modÃ¨le Probit n'est pas parfaitement adaptÃ©e aux donnÃ©es. Bien que ces signaux soient mÃ©caniquement amplifiÃ©s par la taille de l'Ã©chantillon (prÃ¨s de 500 000 observations), ils rappellent que la spÃ©cification retenue demeure une **approximation** de la rÃ©alitÃ©. En particulier, la concentration gÃ©ographique extrÃªme du phÃ©nomÃ¨ne â€” 90 % des transfrontaliers dans 4 dÃ©partements â€” pourrait justifier des modÃ©lisations alternatives intÃ©grant une structure spatiale explicite.\n",
    "\n",
    "#### Variables omises\n",
    "\n",
    "Le modÃ¨le n'inclut pas :\n",
    "- La **distance prÃ©cise Ã  la frontiÃ¨re** (seul le dÃ©partement est disponible)\n",
    "- Les **compÃ©tences linguistiques** (allemand, luxembourgeois)\n",
    "- Le **diffÃ©rentiel salarial individuel** entre emploi local et frontalier\n",
    "- Les **prÃ©fÃ©rences individuelles** (aversion aux trajets, attachement territorial)\n",
    "\n",
    "#### HÃ©tÃ©rogÃ©nÃ©itÃ© non observÃ©e\n",
    "\n",
    "Des caractÃ©ristiques individuelles non mesurÃ©es (motivation, rÃ©seau professionnel, santÃ©) peuvent influencer simultanÃ©ment le choix de rÃ©sidence et le travail frontalier.\n",
    "\n",
    "#### Coupe transversale\n",
    "\n",
    "L'analyse sur une seule annÃ©e (2022) ne permet pas d'Ã©tudier les dynamiques temporelles (entrÃ©es/sorties du travail frontalier, effets de la conjoncture).\n",
    "\n",
    "---\n",
    "\n",
    "### 12.2 Extensions futures recommandÃ©es\n",
    "\n",
    "#### 1. Traitement de l'endogÃ©nÃ©itÃ©\n",
    "\n",
    "| MÃ©thode | Principe | Application possible |\n",
    "|---------|----------|----------------------|\n",
    "| **Probit Ã  Variables Instrumentales (IV Probit)** | Trouver un instrument Z affectant la variable endogÃ¨ne mais pas Y directement | Instrument potentiel : taux de propriÃ©taires dans la commune d'origine |\n",
    "| **Control Function Approach** | Inclure les rÃ©sidus de la 1Ã¨re Ã©tape dans le probit | Permet de tester l'endogÃ©nÃ©itÃ© |\n",
    "| **Probit bivariÃ© rÃ©cursif** | ModÃ©liser simultanÃ©ment P(propriÃ©taire) et P(transfrontalier) | Identification par restrictions d'exclusion |\n",
    "\n",
    "#### 2. ModÃ¨le Probit avec interactions par genre (prÃ©vu)\n",
    "\n",
    "Objectif : Tester si les dÃ©terminants ont des **effets diffÃ©renciÃ©s** selon le sexe.\n",
    "\n",
    "SpÃ©cification :\n",
    "$$P(Y_i = 1) = \\Phi(\\beta_0 + \\beta_1 Femme_i + \\beta_2 X_i + \\beta_3 (Femme_i \\times X_i))$$\n",
    "\n",
    "Permettra de rÃ©pondre Ã  : *L'effet des enfants est-il plus fort pour les femmes ?*\n",
    "\n",
    "#### 3. ModÃ¨le Probit bivariÃ© pour les couples (prÃ©vu)\n",
    "\n",
    "Objectif : Tester la **coordination des dÃ©cisions** au sein des couples.\n",
    "\n",
    "SpÃ©cification :\n",
    "$$Y_{1i}^* = X_{1i}'\\beta_1 + \\varepsilon_{1i}$$\n",
    "$$Y_{2i}^* = X_{2i}'\\beta_2 + \\varepsilon_{2i}$$\n",
    "\n",
    "avec $\\text{Corr}(\\varepsilon_1, \\varepsilon_2) = \\rho$\n",
    "\n",
    "Permettra de rÃ©pondre Ã  : *Les choix professionnels des conjoints sont-ils coordonnÃ©s ?*\n",
    "\n",
    "\n",
    "#### 5. Extensions de donnÃ©es\n",
    "\n",
    "- **Panel** : Suivre les individus sur plusieurs annÃ©es pour identifier les transitions vers le travail frontalier\n",
    "- **Variables gÃ©ographiques fines** : Distance Ã  la frontiÃ¨re, accessibilitÃ© routiÃ¨re\n",
    "- **Variables fiscales** : Revenus individuels pour calculer le diffÃ©rentiel salarial\n",
    "\n",
    "---\n",
    "\n",
    "## 13. Conclusion\n",
    "\n",
    "Cette analyse Ã©conomÃ©trique met en Ã©vidence une **hiÃ©rarchie claire des dÃ©terminants** du travail transfrontalier dans le Grand Est :\n",
    "\n",
    "1. **La gÃ©ographie domine** : rÃ©sider dans un dÃ©partement frontalier (Moselle, Haut-Rhin, Meurthe-et-Moselle) est le facteur le plus dÃ©terminant, avec des effets marginaux de 12 Ã  15 points de pourcentage et des odds ratios de 3,5 Ã  4,7.\n",
    "\n",
    "2. **Les rÃ©seaux transnationaux comptent** : la nationalitÃ© Ã©trangÃ¨re (+3,1 pp) et la naissance Ã  l'Ã©tranger (+2,2 pp) facilitent l'accÃ¨s au travail frontalier, probablement via les compÃ©tences linguistiques et les connexions sociales.\n",
    "\n",
    "3. **Le profil socioprofessionnel sÃ©lectionne** : le travail frontalier concerne prioritairement les ouvriers en CDI (+0,6 pp) et les cadres trÃ¨s diplÃ´mÃ©s (+1,4 Ã  +1,5 pp), tout en excluant les indÃ©pendants (-3,6 pp), le secteur public (-4,2 pp) et les formes d'emploi prÃ©caires.\n",
    "\n",
    "4. **La famille contraint** : chaque enfant supplÃ©mentaire rÃ©duit la probabilitÃ© d'Ãªtre transfrontalier de 0,3 Ã  0,4 point de pourcentage, avec une accÃ©lÃ©ration au-delÃ  de deux enfants.\n",
    "\n",
    "5. **Le genre et l'Ã¢ge structurent les comportements** : les femmes prÃ©sentent une probabilitÃ© infÃ©rieure de 0,8 point de pourcentage, toutes choses Ã©gales par ailleurs. La probabilitÃ© suit une courbe en U inversÃ© avec un maximum autour de 41 ans, reflÃ©tant l'arbitrage entre accumulation d'expÃ©rience et pÃ©nibilitÃ© croissante des trajets.\n",
    "\n",
    "6. **Les variables de logement et motorisation sont associÃ©es** au travail frontalier (propriÃ©tÃ©, maison individuelle, multi-motorisation), mais le sens de la causalitÃ© reste incertain : ces caractÃ©ristiques peuvent Ãªtre des consÃ©quences des revenus frontaliers plutÃ´t que des causes.\n",
    "\n",
    "7. **Le modÃ¨le est statistiquement robuste** : avec une AUC-ROC de 0,849 et une calibration quasi-parfaite (Ã©cart moyen de 0,33 point de pourcentage), le modÃ¨le discrimine efficacement les profils transfrontaliers. La validation croisÃ©e Ã  5 plis (AUC = 0,841 Â± 0,004) confirme l'absence de sur-ajustement. Les coefficients demeurent stables lors de l'exclusion des variables potentiellement endogÃ¨nes.\n",
    "\n",
    "Ces rÃ©sultats fournissent une base solide pour les extensions prÃ©vues : le **probit avec interactions par genre** permettra d'identifier si les dÃ©terminants (notamment la prÃ©sence d'enfants) affectent diffÃ©remment les hommes et les femmes ; le **probit bivariÃ©** testera la coordination des dÃ©cisions professionnelles au sein des couples.\n",
    "\n",
    "\n",
    "Ces rÃ©sultats fournissent une base solide pour l'estimation des modÃ¨les complÃ©mentaires prÃ©vus (probit avec interactions par genre, probit bivariÃ© pour les dÃ©cisions de couple) et pour l'Ã©laboration de recommandations en matiÃ¨re de politique publique (transport, garde d'enfants, formation linguistique).\n",
    "\n",
    "---\n",
    "\n",
    "*Rapport rÃ©digÃ© le 7 janvier 2026 â€” Projet INSEE MobilitÃ© TransfrontaliÃ¨re Grand Est\n",
    "*Romain Mehdi FEHRI\n",
    "*Master 2 Statistique, Ã‰conomÃ©trie & Data Science â€” UniversitÃ© de Strasbourg*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
