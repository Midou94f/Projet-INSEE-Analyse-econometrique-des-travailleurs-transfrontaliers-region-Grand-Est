{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "836d5ec1",
   "metadata": {},
   "source": [
    "# PROJET INSEE PARTIE (III) - RÃ‰GRESSION PROBIT BINAIRE - MOBILITÃ‰ TRANSFRONTALIÃˆRE\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Ce notebook constitue la **troisiÃ¨me partie** du projet d'analyse des dÃ©terminants du travail transfrontalier dans la rÃ©gion Grand Est. Il s'inscrit dans une dÃ©marche Ã©conomÃ©trique en trois temps :\n",
    "\n",
    "| Ã‰tape         | ModÃ¨le                   | Objectif                                         | Statut         |\n",
    "|---------------|--------------------------|--------------------------------------------------|----------------|\n",
    "| **Partie 1**  | â€”                        | PrÃ©paration et validation de la base de donnÃ©es  | âœ… TerminÃ©      |\n",
    "| **Partie 2**  | Elastic Net              | SÃ©lection des variables pertinentes              | âœ… TerminÃ©      |\n",
    "| **Partie 3**  | Probit binaire simple    | Estimation des dÃ©terminants individuels          | ğŸ“ Ce notebook |\n",
    "| Partie 4      | Probit avec interactions | HÃ©tÃ©rogÃ©nÃ©itÃ© des effets selon le genre          | Ã€ venir        |\n",
    "| Partie 5      | Probit bivariÃ©           | Coordination des dÃ©cisions au sein des couples   | Ã€ venir        |\n",
    "\n",
    "---\n",
    "\n",
    "## Objectif de cette partie\n",
    "\n",
    "L'objectif est d'estimer un **modÃ¨le probit binaire** pour identifier les facteurs individuels qui influencent la probabilitÃ© d'exercer une activitÃ© professionnelle hors de France (Luxembourg, Allemagne, Suisse, Belgique).\n",
    "\n",
    "La variable dÃ©pendante est :\n",
    "\n",
    "$$Y_i = \\begin{cases} 1 & \\text{si l'individu } i \\text{ est travailleur transfrontalier} \\\\ 0 & \\text{sinon} \\end{cases}$$\n",
    "\n",
    "Le modÃ¨le estimÃ© est :\n",
    "\n",
    "$$P(Y_i = 1 \\mid X_i) = \\Phi(X_i' \\beta)$$\n",
    "\n",
    "oÃ¹ $\\Phi(\\cdot)$ dÃ©signe la fonction de rÃ©partition de la loi normale centrÃ©e rÃ©duite.\n",
    "\n",
    "---\n",
    "\n",
    "## DonnÃ©es utilisÃ©es\n",
    "\n",
    "La base de donnÃ©es est issue de la fusion des fichiers INSEE **MOBPRO** (mobilitÃ© professionnelle) et **INDCVI** (caractÃ©ristiques individuelles) pour la rÃ©gion Grand Est.\n",
    "\n",
    "| CaractÃ©ristique                  | Valeur                |\n",
    "|----------------------------------|-----------------------|\n",
    "| Observations                     | 494 483               |\n",
    "| Variables explicatives           | 65 (aprÃ¨s exclusion rÃ©fÃ©rences) |\n",
    "| Transfrontaliers (Y = 1)         | 44 264 (8,95 %)       |\n",
    "| Non-transfrontaliers (Y = 0)     | 450 219 (91,05 %)     |\n",
    "\n",
    "Les variables explicatives ont Ã©tÃ© sÃ©lectionnÃ©es dans la partie prÃ©cÃ©dente via une rÃ©gression **Elastic Net** (AUC-ROC = 0.845), garantissant leur pertinence pour discriminer les deux populations.\n",
    "\n",
    "---\n",
    "\n",
    "## SpÃ©cification du modÃ¨le retenu\n",
    "\n",
    "La sÃ©lection de variables par Elastic Net (Partie 2) a identifiÃ© **17 variables conceptuelles** significatives, encodÃ©es en **65 features** aprÃ¨s exclusion des modalitÃ©s de rÃ©fÃ©rence.\n",
    "\n",
    "### Formulation mathÃ©matique\n",
    "\n",
    "Le modÃ¨le probit latent s'Ã©crit :\n",
    "\n",
    "$$Y^*_i = \\beta_0 + \\beta_1 \\text{AGE}_i + \\beta_2 \\text{AGE}^2_i + \\sum_k \\gamma_k D_{ki} + \\varepsilon_i, \\quad \\varepsilon_i \\sim \\mathcal{N}(0,1)$$\n",
    "\n",
    "avec $Y_i = \\mathbb{1}_{Y^*_i > 0}$ et oÃ¹ $D_{ki}$ dÃ©signe les indicatrices des variables catÃ©gorielles.\n",
    "\n",
    "### SpÃ©cification complÃ¨te\n",
    "\n",
    "$$\n",
    "Y^*_i = \\beta_0 + \\beta_1 \\text{AGEREV}_i + \\beta_2 \\text{AGEREV}^2_i + \\sum_{d \\neq 51} \\gamma_d \\mathbb{1}_{\\text{DEPT}=d} + \\sum_{g \\neq 5} \\delta_g \\mathbb{1}_{\\text{GS}=g} + \\sum_{e \\neq 16} \\eta_e \\mathbb{1}_{\\text{EMPL}=e} + \\ldots + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "Les 17 blocs de variables sont : **AGEREV** (+ terme quadratique), **DEPT**, **GS**, **EMPL**, **NA5**, **DIPL**, **SEXE**, **COUPLE**, **NENFR**, **INATC**, **DNAI**, **TP**, **ETUD**, **STOCD**, **VOIT**, **TYPL**, **SANI**.\n",
    "\n",
    "---\n",
    "\n",
    "### Variables explicatives retenues\n",
    "\n",
    "| CatÃ©gorie          | Variable   | Description                          | ModalitÃ©s | RÃ©fÃ©rence |\n",
    "|--------------------|------------|--------------------------------------|-----------|-----------|\n",
    "| **DÃ©mographie**    | AGEREV     | Ã‚ge rÃ©volu (+ terme quadratique)     | Continue  | â€” |\n",
    "|                    | SEXE       | Genre                                | 2         | Homme |\n",
    "| **GÃ©ographie**     | DEPT       | DÃ©partement de rÃ©sidence             | 10        | Marne (51) |\n",
    "|                    | DNAI       | Lieu de naissance                    | 3         | NÃ© Grand Est |\n",
    "| **Capital humain** | DIPL       | DiplÃ´me le plus Ã©levÃ©                | 12        | CAP/BEP |\n",
    "|                    | ETUD       | Inscription aux Ã©tudes               | 2         | Non inscrit |\n",
    "| **Emploi**         | GS         | Groupe socioprofessionnel            | 6         | EmployÃ©s |\n",
    "|                    | EMPL       | Condition d'emploi                   | 9         | CDI/Titulaire |\n",
    "|                    | NA5        | Secteur d'activitÃ© Ã©conomique        | 5         | Services |\n",
    "|                    | TP         | Temps de travail                     | 2         | Temps complet |\n",
    "| **Famille**        | COUPLE     | Vie en couple                        | 2         | Pas en couple |\n",
    "|                    | NENFR      | Nombre d'enfants dans le mÃ©nage      | 6         | 0 enfant |\n",
    "| **Logement**       | STOCD      | Statut d'occupation du logement      | 5         | PropriÃ©taire |\n",
    "|                    | TYPL       | Type de logement                     | 6         | Maison |\n",
    "|                    | SANI       | Installations sanitaires             | 4         | Standard |\n",
    "| **MobilitÃ©**       | VOIT       | Nombre de voitures du mÃ©nage         | 4         | 1 voiture |\n",
    "| **Origine**        | INATC      | NationalitÃ©                          | 2         | FranÃ§ais |\n",
    "\n",
    "**Total** : 17 variables conceptuelles â†’ 65 coefficients estimÃ©s (hors constante).\n",
    "\n",
    "---\n",
    "\n",
    "## Plan du notebook\n",
    "\n",
    "Ce notebook est organisÃ© en **12 sections** :\n",
    "\n",
    "| Section | Contenu |\n",
    "|---------|---------|\n",
    "| **1** | PrÃ©paration des donnÃ©es â€” Chargement, vÃ©rification, suppression des rÃ©fÃ©rences |\n",
    "| **2** | Estimation du modÃ¨le Probit â€” Maximum de vraisemblance (MLE) |\n",
    "| **3** | QualitÃ© de l'ajustement â€” Pseudo RÂ², AIC, BIC, LR test |\n",
    "| **4** | Calcul des effets marginaux â€” AME (Average Marginal Effects) |\n",
    "| **5** | Pouvoir discriminant â€” Courbe ROC, AUC, matrice de confusion |\n",
    "| **6** | Analyse de calibration â€” FiabilitÃ© des probabilitÃ©s prÃ©dites |\n",
    "| **7** | Validation croisÃ©e â€” Robustesse hors Ã©chantillon (5-fold CV) |\n",
    "| **8** | Tests de spÃ©cification â€” StabilitÃ© des coefficients |\n",
    "| **9** | Analyse des rÃ©sidus â€” Identification des profils atypiques |\n",
    "| **10** | Analyse Ã©conomique â€” InterprÃ©tation thÃ©matique des rÃ©sultats |\n",
    "| **11** | Limites mÃ©thodologiques â€” EndogÃ©nÃ©itÃ©, variables omises |\n",
    "| **12** | Conclusion â€” SynthÃ¨se et transition vers Partie 4 |\n",
    "\n",
    "---\n",
    "\n",
    "## Structure de l'analyse Ã©conomique (Section 10)\n",
    "\n",
    "L'interprÃ©tation des rÃ©sultats est organisÃ©e par **thÃ©matique Ã©conomique** :\n",
    "\n",
    "| Sous-section | ThÃ¨me | Variables analysÃ©es |\n",
    "|--------------|-------|---------------------|\n",
    "| 10.1 | Effets gÃ©ographiques | DEPT |\n",
    "| 10.2 | RÃ©seaux transnationaux | INATC, DNAI |\n",
    "| 10.3 | Profil dÃ©mographique | AGEREV, SEXE |\n",
    "| 10.4 | Situation familiale | NENFR, COUPLE |\n",
    "| 10.5 | CaractÃ©ristiques professionnelles | GS, NA5, EMPL |\n",
    "| 10.6 | Capital humain | DIPL, ETUD |\n",
    "| 10.7 | Variables potentiellement endogÃ¨nes | STOCD, VOIT, TYPL, TP |\n",
    "| 10.8 | SynthÃ¨se des dÃ©terminants | Classement par amplitude |\n",
    "\n",
    "---\n",
    "\n",
    "## Principaux rÃ©sultats attendus\n",
    "\n",
    "Cette analyse permettra de rÃ©pondre aux questions suivantes :\n",
    "\n",
    "- Quels dÃ©partements prÃ©sentent la plus forte propension au travail transfrontalier ?\n",
    "- Quel est l'effet du diplÃ´me, de l'Ã¢ge, du genre sur cette probabilitÃ© ?\n",
    "- La prÃ©sence d'enfants constitue-t-elle un frein Ã  la mobilitÃ© transfrontaliÃ¨re ?\n",
    "- Quels secteurs d'activitÃ© et statuts d'emploi favorisent le travail frontalier ?\n",
    "- Le modÃ¨le discrimine-t-il efficacement les deux populations ?\n",
    "\n",
    "Les rÃ©sultats serviront de **rÃ©fÃ©rence** pour les modÃ¨les suivants (interactions par genre, dÃ©cisions de couple), qui testeront l'hÃ©tÃ©rogÃ©nÃ©itÃ© des effets identifiÃ©s ici.\n",
    "\n",
    "---\n",
    "\n",
    "## Choix mÃ©thodologique : pourquoi le Probit ?\n",
    "\n",
    "Le choix du modÃ¨le Probit (plutÃ´t que Logit) est motivÃ© par :\n",
    "\n",
    "1. **CohÃ©rence avec le modÃ¨le structurel final** â€” Le probit bivariÃ© (Partie 5) n'a pas d'Ã©quivalent logit opÃ©rationnel\n",
    "2. **ComparabilitÃ© des coefficients** â€” MÃªme Ã©chelle d'estimation entre les trois modÃ¨les\n",
    "3. **InterprÃ©tation des interactions** â€” Effets marginaux homogÃ¨nes facilitant l'analyse genre Ã— covariables (Partie 4)\n",
    "\n",
    "---\n",
    "\n",
    "## Convention de lecture des rÃ©sultats\n",
    "\n",
    "Les rÃ©sultats sont prÃ©sentÃ©s en **effets marginaux moyens (AME)**, exprimÃ©s en **points de pourcentage (pp)**. L'AME mesure la variation moyenne de la probabilitÃ© d'Ãªtre transfrontalier associÃ©e Ã  un changement unitaire de la variable explicative.\n",
    "\n",
    "| MÃ©thode | Formule | Usage |\n",
    "|---------|---------|-------|\n",
    "| **MEM** | $\\phi(\\bar{X}'\\beta) \\times \\beta$ | Non utilisÃ© (individu fictif) |\n",
    "| **AME** | $\\frac{1}{n} \\sum_i \\phi(X_i'\\beta) \\times \\beta$ | **ReportÃ©** (effet moyen rÃ©el) |\n",
    "\n",
    "*Exemple* : Un AME de +5 pp signifie que la caractÃ©ristique considÃ©rÃ©e augmente en moyenne la probabilitÃ© d'Ãªtre transfrontalier de 5 points de pourcentage.\n",
    "\n",
    "---\n",
    "\n",
    "*Partie 3 â€” Projet INSEE MobilitÃ© TransfrontaliÃ¨re Grand Est*  \n",
    "*Master 2 Statistique, Ã‰conomÃ©trie & Data Science â€” UniversitÃ© de Strasbourg*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f35602",
   "metadata": {},
   "source": [
    "## Step 1 : PrÃ©paration de la base donnÃ©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8fcf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STRUCTURE DU FICHIER X_final_clean.csv\n",
      "================================================================================\n",
      "\n",
      "Dimensions : 494,483 lignes Ã— 81 colonnes\n",
      "\n",
      "================================================================================\n",
      "LISTE DES COLONNES\n",
      "================================================================================\n",
      "   1. AGEREV\n",
      "   2. AGEREV_sq\n",
      "   3. GS_1\n",
      "   4. GS_2\n",
      "   5. GS_3\n",
      "   6. GS_4\n",
      "   7. GS_5\n",
      "   8. GS_6\n",
      "   9. EMPL_11\n",
      "  10. EMPL_12\n",
      "  11. EMPL_13\n",
      "  12. EMPL_14\n",
      "  13. EMPL_15\n",
      "  14. EMPL_16\n",
      "  15. EMPL_21\n",
      "  16. EMPL_22\n",
      "  17. EMPL_23\n",
      "  18. INATC_1\n",
      "  19. INATC_2\n",
      "  20. COUPLE_1\n",
      "  21. COUPLE_2\n",
      "  22. NENFR_0\n",
      "  23. NENFR_1\n",
      "  24. NENFR_2\n",
      "  25. NENFR_3\n",
      "  26. NENFR_4\n",
      "  27. NENFR_Z\n",
      "  28. NA5_AZ\n",
      "  29. NA5_BE\n",
      "  30. NA5_FZ\n",
      "  31. NA5_GU\n",
      "  32. NA5_OQ\n",
      "  33. DIPL_1\n",
      "  34. DIPL_11\n",
      "  35. DIPL_12\n",
      "  36. DIPL_13\n",
      "  37. DIPL_14\n",
      "  38. DIPL_15\n",
      "  39. DIPL_16\n",
      "  40. DIPL_17\n",
      "  41. DIPL_18\n",
      "  42. DIPL_19\n",
      "  43. DIPL_2\n",
      "  44. DIPL_3\n",
      "  45. ETUD_1\n",
      "  46. ETUD_2\n",
      "  47. SANI_0\n",
      "  48. SANI_1\n",
      "  49. SANI_2\n",
      "  50. SANI_X\n",
      "  51. SEXE_1\n",
      "  52. SEXE_2\n",
      "  53. TP_1\n",
      "  54. TP_2\n",
      "  55. DEPT_10\n",
      "  56. DEPT_51\n",
      "  57. DEPT_52\n",
      "  58. DEPT_54\n",
      "  59. DEPT_55\n",
      "  60. DEPT_57\n",
      "  61. DEPT_67\n",
      "  62. DEPT_68\n",
      "  63. DEPT_88\n",
      "  64. STOCD_10.0\n",
      "  65. STOCD_21.0\n",
      "  66. STOCD_22.0\n",
      "  67. STOCD_23.0\n",
      "  68. STOCD_30.0\n",
      "  69. VOIT_0.0\n",
      "  70. VOIT_1.0\n",
      "  71. VOIT_2.0\n",
      "  72. VOIT_3.0\n",
      "  73. TYPL_1.0\n",
      "  74. TYPL_2.0\n",
      "  75. TYPL_3.0\n",
      "  76. TYPL_4.0\n",
      "  77. TYPL_5.0\n",
      "  78. TYPL_6.0\n",
      "  79. DNAI_NEAUTREFR\n",
      "  80. DNAI_NEETRANGER\n",
      "  81. DNAI_NEGRANDEST\n",
      "\n",
      "================================================================================\n",
      "TYPES DE DONNÃ‰ES\n",
      "================================================================================\n",
      "AGEREV             int64\n",
      "AGEREV_sq          int64\n",
      "GS_1               int64\n",
      "GS_2               int64\n",
      "GS_3               int64\n",
      "                   ...  \n",
      "TYPL_5.0           int64\n",
      "TYPL_6.0           int64\n",
      "DNAI_NEAUTREFR     int64\n",
      "DNAI_NEETRANGER    int64\n",
      "DNAI_NEGRANDEST    int64\n",
      "Length: 81, dtype: object\n",
      "\n",
      "================================================================================\n",
      "APERÃ‡U (5 premiÃ¨res lignes)\n",
      "================================================================================\n",
      "   AGEREV  AGEREV_sq  GS_1  GS_2  GS_3  GS_4  GS_5  GS_6  EMPL_11  EMPL_12  \\\n",
      "0      35       1225     0     0     0     0     0     1        0        0   \n",
      "1      40       1600     0     0     0     0     0     1        0        0   \n",
      "2      44       1936     0     0     0     0     0     1        0        0   \n",
      "3      62       3844     0     0     0     1     0     0        0        0   \n",
      "4      59       3481     1     0     0     0     0     0        0        0   \n",
      "\n",
      "   ...  VOIT_3.0  TYPL_1.0  TYPL_2.0  TYPL_3.0  TYPL_4.0  TYPL_5.0  TYPL_6.0  \\\n",
      "0  ...         0         1         0         0         0         0         0   \n",
      "1  ...         1         1         0         0         0         0         0   \n",
      "2  ...         1         1         0         0         0         0         0   \n",
      "3  ...         0         1         0         0         0         0         0   \n",
      "4  ...         0         1         0         0         0         0         0   \n",
      "\n",
      "   DNAI_NEAUTREFR  DNAI_NEETRANGER  DNAI_NEGRANDEST  \n",
      "0               1                0                0  \n",
      "1               0                1                0  \n",
      "2               0                1                0  \n",
      "3               0                0                1  \n",
      "4               0                0                1  \n",
      "\n",
      "[5 rows x 81 columns]\n",
      "\n",
      "================================================================================\n",
      "STATISTIQUES\n",
      "================================================================================\n",
      "                    count         mean          std    min    25%     50%  \\\n",
      "AGEREV           494483.0    41.478560    12.471631   15.0   31.0    42.0   \n",
      "AGEREV_sq        494483.0  1876.012229  1053.827441  225.0  961.0  1764.0   \n",
      "GS_1             494483.0     0.012114     0.109394    0.0    0.0     0.0   \n",
      "GS_2             494483.0     0.056637     0.231148    0.0    0.0     0.0   \n",
      "GS_3             494483.0     0.162653     0.369049    0.0    0.0     0.0   \n",
      "...                   ...          ...          ...    ...    ...     ...   \n",
      "TYPL_5.0         494483.0     0.000562     0.023704    0.0    0.0     0.0   \n",
      "TYPL_6.0         494483.0     0.000677     0.026020    0.0    0.0     0.0   \n",
      "DNAI_NEAUTREFR   494483.0     0.144130     0.351222    0.0    0.0     0.0   \n",
      "DNAI_NEETRANGER  494483.0     0.127818     0.333888    0.0    0.0     0.0   \n",
      "DNAI_NEGRANDEST  494483.0     0.728051     0.444964    0.0    0.0     1.0   \n",
      "\n",
      "                    75%      max  \n",
      "AGEREV             52.0    101.0  \n",
      "AGEREV_sq        2704.0  10201.0  \n",
      "GS_1                0.0      1.0  \n",
      "GS_2                0.0      1.0  \n",
      "GS_3                0.0      1.0  \n",
      "...                 ...      ...  \n",
      "TYPL_5.0            0.0      1.0  \n",
      "TYPL_6.0            0.0      1.0  \n",
      "DNAI_NEAUTREFR      0.0      1.0  \n",
      "DNAI_NEETRANGER     0.0      1.0  \n",
      "DNAI_NEGRANDEST     1.0      1.0  \n",
      "\n",
      "[81 rows x 8 columns]\n",
      "\n",
      "================================================================================\n",
      "VALEURS MANQUANTES\n",
      "================================================================================\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier X\n",
    "X = pd.read_csv('/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/ML_READY/FINAL_AFTER_ARBITRAGES/X_final_clean.csv')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STRUCTURE DU FICHIER X_final_clean.csv\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nDimensions : {X.shape[0]:,} lignes Ã— {X.shape[1]} colonnes\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LISTE DES COLONNES\")\n",
    "print(\"=\"*80)\n",
    "for i, col in enumerate(X.columns):\n",
    "    print(f\"  {i+1:>2}. {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TYPES DE DONNÃ‰ES\")\n",
    "print(\"=\"*80)\n",
    "print(X.dtypes)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"APERÃ‡U (5 premiÃ¨res lignes)\")\n",
    "print(\"=\"*80)\n",
    "print(X.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTIQUES\")\n",
    "print(\"=\"*80)\n",
    "print(X.describe().T)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VALEURS MANQUANTES\")\n",
    "print(\"=\"*80)\n",
    "print(X.isnull().sum()[X.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944719ad",
   "metadata": {},
   "source": [
    "# Choix des catÃ©gories de rÃ©fÃ©rences + check vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb4c143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DIAGNOSTIC PRÃ‰-PROBIT : 17 VARIABLES CONCEPTUELLES\n",
      "================================================================================\n",
      "\n",
      "Base : 494,483 obs | Transfrontaliers : 44,264 (8.95%)\n",
      "\n",
      "================================================================================\n",
      "1. STRUCTURE : 81 DUMMIES â†’ 17 VARIABLES CONCEPTUELLES\n",
      "================================================================================\n",
      "\n",
      "Variable conceptuelle   Nb dummies Colonnes\n",
      "--------------------------------------------------------------------------------\n",
      "AGEREV                     2 AGEREV, AGEREV_sq\n",
      "COUPLE                     2 COUPLE_1, COUPLE_2\n",
      "DEPT                       9 DEPT_10, DEPT_51, DEPT_52 ... (+6)\n",
      "DIPL                      12 DIPL_1, DIPL_11, DIPL_12 ... (+9)\n",
      "DNAI                       3 DNAI_NEAUTREFR, DNAI_NEETRANGER, DNAI_NEGRANDEST\n",
      "EMPL                       9 EMPL_11, EMPL_12, EMPL_13 ... (+6)\n",
      "ETUD                       2 ETUD_1, ETUD_2\n",
      "GS                         6 GS_1, GS_2, GS_3 ... (+3)\n",
      "INATC                      2 INATC_1, INATC_2\n",
      "NA5                        5 NA5_AZ, NA5_BE, NA5_FZ ... (+2)\n",
      "NENFR                      6 NENFR_0, NENFR_1, NENFR_2 ... (+3)\n",
      "SANI                       4 SANI_0, SANI_1, SANI_2 ... (+1)\n",
      "SEXE                       2 SEXE_1, SEXE_2\n",
      "STOCD                      5 STOCD_10.0, STOCD_21.0, STOCD_22.0 ... (+2)\n",
      "TP                         2 TP_1, TP_2\n",
      "TYPL                       6 TYPL_1.0, TYPL_2.0, TYPL_3.0 ... (+3)\n",
      "VOIT                       4 VOIT_0.0, VOIT_1.0, VOIT_2.0 ... (+1)\n",
      "\n",
      "================================================================================\n",
      "2. MODALITÃ‰S PAR VARIABLE (effectifs + taux transfrontalier)\n",
      "================================================================================\n",
      "â†’ Pour choisir la CATÃ‰GORIE DE RÃ‰FÃ‰RENCE du Probit\n",
      "\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š AGEREV (2 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Type: CONTINUE\n",
      "  Moyenne: 41.5 ans | Ã‰cart-type: 12.5\n",
      "  Min: 15 | Max: 101\n",
      "  â†’ Pas de catÃ©gorie de rÃ©fÃ©rence (variable continue)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š COUPLE (2 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  1                         325,880    65.9%           9.7% â† REF (plus frÃ©quente)\n",
      "  2                         168,603    34.1%           7.5% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š DEPT (9 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  67                        118,398    23.9%           4.6% â† REF (plus frÃ©quente)\n",
      "  57                         98,869    20.0%          21.6% \n",
      "  68                         73,587    14.9%          14.1% \n",
      "  54                         64,924    13.1%           9.7% \n",
      "  51                         53,239    10.8%           0.1% \n",
      "  88                         29,098     5.9%           0.2% \n",
      "  10                         27,234     5.5%           0.1% \n",
      "  55                         14,885     3.0%           4.7% \n",
      "  52                         14,249     2.9%           0.1% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š DIPL (12 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  13                        117,859    23.8%           9.6% â† REF (plus frÃ©quente)\n",
      "  16                         75,404    15.2%           7.9% \n",
      "  18                         65,128    13.2%          10.7% \n",
      "  17                         63,260    12.8%           8.3% \n",
      "  15                         56,154    11.4%           8.7% \n",
      "  14                         50,473    10.2%           7.8% \n",
      "  3                          26,638     5.4%           9.1% \n",
      "  12                         16,298     3.3%           8.1% \n",
      "  2                          10,348     2.1%           8.1% \n",
      "  19                          5,428     1.1%          11.2% \n",
      "  11                          4,062     0.8%          12.0% \n",
      "  1                           3,431     0.7%           5.4% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š DNAI (3 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  NEGRANDEST                360,009    72.8%           8.1% â† REF (plus frÃ©quente)\n",
      "  NEAUTREFR                  71,270    14.4%           5.8% \n",
      "  NEETRANGER                 63,204    12.8%          17.5% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š EMPL (9 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  16                        374,974    75.8%          10.4% â† REF (plus frÃ©quente)\n",
      "  15                         40,025     8.1%           5.7% \n",
      "  21                         29,943     6.1%           2.6% \n",
      "  22                         20,770     4.2%           3.6% \n",
      "  11                         14,172     2.9%           1.8% \n",
      "  12                         10,308     2.1%          10.8% \n",
      "  13                          2,437     0.5%           1.3% \n",
      "  14                          1,350     0.3%           9.3% \n",
      "  23                            504     0.1%           3.8% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š ETUD (2 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  2                         469,236    94.9%           9.3% â† REF (plus frÃ©quente)\n",
      "  1                          25,247     5.1%           3.1% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š GS (6 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  5                         133,175    26.9%           7.8% â† REF (plus frÃ©quente)\n",
      "  4                         131,258    26.5%           8.2% \n",
      "  6                         115,625    23.4%          12.3% \n",
      "  3                          80,429    16.3%           9.8% \n",
      "  2                          28,006     5.7%           3.2% \n",
      "  1                           5,990     1.2%           0.4% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š INATC (2 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  1                         458,904    92.8%           8.0% â† REF (plus frÃ©quente)\n",
      "  2                          35,579     7.2%          21.8% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š NA5 (5 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  GU                        222,988    45.1%          11.4% â† REF (plus frÃ©quente)\n",
      "  OQ                        153,798    31.1%           3.5% \n",
      "  BE                         73,852    14.9%          12.9% \n",
      "  FZ                         32,768     6.6%          12.0% \n",
      "  AZ                         11,077     2.2%           0.7% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š NENFR (6 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  1                         124,300    25.1%           9.3% â† REF (plus frÃ©quente)\n",
      "  0                         116,349    23.5%           9.3% \n",
      "  2                         107,206    21.7%           9.5% \n",
      "  Z                         102,533    20.7%           7.8% \n",
      "  3                          33,423     6.8%           8.4% \n",
      "  4                          10,672     2.2%           8.4% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š SANI (4 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  2                         475,443    96.1%           8.9% â† REF (plus frÃ©quente)\n",
      "  1                          15,297     3.1%          11.2% \n",
      "  X                           3,093     0.6%           0.5% \n",
      "  0                             650     0.1%           7.7% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š SEXE (2 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  1                         256,784    51.9%          10.5% â† REF (plus frÃ©quente)\n",
      "  2                         237,699    48.1%           7.2% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š STOCD (5 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  10.0                      302,583    61.2%          10.4% â† REF (plus frÃ©quente)\n",
      "  21.0                      111,524    22.6%           8.3% \n",
      "  22.0                       59,162    12.0%           4.0% \n",
      "  23.0                       11,395     2.3%           6.4% \n",
      "  30.0                        9,819     2.0%           5.3% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š TP (2 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  1                         411,499    83.2%           9.1% â† REF (plus frÃ©quente)\n",
      "  2                          82,984    16.8%           8.3% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š TYPL (6 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  1.0                       293,723    59.4%          10.1% â† REF (plus frÃ©quente)\n",
      "  2.0                       198,316    40.1%           7.4% \n",
      "  3.0                         1,543     0.3%           4.2% \n",
      "  6.0                           335     0.1%           3.9% \n",
      "  4.0                           288     0.1%           4.9% \n",
      "  5.0                           278     0.1%           6.8% \n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š VOIT (4 modalitÃ©s)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ModalitÃ©                 Effectif        %   Taux transf. Suggestion\n",
      "  ----------------------------------------------------------------------\n",
      "  2.0                       217,963    44.1%          10.1% â† REF (plus frÃ©quente)\n",
      "  1.0                       176,994    35.8%           7.7% \n",
      "  3.0                        65,569    13.3%          11.2% \n",
      "  0.0                        33,957     6.9%           4.2% \n",
      "\n",
      "================================================================================\n",
      "3. VIF - MULTICOLINÃ‰ARITÃ‰ (sur 17 variables conceptuelles)\n",
      "================================================================================\n",
      "MÃ©thode: Label encoding des catÃ©gorielles â†’ VIF\n",
      "Seuils : VIF < 5 âœ“ | 5-10 âš ï¸ | â‰¥10 ğŸ”´\n",
      "\n",
      "Calcul VIF sur 17 variables...\n",
      "\n",
      "Variable               VIF Statut\n",
      "----------------------------------------\n",
      "AGEREV                9.82 âš ï¸ ModÃ©rÃ©\n",
      "NA5                   6.80 âš ï¸ ModÃ©rÃ©\n",
      "DNAI                  5.35 âš ï¸ ModÃ©rÃ©\n",
      "DEPT                  4.89 âœ“ OK\n",
      "COUPLE                3.98 âœ“ OK\n",
      "NENFR                 3.43 âœ“ OK\n",
      "DIPL                  3.04 âœ“ OK\n",
      "EMPL                  2.80 âœ“ OK\n",
      "STOCD                 2.59 âœ“ OK\n",
      "VOIT                  2.56 âœ“ OK\n",
      "GS                    2.56 âœ“ OK\n",
      "SEXE                  2.13 âœ“ OK\n",
      "TYPL                  1.75 âœ“ OK\n",
      "ETUD                  1.40 âœ“ OK\n",
      "TP                    1.32 âœ“ OK\n",
      "INATC                 1.17 âœ“ OK\n",
      "SANI                  1.05 âœ“ OK\n",
      "----------------------------------------\n",
      "VIF moyen : 3.33 | VIF max : 9.82\n",
      "\n",
      "âš ï¸ 3 variable(s) avec VIF â‰¥ 5\n",
      "\n",
      "================================================================================\n",
      "4. CORRÃ‰LATIONS FORTES (|Ï| > 0.4)\n",
      "================================================================================\n",
      "\n",
      "âœ… Aucune corrÃ©lation |Ï| > 0.4\n",
      "\n",
      "================================================================================\n",
      "5. CATÃ‰GORIES DE RÃ‰FÃ‰RENCE SUGGÃ‰RÃ‰ES (pour Probit)\n",
      "================================================================================\n",
      "CritÃ¨re: modalitÃ© la plus frÃ©quente (convention standard)\n",
      "\n",
      "Variable        RÃ©fÃ©rence suggÃ©rÃ©e             Justification\n",
      "----------------------------------------------------------------------\n",
      "AGEREV          (continue)                     Pas de rÃ©fÃ©rence\n",
      "COUPLE          En couple                      65.9% des obs\n",
      "DEPT            67                             23.9% des obs\n",
      "DIPL            CAP/BEP                        23.8% des obs\n",
      "DNAI            NÃ© Grand Est                   72.8% des obs\n",
      "EMPL            CDI/Fonctionnaire              75.8% des obs\n",
      "ETUD            Non Ã©tudiant                   94.9% des obs\n",
      "GS              EmployÃ©s                       26.9% des obs\n",
      "INATC           FranÃ§ais                       92.8% des obs\n",
      "NA5             Commerce/Services              45.1% des obs\n",
      "NENFR           1                              25.1% des obs\n",
      "SANI            Salle de bain                  96.1% des obs\n",
      "SEXE            Homme                          51.9% des obs\n",
      "STOCD           PropriÃ©taire                   61.2% des obs\n",
      "TP              Temps complet                  83.2% des obs\n",
      "TYPL            Maison                         59.4% des obs\n",
      "VOIT            2 voitures                     44.1% des obs\n",
      "\n",
      "================================================================================\n",
      "FIN DU DIAGNOSTIC\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# ============================================\n",
    "# CHARGER DONNÃ‰ES\n",
    "# ============================================\n",
    "X = pd.read_csv('/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/ML_READY/FINAL_AFTER_ARBITRAGES/X_final_clean.csv')\n",
    "y = pd.read_csv('/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/ML_READY/FINAL_AFTER_ARBITRAGES/y_final.csv')\n",
    "\n",
    "df = X.copy()\n",
    "df['Y'] = y.values.ravel() if len(y.shape) > 1 else y.values\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DIAGNOSTIC PRÃ‰-PROBIT : 17 VARIABLES CONCEPTUELLES\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBase : {len(df):,} obs | Transfrontaliers : {df['Y'].sum():,} ({df['Y'].mean()*100:.2f}%)\")\n",
    "\n",
    "# ============================================\n",
    "# 1. MAPPING DUMMIES â†’ VARIABLES CONCEPTUELLES\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"1. STRUCTURE : 81 DUMMIES â†’ 17 VARIABLES CONCEPTUELLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Identifier les prÃ©fixes (variables conceptuelles)\n",
    "def get_prefix(col):\n",
    "    if col in ['AGEREV', 'AGEREV_sq']:\n",
    "        return 'AGEREV'\n",
    "    elif col.startswith('DNAI_'):\n",
    "        return 'DNAI'\n",
    "    elif '_' in col:\n",
    "        return col.rsplit('_', 1)[0]\n",
    "    else:\n",
    "        return col\n",
    "\n",
    "# Regrouper colonnes par variable conceptuelle\n",
    "var_mapping = {}\n",
    "for col in X.columns:\n",
    "    prefix = get_prefix(col)\n",
    "    if prefix not in var_mapping:\n",
    "        var_mapping[prefix] = []\n",
    "    var_mapping[prefix].append(col)\n",
    "\n",
    "print(f\"\\n{'Variable conceptuelle':<15} {'Nb dummies':>12} {'Colonnes'}\")\n",
    "print(\"-\"*80)\n",
    "for var, cols in sorted(var_mapping.items()):\n",
    "    cols_str = ', '.join(cols[:3])\n",
    "    if len(cols) > 3:\n",
    "        cols_str += f\" ... (+{len(cols)-3})\"\n",
    "    print(f\"{var:<15} {len(cols):>12} {cols_str}\")\n",
    "\n",
    "# ============================================\n",
    "# 2. DÃ‰TAIL PAR VARIABLE : EFFECTIFS + TAUX TRANSFRONTALIER\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. MODALITÃ‰S PAR VARIABLE (effectifs + taux transfrontalier)\")\n",
    "print(\"=\"*80)\n",
    "print(\"â†’ Pour choisir la CATÃ‰GORIE DE RÃ‰FÃ‰RENCE du Probit\\n\")\n",
    "\n",
    "ref_suggestions = {}\n",
    "\n",
    "for var, cols in sorted(var_mapping.items()):\n",
    "    print(f\"\\n{'â”€'*60}\")\n",
    "    print(f\"ğŸ“Š {var} ({len(cols)} modalitÃ©s)\")\n",
    "    print(f\"{'â”€'*60}\")\n",
    "    \n",
    "    if var == 'AGEREV':\n",
    "        # Variable continue\n",
    "        print(f\"  Type: CONTINUE\")\n",
    "        print(f\"  Moyenne: {X['AGEREV'].mean():.1f} ans | Ã‰cart-type: {X['AGEREV'].std():.1f}\")\n",
    "        print(f\"  Min: {X['AGEREV'].min()} | Max: {X['AGEREV'].max()}\")\n",
    "        print(f\"  â†’ Pas de catÃ©gorie de rÃ©fÃ©rence (variable continue)\")\n",
    "        ref_suggestions[var] = None\n",
    "        continue\n",
    "    \n",
    "    print(f\"  {'ModalitÃ©':<20} {'Effectif':>12} {'%':>8} {'Taux transf.':>14} {'Suggestion'}\")\n",
    "    print(f\"  {'-'*70}\")\n",
    "    \n",
    "    modal_stats = []\n",
    "    for col in cols:\n",
    "        modalite = col.replace(var + '_', '')\n",
    "        effectif = X[col].sum()\n",
    "        pct = effectif / len(X) * 100\n",
    "        taux_transf = df[df[col] == 1]['Y'].mean() * 100 if effectif > 0 else 0\n",
    "        modal_stats.append({\n",
    "            'col': col,\n",
    "            'modalite': modalite,\n",
    "            'effectif': effectif,\n",
    "            'pct': pct,\n",
    "            'taux': taux_transf\n",
    "        })\n",
    "    \n",
    "    # Trier par effectif dÃ©croissant\n",
    "    modal_stats = sorted(modal_stats, key=lambda x: x['effectif'], reverse=True)\n",
    "    \n",
    "    # La plus frÃ©quente = suggestion de rÃ©fÃ©rence\n",
    "    ref_col = modal_stats[0]['col']\n",
    "    ref_suggestions[var] = ref_col\n",
    "    \n",
    "    for i, m in enumerate(modal_stats):\n",
    "        suggestion = \"â† REF (plus frÃ©quente)\" if i == 0 else \"\"\n",
    "        print(f\"  {m['modalite']:<20} {m['effectif']:>12,} {m['pct']:>7.1f}% {m['taux']:>13.1f}% {suggestion}\")\n",
    "\n",
    "# ============================================\n",
    "# 3. VIF SUR VARIABLES CONCEPTUELLES\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. VIF - MULTICOLINÃ‰ARITÃ‰ (sur 17 variables conceptuelles)\")\n",
    "print(\"=\"*80)\n",
    "print(\"MÃ©thode: Label encoding des catÃ©gorielles â†’ VIF\")\n",
    "print(\"Seuils : VIF < 5 âœ“ | 5-10 âš ï¸ | â‰¥10 ğŸ”´\\n\")\n",
    "\n",
    "# Reconstruire les variables conceptuelles en label encoding\n",
    "X_conceptual = pd.DataFrame()\n",
    "\n",
    "for var, cols in var_mapping.items():\n",
    "    if var == 'AGEREV':\n",
    "        X_conceptual['AGEREV'] = X['AGEREV']\n",
    "        # On n'inclut pas AGEREV_sq car colinÃ©aire par construction\n",
    "    else:\n",
    "        # Reconstruire la variable catÃ©gorielle\n",
    "        # Trouver quelle modalitÃ© = 1 pour chaque ligne\n",
    "        temp = X[cols].idxmax(axis=1)\n",
    "        # Encoder en numÃ©rique\n",
    "        X_conceptual[var] = pd.factorize(temp)[0]\n",
    "\n",
    "# Calculer VIF\n",
    "print(f\"Calcul VIF sur {len(X_conceptual.columns)} variables...\")\n",
    "\n",
    "vif_results = []\n",
    "for i, col in enumerate(X_conceptual.columns):\n",
    "    try:\n",
    "        vif = variance_inflation_factor(X_conceptual.values.astype(float), i)\n",
    "        vif_results.append({'Variable': col, 'VIF': vif})\n",
    "    except Exception as e:\n",
    "        vif_results.append({'Variable': col, 'VIF': np.nan})\n",
    "\n",
    "vif_df = pd.DataFrame(vif_results).sort_values('VIF', ascending=False)\n",
    "\n",
    "print(f\"\\n{'Variable':<15} {'VIF':>10} {'Statut'}\")\n",
    "print(\"-\"*40)\n",
    "for _, row in vif_df.iterrows():\n",
    "    vif = row['VIF']\n",
    "    if pd.isna(vif) or np.isinf(vif):\n",
    "        statut = \"âŒ Erreur\"\n",
    "        vif_str = \"âˆ\"\n",
    "    elif vif >= 10:\n",
    "        statut = \"ğŸ”´ SÃ©vÃ¨re\"\n",
    "        vif_str = f\"{vif:.2f}\"\n",
    "    elif vif >= 5:\n",
    "        statut = \"âš ï¸ ModÃ©rÃ©\"\n",
    "        vif_str = f\"{vif:.2f}\"\n",
    "    else:\n",
    "        statut = \"âœ“ OK\"\n",
    "        vif_str = f\"{vif:.2f}\"\n",
    "    print(f\"{row['Variable']:<15} {vif_str:>10} {statut}\")\n",
    "\n",
    "vif_clean = vif_df[~vif_df['VIF'].isna() & ~np.isinf(vif_df['VIF'])]['VIF']\n",
    "print(\"-\"*40)\n",
    "print(f\"VIF moyen : {vif_clean.mean():.2f} | VIF max : {vif_clean.max():.2f}\")\n",
    "\n",
    "if vif_clean.max() < 5:\n",
    "    print(\"\\nâœ… PAS DE MULTICOLINÃ‰ARITÃ‰ PROBLÃ‰MATIQUE\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ {(vif_clean >= 5).sum()} variable(s) avec VIF â‰¥ 5\")\n",
    "\n",
    "# ============================================\n",
    "# 4. CORRÃ‰LATIONS FORTES ENTRE VARIABLES CONCEPTUELLES\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. CORRÃ‰LATIONS FORTES (|Ï| > 0.4)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "corr = X_conceptual.corr(method='spearman')\n",
    "\n",
    "pairs = []\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(i+1, len(corr.columns)):\n",
    "        r = corr.iloc[i, j]\n",
    "        if abs(r) > 0.4:\n",
    "            pairs.append((corr.columns[i], corr.columns[j], r))\n",
    "\n",
    "if pairs:\n",
    "    print(f\"\\n{'Variable 1':<15} {'Variable 2':<15} {'Ï Spearman':>12}\")\n",
    "    print(\"-\"*45)\n",
    "    for v1, v2, r in sorted(pairs, key=lambda x: abs(x[2]), reverse=True):\n",
    "        print(f\"{v1:<15} {v2:<15} {r:>12.3f}\")\n",
    "else:\n",
    "    print(\"\\nâœ… Aucune corrÃ©lation |Ï| > 0.4\")\n",
    "\n",
    "# ============================================\n",
    "# 5. RÃ‰CAPITULATIF CATÃ‰GORIES DE RÃ‰FÃ‰RENCE\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"5. CATÃ‰GORIES DE RÃ‰FÃ‰RENCE SUGGÃ‰RÃ‰ES (pour Probit)\")\n",
    "print(\"=\"*80)\n",
    "print(\"CritÃ¨re: modalitÃ© la plus frÃ©quente (convention standard)\\n\")\n",
    "\n",
    "print(f\"{'Variable':<15} {'RÃ©fÃ©rence suggÃ©rÃ©e':<30} {'Justification'}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Labels lisibles\n",
    "labels = {\n",
    "    'GS_5': 'EmployÃ©s',\n",
    "    'EMPL_16': 'CDI/Fonctionnaire',\n",
    "    'INATC_1': 'FranÃ§ais',\n",
    "    'COUPLE_1': 'En couple',\n",
    "    'NENFR_0': '0 enfant',\n",
    "    'NA5_GU': 'Commerce/Services',\n",
    "    'DIPL_13': 'CAP/BEP',\n",
    "    'ETUD_2': 'Non Ã©tudiant',\n",
    "    'SANI_2': 'Salle de bain',\n",
    "    'SEXE_1': 'Homme',\n",
    "    'TP_1': 'Temps complet',\n",
    "    'DEPT_57': 'Moselle',\n",
    "    'STOCD_10.0': 'PropriÃ©taire',\n",
    "    'VOIT_2.0': '2 voitures',\n",
    "    'TYPL_1.0': 'Maison',\n",
    "    'DNAI_NEGRANDEST': 'NÃ© Grand Est'\n",
    "}\n",
    "\n",
    "for var, ref_col in ref_suggestions.items():\n",
    "    if ref_col is None:\n",
    "        print(f\"{var:<15} {'(continue)':<30} {'Pas de rÃ©fÃ©rence'}\")\n",
    "    else:\n",
    "        label = labels.get(ref_col, ref_col.replace(var + '_', ''))\n",
    "        effectif = X[ref_col].sum()\n",
    "        pct = effectif / len(X) * 100\n",
    "        print(f\"{var:<15} {label:<30} {pct:.1f}% des obs\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FIN DU DIAGNOSTIC\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dded8c2f",
   "metadata": {},
   "source": [
    "# SYNTHÃˆSE EXHAUSTIVE DES VARIABLES DU MODÃˆLE PROBIT SIMPLE\n",
    "\n",
    "## Projet INSEE - MobilitÃ© TransfrontaliÃ¨re Grand Est\n",
    "\n",
    "**Base de donnÃ©es** : 494,483 observations | Transfrontaliers : 44,264 (8.95%)\n",
    "\n",
    "---\n",
    "\n",
    "# 1. AGEREV â€” Ã‚ge en annÃ©es rÃ©volues\n",
    "\n",
    "**Source** : INDCVI (Fichier Individus)\n",
    "\n",
    "| PropriÃ©tÃ©             | Valeur |\n",
    "|-----------            |--------|\n",
    "| **Type**              | Continue |\n",
    "| **Description INSEE** | Ã‚ge en annÃ©es rÃ©volues dÃ©taillÃ© (Ã¢ge au dernier anniversaire) |\n",
    "| **Plage**             | 0 Ã  120 ans |\n",
    "| **Dans le modÃ¨le**    | 15-101 ans (actifs occupÃ©s uniquement) |\n",
    "\n",
    "**Statistiques dans la BDD** :\n",
    "- Moyenne : 41.5 ans\n",
    "- Ã‰cart-type : 12.5 ans\n",
    "- Min : 15 ans | Max : 101 ans\n",
    "\n",
    "**SpÃ©cification probit** : \n",
    "- `AGEREV` (effet linÃ©aire)\n",
    "- `AGEREV_sq` (effet quadratique) â†’ Effet en U inversÃ© confirmÃ© par Elastic Net\n",
    "\n",
    "**Pas de catÃ©gorie de rÃ©fÃ©rence** (variable continue)\n",
    "\n",
    "---\n",
    "\n",
    "# 2. COUPLE â€” DÃ©claration de vie en couple\n",
    "\n",
    "**Source** : INDCVI (Fichier Individus)\n",
    "\n",
    "| Code  | LibellÃ© INSEE                    | Effectif | % Base | Taux transf. |\n",
    "|------ |---------------                   |----------|--------|--------------|\n",
    "| **1** | A dÃ©clarÃ© vivre en couple        | 325,880  | 65.9%  | 9.7% |\n",
    "| 2     | A dÃ©clarÃ© ne pas vivre en couple | 168,603  | 34.1%  | 7.5% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `COUPLE_1` (En couple) â€” 65.9% des observations\n",
    "\n",
    "**Note** : Variable dÃ©clarative, pas de distinction mariÃ©/pacsÃ©/concubinage ici (voir STAT_CONJ si nÃ©cessaire)\n",
    "\n",
    "---\n",
    "\n",
    "# 3. DEPT â€” DÃ©partement du lieu de rÃ©sidence\n",
    "\n",
    "**Source** : INDCVI + MOBPRO\n",
    "\n",
    "| Code   | DÃ©partement        | Effectif | % Base | Taux transf. | InterprÃ©tation |\n",
    "|------  |-------------       |----------|--------|--------------|----------------|\n",
    "| **67** | Bas-Rhin           | 118,398  | 23.9%  | 4.6% | Strasbourg, Ã©loignÃ© frontiÃ¨re |\n",
    "| 57     | Moselle            | 98,869   | 20.0%  | **21.6%** | ProximitÃ© Luxembourg |\n",
    "| 68     | Haut-Rhin          | 73,587   | 14.9%  | **14.1%** | ProximitÃ© Suisse/Allemagne|\n",
    "| 54     | Meurthe-et-Moselle | 64,924   | 13.1%  | 9.7% | ProximitÃ© Luxembourg |\n",
    "| 51     | Marne              | 53,239   | 10.8%  | 0.1% | Ã‰loignÃ© des frontiÃ¨res |\n",
    "| 88     | Vosges             | 29,098   | 5.9%   | 0.2% | Relief montagneux |\n",
    "| 10     | Aube               | 27,234   | 5.5%   | 0.1% | Ã‰loignÃ© des frontiÃ¨res |\n",
    "| 55     | Meuse              | 14,885   | 3.0%   | 4.7% | Entre Metz et frontiÃ¨re |\n",
    "| 52     | Haute-Marne        | 14,249   | 2.9%   | 0.1% | Ã‰loignÃ© des frontiÃ¨res |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `DEPT_67` (Bas-Rhin) â€” 23.9% des observations\n",
    "\n",
    "**Attention** : Le diagnostic suggÃ¨re DEPT_67 (plus frÃ©quent), mais Ã©conomÃ©triquement on pourrait prÃ©fÃ©rer un dÃ©partement \"neutre\" Ã©loignÃ© des frontiÃ¨res (ex: DEPT_51 Marne) pour que tous les coefficients des dÃ©partements frontaliers soient positifs et comparables.\n",
    "\n",
    "## Choix final : alternative selectionnÃ©e pour DEPT\n",
    "Utiliser DEPT_51 (Marne) comme rÃ©fÃ©rence pour avoir tous les coefficients des dÃ©partements frontaliers en positif, ce qui facilite l'interprÃ©tation.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. DIPL â€” DiplÃ´me le plus Ã©levÃ©\n",
    "\n",
    "**Source** : INDCVI (Fichier Individus)\n",
    "\n",
    "| Code | LibellÃ© INSEE complet                       | Effectif | % Base | Taux transf. |\n",
    "|------|----------------------                       |----------|--------|--------------|\n",
    "| 01 | Pas de scolaritÃ© ou arrÃªt avant fin primaire        | 3,431  | 0.7%  | 5.4% |\n",
    "| 02 | Aucun diplÃ´me, scolaritÃ© fin primaire/avant collÃ¨ge | 10,348 | 2.1%  | 8.1% |\n",
    "| 03 | Aucun diplÃ´me, scolaritÃ© jusqu'Ã  fin collÃ¨ge ou +   | 26,638 | 5.4%  | 9.1% |\n",
    "| 11 | CEP (certificat d'Ã©tudes primaires)                 | 4,062  | 0.8%  | 12.0% |\n",
    "| 12 | BEPC, brevet Ã©lÃ©mentaire, DNB                       | 16,298 | 3.3%  | 8.1% |\n",
    "| **13** | **CAP, BEP ou diplÃ´me Ã©quivalent**              | 117,859|**23.8%**| 9.6% |\n",
    "| 14 | Bac gÃ©nÃ©ral/techno, brevet supÃ©rieur, DAEU          | 50,473 | 10.2% | 7.8% |\n",
    "| 15 | Bac pro, brevet professionnel/technicien            | 56,154 | 11.4% | 8.7% |\n",
    "| 16 | BTS, DUT, Deug, Deust (Bac+2)                       | 75,404 | 15.2% | 7.9% |\n",
    "| 17 | Licence, licence pro, maÃ®trise (Bac+3/4)            | 63,260 | 12.8% | 8.3% |\n",
    "| 18 | Master, DEA, DESS, grande Ã©cole (Bac+5)             | 65,128 | 13.2% | **10.7%** |\n",
    "| 19 | Doctorat de recherche (hors santÃ©)                  | 5,428  | 1.1%  | **11.2%** |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `DIPL_13` (CAP/BEP) â€” 23.8% des observations\n",
    "\n",
    "**InterprÃ©tation** : Les trÃ¨s diplÃ´mÃ©s (18, 19) et les CEP (11) ont les taux transfrontaliers les plus Ã©levÃ©s. L'effet diplÃ´me n'est pas linÃ©aire.\n",
    "\n",
    "---\n",
    "\n",
    "# 5. DNAI â€” DÃ©partement de naissance (recodÃ©)\n",
    "\n",
    "**Source** : INDCVI â€” Variable DNAI recodÃ©e en 3 modalitÃ©s\n",
    "\n",
    "| Code recodÃ©    | Description                        | Effectif | % Base | Taux transf. |\n",
    "|-------------   |-------------                       |----------|--------|--------------|\n",
    "| **NEGRANDEST** | NÃ© dans le Grand Est            | 360,009 | 72.8% | 8.1% |\n",
    "| NEAUTREFR      | NÃ© ailleurs en France           | 71,270 | 14.4% | 5.8% |\n",
    "| NEETRANGER     | NÃ© Ã  l'Ã©tranger (code 99 INSEE) | 63,204 | 12.8% | **17.5%** |\n",
    "\n",
    "**Variable INSEE originale** : \n",
    "- Codes 08, 10, 51, 52, 54, 55, 57, 67, 68, 88 â†’ NEGRANDEST\n",
    "- Autres codes franÃ§ais â†’ NEAUTREFR\n",
    "- Code 99 â†’ NEETRANGER\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `DNAI_NEGRANDEST` â€” 72.8% des observations\n",
    "\n",
    "**InterprÃ©tation Ã©conomique** : Les personnes nÃ©es Ã  l'Ã©tranger ont 2Ã— plus de chances d'Ãªtre transfrontaliers (rÃ©seaux, expÃ©rience internationale, moins d'ancrage territorial).\n",
    "\n",
    "---\n",
    "\n",
    "# 6. EMPL â€” Condition d'emploi\n",
    "\n",
    "**Source** : INDCVI + MOBPRO\n",
    "\n",
    "| Code | LibellÃ© INSEE                                 | Effectif | % Base | Taux transf. |\n",
    "|------|---------------                                |----------|--------|--------------|\n",
    "| 11 | Contrat d'apprentissage ou professionnalisation  | 14,172  | 2.9%    | 1.8% |\n",
    "| 12 | PlacÃ©s par agence d'intÃ©rim                      | 10,308  | 2.1%    | **10.8%** |\n",
    "| 13 | Emplois aidÃ©s (CUI, avenir, etc.)                | 2,437   | 0.5%    | 1.3% |\n",
    "| 14 | Stagiaires rÃ©munÃ©rÃ©s en entreprise               | 1,350   | 0.3%    | 9.3% |\n",
    "| 15 | Autres emplois Ã  durÃ©e limitÃ©e (CDD, saisonnier) | 40,025  | 8.1%    | 5.7% |\n",
    "| **16** | **CDI, titulaire fonction publique**         | 374,974 |**75.8%**| **10.4%** |\n",
    "| 21 | Non salariÃ©s : IndÃ©pendants                      | 29,943  | 6.1%    | 2.6% |\n",
    "| 22 | Non salariÃ©s : Employeurs                        | 20,770  | 4.2%    | 3.6% |\n",
    "| 23 | Non salariÃ©s : Aides familiaux                   | 504     | 0.1%    | 3.8% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `EMPL_16` (CDI/Fonctionnaire) â€” 75.8% des observations\n",
    "\n",
    "**InterprÃ©tation** : \n",
    "- Les CDI ont le taux transfrontalier le plus Ã©levÃ© (stabilitÃ© â†’ acceptation dÃ©placements)\n",
    "- L'intÃ©rim (12) aussi Ã©levÃ© car souvent transfrontalier (agences spÃ©cialisÃ©es Luxembourg)\n",
    "- Les indÃ©pendants (21) trÃ¨s faibles car activitÃ© ancrÃ©e localement\n",
    "\n",
    "---\n",
    "\n",
    "# 7. ETUD â€” Inscription dans un Ã©tablissement d'enseignement\n",
    "\n",
    "**Source** : INDCVI (Fichier Individus)\n",
    "\n",
    "| Code  | LibellÃ© INSEE         | Effectif | % Base | Taux transf. |\n",
    "|------ |---------------        |----------|--------|--------------|\n",
    "| 1     | Oui (inscrit)         | 25,247   | 5.1%   | 3.1% |\n",
    "| **2** | **Non (non inscrit)** | 469,236  |**94.9%**| 9.3% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `ETUD_2` (Non Ã©tudiant) â€” 94.9% des observations\n",
    "\n",
    "**Note** : Dans ta base, tu as filtrÃ© sur les actifs occupÃ©s, donc les \"Ã©tudiants\" ici sont des travailleurs-Ã©tudiants (alternance, formation continue).\n",
    "\n",
    "---\n",
    "\n",
    "# 8. GS â€” Groupe socioprofessionnel en 6 postes\n",
    "\n",
    "**Source** : INDCVI + MOBPRO\n",
    "\n",
    "| Code | LibellÃ© INSEE                               | Effectif | % Base | Taux transf. |\n",
    "|------|---------------                              |----------|--------|--------------|\n",
    "| 1    | Agriculteurs exploitants                    | 5,990   | 1.2%    | **0.4%** |\n",
    "| 2    | Artisans, commerÃ§ants, chefs d'entreprise   | 28,006  | 5.7%    | 3.2% |\n",
    "| 3    | Cadres et professions intellect. supÃ©rieures| 80,429  | 16.3%   | 9.8% |\n",
    "| 4    | Professions intermÃ©diaires                  | 131,258 | 26.5%   | 8.2% |\n",
    "|**5** | **EmployÃ©s**                                | 133,175 |**26.9%**| 7.8% |\n",
    "| 6    | Ouvriers                                    | 115,625 | 23.4%   | **12.3%** |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `GS_5` (EmployÃ©s) â€” 26.9% des observations\n",
    "\n",
    "**InterprÃ©tation Ã©conomique** :\n",
    "- **Ouvriers (6)** : Taux le plus Ã©levÃ© (12.3%) â†’ industrie transfrontaliÃ¨re (Luxembourg, Allemagne)\n",
    "- **Agriculteurs (1)** : Taux quasi nul â†’ activitÃ© terrienne par nature\n",
    "- **Cadres (3)** : Taux Ã©levÃ© â†’ diffÃ©rentiel salarial attractif Luxembourg/Suisse\n",
    "\n",
    "---\n",
    "\n",
    "# 9. INATC â€” Indicateur de nationalitÃ© condensÃ©\n",
    "\n",
    "**Source** : INDCVI + MOBPRO\n",
    "\n",
    "| Code  | LibellÃ© INSEE | Effectif | % Base | Taux transf. |\n",
    "|------ |---------------|----------|--------|--------------|\n",
    "| **1** | **FranÃ§ais**  | 458,904  |**92.8%**| 8.0% |\n",
    "| 2     | Ã‰trangers     | 35,579   | 7.2%   | **21.8%** |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `INATC_1` (FranÃ§ais) â€” 92.8% des observations\n",
    "\n",
    "**InterprÃ©tation** : Les Ã©trangers rÃ©sidant dans le Grand Est ont 2.7Ã— plus de chances d'Ãªtre transfrontaliers (proximitÃ© culturelle/linguistique avec pays voisin, rÃ©seaux, moins de contraintes administratives perÃ§ues).\n",
    "\n",
    "---\n",
    "\n",
    "# 10. NA5 â€” ActivitÃ© Ã©conomique regroupÃ©e en 5 postes\n",
    "\n",
    "**Source** : INDCVI + MOBPRO (Nomenclature d'ActivitÃ©s FranÃ§aise)\n",
    "\n",
    "| Code | LibellÃ© INSEE                                | Effectif | % Base | Taux transf. |\n",
    "|------|---------------                               |----------|--------|--------------|\n",
    "| AZ | Agriculture, sylviculture et pÃªche              | 11,077 | 2.2%     | **0.7%** |\n",
    "| BE | Industrie manufacturiÃ¨re, extractives et autres | 73,852 | 14.9%    | **12.9%** |\n",
    "| FZ | Construction                                    | 32,768 | 6.6%     | **12.0%** |\n",
    "| **GU** | **Commerce, transports et services divers** | 222,988 |**45.1%**| 11.4% |\n",
    "| OQ | Administration publique, enseignement, santÃ©    | 153,798 | 31.1%   | 3.5% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `NA5_GU` (Commerce/Services) â€” 45.1% des observations\n",
    "\n",
    "**InterprÃ©tation Ã©conomique** :\n",
    "- **OQ (Administration)** : Taux trÃ¨s faible (3.5%) â†’ emplois publics franÃ§ais par nature\n",
    "- **AZ (Agriculture)** : Quasi nul â†’ activitÃ© terrienne\n",
    "- **BE (Industrie)** et **FZ (Construction)** : TrÃ¨s Ã©levÃ©s â†’ secteurs transfrontaliers typiques\n",
    "\n",
    "---\n",
    "\n",
    "# 11. NENFR â€” Nombre d'enfants de la famille (regroupÃ©)\n",
    "\n",
    "**Source** : INDCVI (Fichier Individus)\n",
    "\n",
    "| Code  | LibellÃ© INSEE                 | Effectif | % Base    | Taux transf. |\n",
    "|------ |---------------                |----------|--------   |--------------|\n",
    "| 0     | 0 enfant (couple sans enfant) | 116,349  | 23.5%     | 9.3% |\n",
    "| **1** | **1 enfant**                  | 124,300  | **25.1%** | 9.3% |\n",
    "| 2     | 2 enfants                     | 107,206  | 21.7%     | 9.5% |\n",
    "| 3     | 3 enfants                     | 33,423   | 6.8%      | 8.4% |\n",
    "| 4     | 4 enfants ou plus             | 10,672   | 2.2%      | 8.4% |\n",
    "| Z     | Personne hors famille ou hors logement ordinaire | 102,533 | 20.7% | 7.8% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `NENFR_1` (1 enfant) â€” 25.1% des observations\n",
    "\n",
    "**Choix final** : `NENFR_0` (0 enfant) car plus interprÃ©table Ã©conomiquement.\n",
    "\n",
    "**Note** : La modalitÃ© \"Z\" correspond aux personnes vivant seules ou hors famille.\n",
    "\n",
    "---\n",
    "\n",
    "# 12. SANI â€” Installations sanitaires (France mÃ©tropolitaine)\n",
    "\n",
    "**Source** : INDCVI (Fichier Individus)\n",
    "\n",
    "| Code  | LibellÃ© INSEE                                | Effectif | % Base | Taux transf. |\n",
    "|------ |---------------                               |----------|--------|--------------|\n",
    "| 0     | Ni baignoire, ni douche                          | 650     | 0.1%  | 7.7% |\n",
    "| 1     | Baignoire ou douche hors piÃ¨ce rÃ©servÃ©e          | 15,297  | 3.1%  | **11.2%** |\n",
    "| **2** | **Salle(s) de bains (avec douche ou baignoire)** | 475,443 |**96.1%**| 8.9% |\n",
    "| X     | Hors logement ordinaire                          | 3,093   | 0.6%  | 0.5% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `SANI_2` (Salle de bains standard) â€” 96.1% des observations\n",
    "\n",
    "**InterprÃ©tation** : Variable proxy du niveau de confort/standing du logement. Peut capter des effets de richesse.\n",
    "\n",
    "---\n",
    "\n",
    "# 13. SEXE â€” Sexe\n",
    "\n",
    "**Source** : INDCVI + MOBPRO\n",
    "\n",
    "| Code   | LibellÃ© INSEE | Effectif | % Base | Taux transf. |\n",
    "|------ |--------------  |----------|--------|--------------|\n",
    "| **1** | **Hommes**     | 256,784  | **51.9%** | **10.5%** |\n",
    "| 2     | Femmes         | 237,699  | 48.1%      | 7.2% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `SEXE_1` (Homme) â€” 51.9% des observations\n",
    "\n",
    "**InterprÃ©tation Ã©conomique** : Les hommes ont 1.5Ã— plus de chances d'Ãªtre transfrontaliers. Effet Ã  explorer avec interactions (SEXE Ã— NENFR, SEXE Ã— EMPL) dans le modÃ¨le 2.\n",
    "\n",
    "---\n",
    "\n",
    "# 14. STOCD â€” Statut d'occupation dÃ©taillÃ© du logement\n",
    "\n",
    "**Source** : INDCVI + MOBPRO\n",
    "\n",
    "| Code   | LibellÃ© INSEE                       | Effectif | % Base | Taux transf. |\n",
    "|------  |---------------                      |--------- |--------|--------------|\n",
    "| 00     | Logement ordinaire inoccupÃ©         | â€” | â€” | â€” |\n",
    "| **10** | **PropriÃ©taire**                    | 302,583  |**61.2%**| **10.4%** |\n",
    "| 21     | Locataire logement vide non HLM     | 111,524  | 22.6%   | 8.3% |\n",
    "| 22     | Locataire logement vide HLM         | 59,162   | 12.0%   | 4.0% |\n",
    "| 23     | Locataire meublÃ© ou chambre d'hÃ´tel | 11,395   | 2.3%    | 6.4% |\n",
    "| 30     | LogÃ© gratuitement                   | 9,819    | 2.0%    | 5.3% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `STOCD_10` (PropriÃ©taire) â€” 61.2% des observations\n",
    "\n",
    "**Note** : Dans ta base, le code apparaÃ®t comme `STOCD_10.0` (float) â†’ Ã  vÃ©rifier/nettoyer.\n",
    "\n",
    "**InterprÃ©tation** : Les propriÃ©taires ont le taux le plus Ã©levÃ© (revenus â†’ mobilitÃ© acceptÃ©e). Les locataires HLM ont le taux le plus faible.\n",
    "\n",
    "---\n",
    "\n",
    "# 15. TP â€” Temps de travail\n",
    "\n",
    "**Source** : INDCVI + MOBPRO\n",
    "\n",
    "| Code | LibellÃ© INSEE   | Effectif | % Base    | Taux transf. |\n",
    "|------|---------------  |----------|--------   |--------------|\n",
    "|**1** |**Temps complet**| 411,499  | **83.2%** | 9.1% |\n",
    "| 2    | Temps partiel   | 82,984   | 16.8%     | 8.3% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `TP_1` (Temps complet) â€” 83.2% des observations\n",
    "\n",
    "**Note** : La modalitÃ© \"Z\" (Sans objet) a Ã©tÃ© exclue car tu travailles sur les actifs occupÃ©s.\n",
    "\n",
    "---\n",
    "\n",
    "# 16. TYPL â€” Type de logement\n",
    "\n",
    "**Source** : INDCVI + MOBPRO\n",
    "\n",
    "| Code | LibellÃ© INSEE                       | Effectif | % Base | Taux transf. |\n",
    "|------|---------------                      |----------|--------|--------------|\n",
    "| **1** | **Maison**                         | 293,723  |**59.4%**| **10.1%** |\n",
    "| 2     | Appartement                        | 198,316  | 40.1%   | 7.4% |\n",
    "| 3     | Logement-foyer                     | 1,543    | 0.3%    | 4.2% |\n",
    "| 4     | Chambre d'hÃ´tel                    | 288      | 0.1%    | 4.9% |\n",
    "| 5     | Habitation de fortune              | 278      | 0.1%    | 6.8% |\n",
    "| 6     | PiÃ¨ce indÃ©pendante (entrÃ©e propre) | 335      | 0.1%    | 3.9% |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `TYPL_1` (Maison) â€” 59.4% des observations\n",
    "\n",
    "**Note** : Dans ta base, le code apparaÃ®t comme `TYPL_1.0` (float) â†’ Ã  vÃ©rifier/nettoyer.\n",
    "\n",
    "**InterprÃ©tation** : Les habitants de maisons sont plus souvent transfrontaliers (pÃ©riurbain/rural frontalier vs. centre-ville).\n",
    "\n",
    "---\n",
    "\n",
    "# 17. VOIT â€” Nombre de voitures du mÃ©nage\n",
    "\n",
    "**Source** : INDCVI + MOBPRO\n",
    "\n",
    "| Code | LibellÃ© INSEE           | Effectif | % Base | Taux transf. |\n",
    "|------|---------------          |----------|--------|--------------|\n",
    "| 0     | Aucune voiture         | 33,957   | 6.9%   | 4.2% |\n",
    "| 1     | Une seule voiture      | 176,994  | 35.8%  | 7.7% |\n",
    "| **2** | **Deux voitures**      | 217,963  |**44.1%**| 10.1% |\n",
    "| 3     | Trois voitures ou plus | 65,569   | 13.3%  | **11.2%** |\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence suggÃ©rÃ©e** : `VOIT_2` (2 voitures) â€” 44.1% des observations\n",
    "\n",
    "**Note** : Dans ta base, le code apparaÃ®t comme `VOIT_2.0` (float) â†’ Ã  vÃ©rifier/nettoyer.\n",
    "\n",
    "**InterprÃ©tation Ã©conomique** : Effet monotone croissant â†’ plus de voitures = plus de mobilitÃ© possible = plus de travail transfrontalier. Effet revenu + effet accÃ¨s.\n",
    "\n",
    "---\n",
    "\n",
    "# TABLEAU RÃ‰CAPITULATIF DES CATÃ‰GORIES DE RÃ‰FÃ‰RENCE\n",
    "\n",
    "| Variable | RÃ©fÃ©rence suggÃ©rÃ©e| LibellÃ©           | % Base | Justification |\n",
    "|----------|-------------------|---------          |--------|---------------|\n",
    "| AGEREV   | â€”                 | Continue          | â€”     | Pas de rÃ©fÃ©rence |\n",
    "| COUPLE   | `COUPLE_1`        | En couple         | 65.9% | Plus frÃ©quente |\n",
    "| DEPT     | `DEPT_51`         | Marne          | 10.8% |Choix arbitraire \"effet frontiÃ¨re\"\n",
    "| DIPL     | `DIPL_13`         | CAP/BEP           | 23.8% | Plus frÃ©quente |\n",
    "| DNAI     | `DNAI_NEGRANDEST` | NÃ© Grand Est      | 72.8% | Plus frÃ©quente |\n",
    "| EMPL     | `EMPL_16`         | CDI/Fonctionnaire | 75.8% | Plus frÃ©quente |\n",
    "| ETUD     | `ETUD_2`          | Non Ã©tudiant      | 94.9% | Plus frÃ©quente |\n",
    "| GS       | `GS_5`            | EmployÃ©s          | 26.9% | Plus frÃ©quente |\n",
    "| INATC    | `INATC_1`         | FranÃ§ais          | 92.8% | Plus frÃ©quente |\n",
    "| NA5      | `NA5_GU`          | Commerce/Services | 45.1% | Plus frÃ©quente |\n",
    "| NENFR    | `NENFR_0`         | 0 enfant     | 23.5% |Choix arbitraire \"effet parentalitÃ©\"\n",
    "| SANI     | `SANI_2`          | Salle de bains    | 96.1% | Plus frÃ©quente |\n",
    "| SEXE     | `SEXE_1`          | Homme             | 51.9% | Plus frÃ©quente |\n",
    "| STOCD    | `STOCD_10`        | PropriÃ©taire      | 61.2% | Plus frÃ©quente |\n",
    "| TP       | `TP_1`            | Temps complet     | 83.2% | Plus frÃ©quente |\n",
    "| TYPL     | `TYPL_1`          | Maison            | 59.4% | Plus frÃ©quente |\n",
    "| VOIT     | `VOIT_2`          | 1 voitures        | 35.8% | Choix arbitraire \"mÃ©diane\" |\n",
    "\n",
    "---\n",
    "\n",
    "# POINTS D'ATTENTION\n",
    "\n",
    "## Variable NENFR\n",
    "La modalitÃ© \"Z\" (hors famille) mÃ©lange :\n",
    "- Personnes vivant seules\n",
    "- Personnes en colocation hors famille\n",
    "- Personnes en communautÃ©\n",
    "\n",
    "Ã€ interprÃ©ter avec prudence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f817a95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PRÃ‰PARATION DE LA BASE PROBIT\n",
      "================================================================================\n",
      "\n",
      "âœ“ Base chargÃ©e : 494,483 observations Ã— 81 variables\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CATÃ‰GORIES DE RÃ‰FÃ‰RENCE SUPPRIMÃ‰ES\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Variable     RÃ©fÃ©rence supprimÃ©e  Justification\n",
      "----------------------------------------------------------------------\n",
      "GS           GS_5                 EmployÃ©s - plus frÃ©quent (26.9%)\n",
      "EMPL         EMPL_16              CDI/Titulaire - plus frÃ©quent (75.8%)\n",
      "INATC        INATC_1              FranÃ§ais - plus frÃ©quent (92.8%)\n",
      "COUPLE       COUPLE_1             En couple - plus frÃ©quent (65.9%)\n",
      "NENFR        NENFR_0              0 enfant - CHOIX (interprÃ©tation parentalitÃ©)\n",
      "NA5          NA5_GU               Commerce/Services - plus frÃ©quent (45.1%)\n",
      "DIPL         DIPL_13              CAP/BEP - plus frÃ©quent (23.8%)\n",
      "ETUD         ETUD_2               Non Ã©tudiant - plus frÃ©quent (94.9%)\n",
      "SANI         SANI_2               Salle de bain - plus frÃ©quent (96.1%)\n",
      "SEXE         SEXE_1               Homme - plus frÃ©quent (51.9%)\n",
      "TP           TP_1                 Temps complet - plus frÃ©quent (83.2%)\n",
      "DEPT         DEPT_51              Marne - CHOIX (dept intÃ©rieur, non-frontalier)\n",
      "STOCD        STOCD_10.0           PropriÃ©taire - plus frÃ©quent (61.2%)\n",
      "VOIT         VOIT_1.0             1 voiture - CHOIX (rÃ©fÃ©rence mÃ©diane)\n",
      "TYPL         TYPL_1.0             Maison - plus frÃ©quent (59.4%)\n",
      "DNAI         DNAI_NEGRANDEST      NÃ© Grand Est - plus frÃ©quent (72.8%)\n",
      "\n",
      "================================================================================\n",
      "STRUCTURE DE LA BASE PROBIT\n",
      "================================================================================\n",
      "\n",
      "âœ“ Dimensions finales : 494,483 observations Ã— 65 variables\n",
      "  (suppression de 16 catÃ©gories de rÃ©fÃ©rence)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "RÃ‰CAPITULATIF PAR VARIABLE CONCEPTUELLE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Variable     ModalitÃ©s gardÃ©es                        K-1\n",
      "----------------------------------------------------------------------\n",
      "AGEREV       AGEREV, AGEREV_sq                        2\n",
      "GS           GS_1, GS_2, GS_3... (+2)                 5\n",
      "EMPL         EMPL_11, EMPL_12, EMPL_13... (+5)        8\n",
      "INATC        INATC_2                                  1\n",
      "COUPLE       COUPLE_2                                 1\n",
      "NENFR        NENFR_1, NENFR_2, NENFR_3... (+2)        5\n",
      "NA5          NA5_AZ, NA5_BE, NA5_FZ... (+1)           4\n",
      "DIPL         DIPL_1, DIPL_11, DIPL_12... (+8)         11\n",
      "ETUD         ETUD_1                                   1\n",
      "SANI         SANI_0, SANI_1, SANI_X                   3\n",
      "SEXE         SEXE_2                                   1\n",
      "TP           TP_2                                     1\n",
      "DEPT         DEPT_10, DEPT_52, DEPT_54... (+5)        8\n",
      "STOCD        STOCD_21.0, STOCD_22.0, STOCD_23.0... (+1) 4\n",
      "VOIT         VOIT_0.0, VOIT_2.0, VOIT_3.0             3\n",
      "TYPL         TYPL_2.0, TYPL_3.0, TYPL_4.0... (+2)     5\n",
      "DNAI         DNAI_NEAUTREFR, DNAI_NEETRANGER          2\n",
      "----------------------------------------------------------------------\n",
      "TOTAL                                                 65 + constante\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LISTE COMPLÃˆTE DES COLONNES (ordre alphabÃ©tique)\n",
      "--------------------------------------------------------------------------------\n",
      "   1. AGEREV\n",
      "   2. AGEREV_sq\n",
      "   3. COUPLE_2\n",
      "   4. DEPT_10\n",
      "   5. DEPT_52\n",
      "   6. DEPT_54\n",
      "   7. DEPT_55\n",
      "   8. DEPT_57\n",
      "   9. DEPT_67\n",
      "  10. DEPT_68\n",
      "  11. DEPT_88\n",
      "  12. DIPL_1\n",
      "  13. DIPL_11\n",
      "  14. DIPL_12\n",
      "  15. DIPL_14\n",
      "  16. DIPL_15\n",
      "  17. DIPL_16\n",
      "  18. DIPL_17\n",
      "  19. DIPL_18\n",
      "  20. DIPL_19\n",
      "  21. DIPL_2\n",
      "  22. DIPL_3\n",
      "  23. DNAI_NEAUTREFR\n",
      "  24. DNAI_NEETRANGER\n",
      "  25. EMPL_11\n",
      "  26. EMPL_12\n",
      "  27. EMPL_13\n",
      "  28. EMPL_14\n",
      "  29. EMPL_15\n",
      "  30. EMPL_21\n",
      "  31. EMPL_22\n",
      "  32. EMPL_23\n",
      "  33. ETUD_1\n",
      "  34. GS_1\n",
      "  35. GS_2\n",
      "  36. GS_3\n",
      "  37. GS_4\n",
      "  38. GS_6\n",
      "  39. INATC_2\n",
      "  40. NA5_AZ\n",
      "  41. NA5_BE\n",
      "  42. NA5_FZ\n",
      "  43. NA5_OQ\n",
      "  44. NENFR_1\n",
      "  45. NENFR_2\n",
      "  46. NENFR_3\n",
      "  47. NENFR_4\n",
      "  48. NENFR_Z\n",
      "  49. SANI_0\n",
      "  50. SANI_1\n",
      "  51. SANI_X\n",
      "  52. SEXE_2\n",
      "  53. STOCD_21.0\n",
      "  54. STOCD_22.0\n",
      "  55. STOCD_23.0\n",
      "  56. STOCD_30.0\n",
      "  57. TP_2\n",
      "  58. TYPL_2.0\n",
      "  59. TYPL_3.0\n",
      "  60. TYPL_4.0\n",
      "  61. TYPL_5.0\n",
      "  62. TYPL_6.0\n",
      "  63. VOIT_0.0\n",
      "  64. VOIT_2.0\n",
      "  65. VOIT_3.0\n",
      "\n",
      "================================================================================\n",
      "SAUVEGARDE\n",
      "================================================================================\n",
      "\n",
      "âœ“ Base sauvegardÃ©e : /Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready\n",
      "  â†’ 494,483 observations\n",
      "  â†’ 65 variables explicatives\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "APERÃ‡U (5 premiÃ¨res lignes)\n",
      "--------------------------------------------------------------------------------\n",
      "   AGEREV  AGEREV_sq  GS_1  GS_2  GS_3  GS_4  GS_6  EMPL_11  EMPL_12  EMPL_13  \\\n",
      "0      35       1225     0     0     0     0     1        0        0        0   \n",
      "1      40       1600     0     0     0     0     1        0        0        0   \n",
      "2      44       1936     0     0     0     0     1        0        0        0   \n",
      "3      62       3844     0     0     0     1     0        0        0        0   \n",
      "4      59       3481     1     0     0     0     0        0        0        0   \n",
      "\n",
      "   ...  VOIT_0.0  VOIT_2.0  VOIT_3.0  TYPL_2.0  TYPL_3.0  TYPL_4.0  TYPL_5.0  \\\n",
      "0  ...         0         0         0         0         0         0         0   \n",
      "1  ...         0         0         1         0         0         0         0   \n",
      "2  ...         0         0         1         0         0         0         0   \n",
      "3  ...         0         0         0         0         0         0         0   \n",
      "4  ...         0         1         0         0         0         0         0   \n",
      "\n",
      "   TYPL_6.0  DNAI_NEAUTREFR  DNAI_NEETRANGER  \n",
      "0         0               1                0  \n",
      "1         0               0                1  \n",
      "2         0               0                1  \n",
      "3         0               0                0  \n",
      "4         0               0                0  \n",
      "\n",
      "[5 rows x 65 columns]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VÃ‰RIFICATION MULTICOLINÃ‰ARITÃ‰\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "âœ“ Rang de la matrice X : 65\n",
      "âœ“ Nombre de colonnes   : 65\n",
      "\n",
      "âœ… Matrice de plein rang - pas de multicolinÃ©aritÃ© parfaite\n",
      "\n",
      "================================================================================\n",
      "PRÃ‰PARATION TERMINÃ‰E\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "PRÃ‰PARATION DE LA BASE PROBIT - BDD_PROBIT\n",
    "================================================================================\n",
    "CrÃ©ation d'une base prÃªte pour l'estimation probit en supprimant les catÃ©gories\n",
    "de rÃ©fÃ©rence pour chaque variable catÃ©gorielle (Ã©viter la multicolinÃ©aritÃ© parfaite).\n",
    "\n",
    "CatÃ©gories de rÃ©fÃ©rence retenues (17 variables conceptuelles) :\n",
    "--------------------------------------------------------------------------------\n",
    "Variable    | RÃ©fÃ©rence      | Justification\n",
    "--------------------------------------------------------------------------------\n",
    "AGEREV      | (continue)     | Variable continue + terme quadratique\n",
    "GS          | GS_5           | EmployÃ©s - modalitÃ© la plus frÃ©quente (26.9%)\n",
    "EMPL        | EMPL_16        | CDI/Titulaire - modalitÃ© la plus frÃ©quente (75.8%)\n",
    "INATC       | INATC_1        | FranÃ§ais - modalitÃ© la plus frÃ©quente (92.8%)\n",
    "COUPLE      | COUPLE_1       | En couple - modalitÃ© la plus frÃ©quente (65.9%)\n",
    "NENFR       | NENFR_0        | 0 enfant - CHOIX UTILISATEUR (interprÃ©tation parentalitÃ©)\n",
    "NA5         | NA5_GU         | Commerce/Services - modalitÃ© la plus frÃ©quente (45.1%)\n",
    "DIPL        | DIPL_13        | CAP/BEP - modalitÃ© la plus frÃ©quente (23.8%)\n",
    "ETUD        | ETUD_2         | Non Ã©tudiant - modalitÃ© la plus frÃ©quente (94.9%)\n",
    "SANI        | SANI_2         | Salle de bain standard - modalitÃ© la plus frÃ©quente (96.1%)\n",
    "SEXE        | SEXE_1         | Homme - modalitÃ© la plus frÃ©quente (51.9%)\n",
    "TP          | TP_1           | Temps complet - modalitÃ© la plus frÃ©quente (83.2%)\n",
    "DEPT        | DEPT_51        | Marne - CHOIX UTILISATEUR (dÃ©partement intÃ©rieur, \n",
    "            |                | coefficients = effet relatif Ã  un dept non-frontalier)\n",
    "STOCD       | STOCD_10.0     | PropriÃ©taire - modalitÃ© la plus frÃ©quente (61.2%)\n",
    "VOIT        | VOIT_1.0       | 1 voiture - CHOIX UTILISATEUR (rÃ©fÃ©rence mÃ©diane)\n",
    "TYPL        | TYPL_1.0       | Maison - modalitÃ© la plus frÃ©quente (59.4%)\n",
    "DNAI        | DNAI_NEGRANDEST| NÃ© Grand Est - modalitÃ© la plus frÃ©quente (72.8%)\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================================\n",
    "# CHARGEMENT DES DONNÃ‰ES\n",
    "# ============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"PRÃ‰PARATION DE LA BASE PROBIT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Charger X_final_clean\n",
    "X = pd.read_csv('/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/ML_READY/FINAL_AFTER_ARBITRAGES/X_final_clean.csv')\n",
    "print(f\"\\nâœ“ Base chargÃ©e : {X.shape[0]:,} observations Ã— {X.shape[1]} variables\")\n",
    "\n",
    "# ============================================================================\n",
    "# DÃ‰FINITION DES CATÃ‰GORIES DE RÃ‰FÃ‰RENCE Ã€ SUPPRIMER\n",
    "# ============================================================================\n",
    "references_a_supprimer = {\n",
    "    # Variable catÃ©gorielle : colonne de rÃ©fÃ©rence Ã  supprimer\n",
    "    'GS': 'GS_5',              # EmployÃ©s (26.9%)\n",
    "    'EMPL': 'EMPL_16',         # CDI/Titulaire (75.8%)\n",
    "    'INATC': 'INATC_1',        # FranÃ§ais (92.8%)\n",
    "    'COUPLE': 'COUPLE_1',      # En couple (65.9%)\n",
    "    'NENFR': 'NENFR_0',        # 0 enfant - CHOIX UTILISATEUR\n",
    "    'NA5': 'NA5_GU',           # Commerce/Services (45.1%)\n",
    "    'DIPL': 'DIPL_13',         # CAP/BEP (23.8%)\n",
    "    'ETUD': 'ETUD_2',          # Non Ã©tudiant (94.9%)\n",
    "    'SANI': 'SANI_2',          # Salle de bain standard (96.1%)\n",
    "    'SEXE': 'SEXE_1',          # Homme (51.9%)\n",
    "    'TP': 'TP_1',              # Temps complet (83.2%)\n",
    "    'DEPT': 'DEPT_51',         # Marne - CHOIX UTILISATEUR\n",
    "    'STOCD': 'STOCD_10.0',     # PropriÃ©taire (61.2%)\n",
    "    'VOIT': 'VOIT_1.0',        # 1 voiture - CHOIX UTILISATEUR\n",
    "    'TYPL': 'TYPL_1.0',        # Maison (59.4%)\n",
    "    'DNAI': 'DNAI_NEGRANDEST', # NÃ© Grand Est (72.8%)\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# SUPPRESSION DES CATÃ‰GORIES DE RÃ‰FÃ‰RENCE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"CATÃ‰GORIES DE RÃ‰FÃ‰RENCE SUPPRIMÃ‰ES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "colonnes_a_supprimer = list(references_a_supprimer.values())\n",
    "colonnes_presentes = [col for col in colonnes_a_supprimer if col in X.columns]\n",
    "colonnes_absentes = [col for col in colonnes_a_supprimer if col not in X.columns]\n",
    "\n",
    "if colonnes_absentes:\n",
    "    print(f\"\\nâš  Colonnes non trouvÃ©es : {colonnes_absentes}\")\n",
    "\n",
    "# CrÃ©er la base probit\n",
    "bdd_probit = X.drop(columns=colonnes_presentes)\n",
    "\n",
    "print(f\"\\n{'Variable':<12} {'RÃ©fÃ©rence supprimÃ©e':<20} {'Justification'}\")\n",
    "print(\"-\" * 70)\n",
    "justifications = {\n",
    "    'GS_5': 'EmployÃ©s - plus frÃ©quent (26.9%)',\n",
    "    'EMPL_16': 'CDI/Titulaire - plus frÃ©quent (75.8%)',\n",
    "    'INATC_1': 'FranÃ§ais - plus frÃ©quent (92.8%)',\n",
    "    'COUPLE_1': 'En couple - plus frÃ©quent (65.9%)',\n",
    "    'NENFR_0': '0 enfant - CHOIX (interprÃ©tation parentalitÃ©)',\n",
    "    'NA5_GU': 'Commerce/Services - plus frÃ©quent (45.1%)',\n",
    "    'DIPL_13': 'CAP/BEP - plus frÃ©quent (23.8%)',\n",
    "    'ETUD_2': 'Non Ã©tudiant - plus frÃ©quent (94.9%)',\n",
    "    'SANI_2': 'Salle de bain - plus frÃ©quent (96.1%)',\n",
    "    'SEXE_1': 'Homme - plus frÃ©quent (51.9%)',\n",
    "    'TP_1': 'Temps complet - plus frÃ©quent (83.2%)',\n",
    "    'DEPT_51': 'Marne - CHOIX (dept intÃ©rieur, non-frontalier)',\n",
    "    'STOCD_10.0': 'PropriÃ©taire - plus frÃ©quent (61.2%)',\n",
    "    'VOIT_1.0': '1 voiture - CHOIX (rÃ©fÃ©rence mÃ©diane)',\n",
    "    'TYPL_1.0': 'Maison - plus frÃ©quent (59.4%)',\n",
    "    'DNAI_NEGRANDEST': 'NÃ© Grand Est - plus frÃ©quent (72.8%)',\n",
    "}\n",
    "\n",
    "for var, ref in references_a_supprimer.items():\n",
    "    if ref in colonnes_presentes:\n",
    "        print(f\"{var:<12} {ref:<20} {justifications.get(ref, '')}\")\n",
    "\n",
    "# ============================================================================\n",
    "# VÃ‰RIFICATION DE LA STRUCTURE FINALE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STRUCTURE DE LA BASE PROBIT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nâœ“ Dimensions finales : {bdd_probit.shape[0]:,} observations Ã— {bdd_probit.shape[1]} variables\")\n",
    "print(f\"  (suppression de {len(colonnes_presentes)} catÃ©gories de rÃ©fÃ©rence)\")\n",
    "\n",
    "# Compter les modalitÃ©s par variable conceptuelle\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"RÃ‰CAPITULATIF PAR VARIABLE CONCEPTUELLE\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"\\n{'Variable':<12} {'ModalitÃ©s gardÃ©es':<40} {'K-1'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Dictionnaire pour regrouper les colonnes par variable\n",
    "variables_conceptuelles = {\n",
    "    'AGEREV': ['AGEREV', 'AGEREV_sq'],\n",
    "    'GS': [c for c in bdd_probit.columns if c.startswith('GS_')],\n",
    "    'EMPL': [c for c in bdd_probit.columns if c.startswith('EMPL_')],\n",
    "    'INATC': [c for c in bdd_probit.columns if c.startswith('INATC_')],\n",
    "    'COUPLE': [c for c in bdd_probit.columns if c.startswith('COUPLE_')],\n",
    "    'NENFR': [c for c in bdd_probit.columns if c.startswith('NENFR_')],\n",
    "    'NA5': [c for c in bdd_probit.columns if c.startswith('NA5_')],\n",
    "    'DIPL': [c for c in bdd_probit.columns if c.startswith('DIPL_')],\n",
    "    'ETUD': [c for c in bdd_probit.columns if c.startswith('ETUD_')],\n",
    "    'SANI': [c for c in bdd_probit.columns if c.startswith('SANI_')],\n",
    "    'SEXE': [c for c in bdd_probit.columns if c.startswith('SEXE_')],\n",
    "    'TP': [c for c in bdd_probit.columns if c.startswith('TP_')],\n",
    "    'DEPT': [c for c in bdd_probit.columns if c.startswith('DEPT_')],\n",
    "    'STOCD': [c for c in bdd_probit.columns if c.startswith('STOCD_')],\n",
    "    'VOIT': [c for c in bdd_probit.columns if c.startswith('VOIT_')],\n",
    "    'TYPL': [c for c in bdd_probit.columns if c.startswith('TYPL_')],\n",
    "    'DNAI': [c for c in bdd_probit.columns if c.startswith('DNAI_')],\n",
    "}\n",
    "\n",
    "total_params = 0\n",
    "for var, cols in variables_conceptuelles.items():\n",
    "    if cols:\n",
    "        n_cols = len(cols)\n",
    "        total_params += n_cols\n",
    "        cols_str = ', '.join(cols[:3])\n",
    "        if len(cols) > 3:\n",
    "            cols_str += f'... (+{len(cols)-3})'\n",
    "        print(f\"{var:<12} {cols_str:<40} {n_cols}\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'TOTAL':<12} {'':<40} {total_params} + constante\")\n",
    "\n",
    "# ============================================================================\n",
    "# LISTE COMPLÃˆTE DES COLONNES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"LISTE COMPLÃˆTE DES COLONNES (ordre alphabÃ©tique)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, col in enumerate(sorted(bdd_probit.columns), 1):\n",
    "    print(f\"  {i:2}. {col}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAUVEGARDE\n",
    "# ============================================================================\n",
    "import os\n",
    "\n",
    "out_dir = \"/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "out_file = os.path.join(out_dir, \"BDD_PROBIT.csv\")   # choisis le nom que tu veux\n",
    "bdd_probit.to_csv(out_file, index=False)\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAUVEGARDE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nâœ“ Base sauvegardÃ©e : {output_path}\")\n",
    "print(f\"  â†’ {bdd_probit.shape[0]:,} observations\")\n",
    "print(f\"  â†’ {bdd_probit.shape[1]} variables explicatives\")\n",
    "\n",
    "# ============================================================================\n",
    "# APERÃ‡U FINAL\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"APERÃ‡U (5 premiÃ¨res lignes)\")\n",
    "print(\"-\" * 80)\n",
    "print(bdd_probit.head())\n",
    "\n",
    "# ============================================================================\n",
    "# VÃ‰RIFICATION : RANG DE LA MATRICE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"VÃ‰RIFICATION MULTICOLINÃ‰ARITÃ‰\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# VÃ©rifier que la matrice est de plein rang\n",
    "rank = np.linalg.matrix_rank(bdd_probit.values)\n",
    "print(f\"\\nâœ“ Rang de la matrice X : {rank}\")\n",
    "print(f\"âœ“ Nombre de colonnes   : {bdd_probit.shape[1]}\")\n",
    "\n",
    "if rank == bdd_probit.shape[1]:\n",
    "    print(\"\\nâœ… Matrice de plein rang - pas de multicolinÃ©aritÃ© parfaite\")\n",
    "else:\n",
    "    print(f\"\\nâš  ATTENTION : DÃ©ficit de rang = {bdd_probit.shape[1] - rank}\")\n",
    "    print(\"  â†’ MulticolinÃ©aritÃ© parfaite dÃ©tectÃ©e\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PRÃ‰PARATION TERMINÃ‰E\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecdbd79",
   "metadata": {},
   "source": [
    "La BDD est prÃªt pour le lancement de l'analyse statistique..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910e1c7",
   "metadata": {},
   "source": [
    "# Estimation Ã©conomÃ©trique en modÃ¨le probit binaire : Les dÃ©terminants du travail transfrontalier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d92e4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "  MODÃˆLE PROBIT BINAIRE â€” TRAVAIL TRANSFRONTALIER\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "    Date d'exÃ©cution : 2026-01-09 00:11:45\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  [1] CHARGEMENT DES DONNÃ‰ES\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "    âœ“ Observations                        : 494,483\n",
      "    âœ“ Features                            : 66 (dont constante)\n",
      "\n",
      "    Distribution de la variable cible :\n",
      "        â€¢ Transfrontaliers (Y=1)    : 44,264 (8.95%)\n",
      "        â€¢ Non-transfrontaliers (Y=0) : 450,219 (91.05%)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  [2] ESTIMATION DU MODÃˆLE PROBIT\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    â³ Estimation en cours...\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.229292\n",
      "         Iterations 10\n",
      "\n",
      "    âœ“ Estimation terminÃ©e en 17.5 secondes\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  [3] QUALITÃ‰ DE L'AJUSTEMENT\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "    âœ“ Convergence                         : âœ“ Oui\n",
      "    âœ“ ItÃ©rations                          : 10\n",
      "    âœ“ Log-vraisemblance                   : -113,380.76\n",
      "    âœ“ Log-L (modÃ¨le nul)                  : -149,045.06\n",
      "    âœ“ Pseudo RÂ² (McFadden)                : 0.2393\n",
      "    âœ“ AIC                                 : 226,893.52\n",
      "    âœ“ BIC                                 : 227,626.87\n",
      "    âœ“ Test LR (Ï‡Â²)                        : 71,328.59\n",
      "    âœ“ P-value LR                          : 0.00e+00\n",
      "    âœ“ Variables signif. (1%)              : 56/66\n",
      "    âœ“ Variables signif. (5%)              : 57/66\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  [4] CALCUL DES EFFETS MARGINAUX\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    â³ Calcul MEM (Ã  la moyenne)...\n",
      "    âœ“ MEM calculÃ© en 1.1 secondes\n",
      "\n",
      "    â³ Calcul AME (Ã©chantillon de 50,000 observations)...\n",
      "    âœ“ AME calculÃ© en 0.4 secondes sur 50,000 obs\n",
      "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "    â”‚  MEM (Marginal Effects at Means)                                  â”‚\n",
      "    â”‚    â†’ Effet pour un individu fictif aux caractÃ©ristiques moyennes  â”‚\n",
      "    â”‚    â†’ Calcul : Ï†(XÌ„'Î²) Ã— Î²                                         â”‚\n",
      "    â”‚                                                                   â”‚\n",
      "    â”‚  AME (Average Marginal Effects)  â† RECOMMANDÃ‰                     â”‚\n",
      "    â”‚    â†’ Effet moyen calculÃ© sur un Ã©chantillon reprÃ©sentatif         â”‚\n",
      "    â”‚    â†’ Calcul : (1/n) Î£ Ï†(Xáµ¢'Î²) Ã— Î²                                 â”‚\n",
      "    â”‚    â†’ Ã‰chantillon : 50,000 observations                            â”‚\n",
      "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  [5] COEFFICIENTS PROBIT\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    â€¢ Coefficients positifs : 24\n",
      "    â€¢ Coefficients nÃ©gatifs : 41\n",
      "\n",
      "    ğŸ”º COEFFICIENTS POSITIFS (â†‘ probabilitÃ© transfrontalier) :\n",
      "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "    Variable                          Coef    Std.Err        z      P>|z|   Sig\n",
      "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "    DEPT_57                        +2.4367     0.0481    50.65     0.0000   ***\n",
      "    DEPT_68                        +2.0908     0.0483    43.32     0.0000   ***\n",
      "    DEPT_54                        +1.9401     0.0484    40.07     0.0000   ***\n",
      "    DEPT_55                        +1.5232     0.0516    29.50     0.0000   ***\n",
      "    DEPT_67                        +1.4722     0.0484    30.45     0.0000   ***\n",
      "    INATC_2                        +0.4950     0.0136    36.37     0.0000   ***\n",
      "    EMPL_14                        +0.4143     0.0579     7.16     0.0000   ***\n",
      "    DNAI_NEETRANGER                +0.3496     0.0115    30.34     0.0000   ***\n",
      "    DEPT_88                        +0.2933     0.0634     4.63     0.0000   ***\n",
      "    DIPL_19                        +0.2444     0.0278     8.79     0.0000   ***\n",
      "    DIPL_18                        +0.2216     0.0122    18.21     0.0000   ***\n",
      "    VOIT_3.0                       +0.1665     0.0101    16.43     0.0000   ***\n",
      "    DIPL_11                        +0.1226     0.0315     3.90     0.0001   ***\n",
      "    TP_2                           +0.1225     0.0088    13.99     0.0000   ***\n",
      "    DEPT_52                        +0.1197     0.0894     1.34     0.1808      \n",
      "    VOIT_2.0                       +0.1181     0.0079    14.98     0.0000   ***\n",
      "    DEPT_10                        +0.1043     0.0725     1.44     0.1501      \n",
      "    GS_6                           +0.0932     0.0094     9.88     0.0000   ***\n",
      "    SANI_1                         +0.0876     0.0161     5.46     0.0000   ***\n",
      "    NENFR_Z                        +0.0819     0.0130     6.31     0.0000   ***\n",
      "    DIPL_17                        +0.0794     0.0114     6.97     0.0000   ***\n",
      "    AGEREV                         +0.0326     0.0019    16.87     0.0000   ***\n",
      "    COUPLE_2                       +0.0219     0.0096     2.29     0.0223     *\n",
      "    NA5_BE                         +0.0131     0.0082     1.59     0.1118      \n",
      "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    ğŸ”» COEFFICIENTS NÃ‰GATIFS (â†“ probabilitÃ© transfrontalier) :\n",
      "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "    Variable                          Coef    Std.Err        z      P>|z|   Sig\n",
      "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "    SANI_X                         -1.5565     0.1076   -14.47     0.0000   ***\n",
      "    NA5_AZ                         -0.9543     0.0539   -17.69     0.0000   ***\n",
      "    EMPL_13                        -0.7465     0.0805    -9.27     0.0000   ***\n",
      "    NA5_OQ                         -0.6602     0.0084   -78.40     0.0000   ***\n",
      "    TYPL_6.0                       -0.6315     0.1516    -4.17     0.0000   ***\n",
      "    TYPL_4.0                       -0.6174     0.1517    -4.07     0.0000   ***\n",
      "    EMPL_21                        -0.5691     0.0230   -24.73     0.0000   ***\n",
      "    EMPL_11                        -0.5282     0.0347   -15.22     0.0000   ***\n",
      "    DIPL_1                         -0.5207     0.0424   -12.28     0.0000   ***\n",
      "    STOCD_22.0                     -0.4938     0.0134   -36.85     0.0000   ***\n",
      "    TYPL_3.0                       -0.4778     0.0684    -6.99     0.0000   ***\n",
      "    EMPL_22                        -0.4735     0.0268   -17.68     0.0000   ***\n",
      "    ETUD_1                         -0.3310     0.0230   -14.38     0.0000   ***\n",
      "    VOIT_0.0                       -0.3233     0.0158   -20.51     0.0000   ***\n",
      "    GS_2                           -0.3072     0.0277   -11.08     0.0000   ***\n",
      "    STOCD_30.0                     -0.2839     0.0248   -11.44     0.0000   ***\n",
      "    DIPL_2                         -0.2534     0.0226   -11.23     0.0000   ***\n",
      "    EMPL_23                        -0.2226     0.1224    -1.82     0.0689     .\n",
      "    NENFR_4                        -0.2120     0.0219    -9.67     0.0000   ***\n",
      "    STOCD_23.0                     -0.2075     0.0236    -8.81     0.0000   ***\n",
      "    NENFR_3                        -0.1877     0.0137   -13.74     0.0000   ***\n",
      "    TYPL_5.0                       -0.1759     0.1350    -1.30     0.1925      \n",
      "    TYPL_2.0                       -0.1659     0.0084   -19.76     0.0000   ***\n",
      "    SEXE_2                         -0.1255     0.0069   -18.13     0.0000   ***\n",
      "    GS_1                           -0.1072     0.0938    -1.14     0.2529      \n",
      "    EMPL_15                        -0.1003     0.0128    -7.82     0.0000   ***\n",
      "    DIPL_3                         -0.0963     0.0141    -6.84     0.0000   ***\n",
      "    NENFR_2                        -0.0936     0.0094    -9.96     0.0000   ***\n",
      "    GS_3                           -0.0843     0.0115    -7.35     0.0000   ***\n",
      "    STOCD_21.0                     -0.0803     0.0088    -9.09     0.0000   ***\n",
      "    EMPL_12                        -0.0775     0.0194    -4.00     0.0001   ***\n",
      "    NENFR_1                        -0.0710     0.0090    -7.87     0.0000   ***\n",
      "    SANI_0                         -0.0697     0.0863    -0.81     0.4193      \n",
      "    DIPL_14                        -0.0500     0.0116    -4.33     0.0000   ***\n",
      "    DIPL_16                        -0.0488     0.0104    -4.69     0.0000   ***\n",
      "    GS_4                           -0.0401     0.0089    -4.49     0.0000   ***\n",
      "    DIPL_15                        -0.0354     0.0108    -3.27     0.0011    **\n",
      "    DNAI_NEAUTREFR                 -0.0299     0.0099    -3.02     0.0026    **\n",
      "    DIPL_12                        -0.0219     0.0183    -1.20     0.2308      \n",
      "    NA5_FZ                         -0.0204     0.0117    -1.75     0.0802     .\n",
      "    AGEREV_sq                      -0.0004     0.0000   -17.41     0.0000   ***\n",
      "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "    Signif. codes: '***' 0.001  '**' 0.01  '*' 0.05  '.' 0.1\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  [6] EFFETS MARGINAUX MOYENS â€” AME (en points de %)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    â€¢ Effets positifs : 24\n",
      "    â€¢ Effets nÃ©gatifs : 41\n",
      "\n",
      "    ğŸ”º AME POSITIFS (â†‘ probabilitÃ© transfrontalier) :\n",
      "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "    Variable                      AME (pp)      P>|z|   Sig\n",
      "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "    DEPT_57                      +30.6318%     0.0000   ***\n",
      "    DEPT_68                      +26.2830%     0.0000   ***\n",
      "    DEPT_54                      +24.3891%     0.0000   ***\n",
      "    DEPT_55                      +19.1479%     0.0000   ***\n",
      "    DEPT_67                      +18.5077%     0.0000   ***\n",
      "    INATC_2                       +6.2231%     0.0000   ***\n",
      "    EMPL_14                       +5.2077%     0.0000   ***\n",
      "    DNAI_NEETRANGER               +4.3946%     0.0000   ***\n",
      "    DEPT_88                       +3.6875%     0.0000   ***\n",
      "    DIPL_19                       +3.0728%     0.0000   ***\n",
      "    DIPL_18                       +2.7860%     0.0000   ***\n",
      "    VOIT_3.0                      +2.0929%     0.0000   ***\n",
      "    DIPL_11                       +1.5418%     0.0001   ***\n",
      "    TP_2                          +1.5397%     0.0000   ***\n",
      "    DEPT_52                       +1.5043%     0.1808      \n",
      "    VOIT_2.0                      +1.4844%     0.0000   ***\n",
      "    DEPT_10                       +1.3110%     0.1501      \n",
      "    GS_6                          +1.1714%     0.0000   ***\n",
      "    SANI_1                        +1.1013%     0.0000   ***\n",
      "    NENFR_Z                       +1.0290%     0.0000   ***\n",
      "    DIPL_17                       +0.9986%     0.0000   ***\n",
      "    AGEREV                        +0.4101%     0.0000   ***\n",
      "    COUPLE_2                      +0.2755%     0.0223     *\n",
      "    NA5_BE                        +0.1646%     0.1118      \n",
      "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    ğŸ”» AME NÃ‰GATIFS (â†“ probabilitÃ© transfrontalier) :\n",
      "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "    Variable                      AME (pp)      P>|z|   Sig\n",
      "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "    SANI_X                       -19.5667%     0.0000   ***\n",
      "    NA5_AZ                       -11.9960%     0.0000   ***\n",
      "    EMPL_13                       -9.3839%     0.0000   ***\n",
      "    NA5_OQ                        -8.2994%     0.0000   ***\n",
      "    TYPL_6.0                      -7.9390%     0.0000   ***\n",
      "    TYPL_4.0                      -7.7615%     0.0000   ***\n",
      "    EMPL_21                       -7.1539%     0.0000   ***\n",
      "    EMPL_11                       -6.6396%     0.0000   ***\n",
      "    DIPL_1                        -6.5464%     0.0000   ***\n",
      "    STOCD_22.0                    -6.2076%     0.0000   ***\n",
      "    TYPL_3.0                      -6.0061%     0.0000   ***\n",
      "    EMPL_22                       -5.9522%     0.0000   ***\n",
      "    ETUD_1                        -4.1607%     0.0000   ***\n",
      "    VOIT_0.0                      -4.0644%     0.0000   ***\n",
      "    GS_2                          -3.8619%     0.0000   ***\n",
      "    STOCD_30.0                    -3.5689%     0.0000   ***\n",
      "    DIPL_2                        -3.1860%     0.0000   ***\n",
      "    EMPL_23                       -2.7984%     0.0689     .\n",
      "    NENFR_4                       -2.6657%     0.0000   ***\n",
      "    STOCD_23.0                    -2.6091%     0.0000   ***\n",
      "    NENFR_3                       -2.3590%     0.0000   ***\n",
      "    TYPL_5.0                      -2.2115%     0.1925      \n",
      "    TYPL_2.0                      -2.0851%     0.0000   ***\n",
      "    SEXE_2                        -1.5778%     0.0000   ***\n",
      "    GS_1                          -1.3479%     0.2529      \n",
      "    EMPL_15                       -1.2610%     0.0000   ***\n",
      "    DIPL_3                        -1.2108%     0.0000   ***\n",
      "    NENFR_2                       -1.1765%     0.0000   ***\n",
      "    GS_3                          -1.0599%     0.0000   ***\n",
      "    STOCD_21.0                    -1.0094%     0.0000   ***\n",
      "    EMPL_12                       -0.9744%     0.0001   ***\n",
      "    NENFR_1                       -0.8926%     0.0000   ***\n",
      "    SANI_0                        -0.8764%     0.4193      \n",
      "    DIPL_14                       -0.6285%     0.0000   ***\n",
      "    DIPL_16                       -0.6131%     0.0000   ***\n",
      "    GS_4                          -0.5038%     0.0000   ***\n",
      "    DIPL_15                       -0.4454%     0.0011    **\n",
      "    DNAI_NEAUTREFR                -0.3754%     0.0026    **\n",
      "    DIPL_12                       -0.2758%     0.2308      \n",
      "    NA5_FZ                        -0.2566%     0.0802     .\n",
      "    AGEREV_sq                     -0.0049%     0.0000   ***\n",
      "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "    Signif. codes: '***' 0.001  '**' 0.01  '*' 0.05  '.' 0.1\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  [7] COMPARAISON MEM vs AME (TOP 10 par amplitude)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    Variable                      MEM (pp)     AME (pp)        Ã‰cart\n",
      "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "    DEPT_57                      +15.3453%    +30.6318%    +15.2865%\n",
      "    DEPT_68                      +13.1667%    +26.2830%    +13.1163%\n",
      "    DEPT_54                      +12.2179%    +24.3891%    +12.1711%\n",
      "    SANI_X                        -9.8021%    -19.5667%     -9.7646%\n",
      "    DEPT_55                       +9.5923%    +19.1479%     +9.5556%\n",
      "    DEPT_67                       +9.2716%    +18.5077%     +9.2361%\n",
      "    NA5_AZ                        -6.0095%    -11.9960%     -5.9865%\n",
      "    EMPL_13                       -4.7010%     -9.3839%     -4.6830%\n",
      "    NA5_OQ                        -4.1576%     -8.2994%     -4.1417%\n",
      "    TYPL_6.0                      -3.9771%     -7.9390%     -3.9619%\n",
      "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "    CorrÃ©lation MEM/AME : 1.0000\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  [8] EXPORT DES RÃ‰SULTATS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "    âœ“ probit_model1_summary.txt           : exportÃ©\n",
      "    âœ“ AME_results.csv                     : exportÃ©\n",
      "    âœ“ coefficients_probit.csv             : exportÃ©\n",
      "\n",
      "    ğŸ“ Fichiers exportÃ©s dans :\n",
      "       /Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready/\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "  RÃ‰SUMÃ‰ FINAL\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "    â”‚  PERFORMANCE DU MODÃˆLE                                  â”‚\n",
      "    â”‚    Pseudo RÂ² (McFadden)  : 0.2393                       â”‚\n",
      "    â”‚    AIC                   : 226,894                      â”‚\n",
      "    â”‚    BIC                   : 227,627                      â”‚\n",
      "    â”‚    Variables signif. 1%  : 56/66                        â”‚\n",
      "    â”‚                                                         â”‚\n",
      "    â”‚  TOP 6 EFFETS POSITIFS (AME) :                          â”‚\n",
      "    â”‚    DEPT_57                : +30.632 pp ***              â”‚\n",
      "    â”‚    DEPT_68                : +26.283 pp ***              â”‚\n",
      "    â”‚    DEPT_54                : +24.389 pp ***              â”‚\n",
      "    â”‚    DEPT_55                : +19.148 pp ***              â”‚\n",
      "    â”‚    DEPT_67                : +18.508 pp ***              â”‚\n",
      "    â”‚    INATC_2                :  +6.223 pp ***              â”‚\n",
      "    â”‚                                                         â”‚\n",
      "    â”‚  TOP 6 EFFETS NÃ‰GATIFS (AME) :                          â”‚\n",
      "    â”‚    SANI_X                 : -19.567 pp ***              â”‚\n",
      "    â”‚    NA5_AZ                 : -11.996 pp ***              â”‚\n",
      "    â”‚    EMPL_13                :  -9.384 pp ***              â”‚\n",
      "    â”‚    NA5_OQ                 :  -8.299 pp ***              â”‚\n",
      "    â”‚    TYPL_6.0               :  -7.939 pp ***              â”‚\n",
      "    â”‚    TYPL_4.0               :  -7.762 pp ***              â”‚\n",
      "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "  âœ… ESTIMATION PROBIT TERMINÃ‰E AVEC SUCCÃˆS\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "MODÃˆLE 1 : PROBIT BINAIRE â€” DÃ‰TERMINANTS DU TRAVAIL TRANSFRONTALIER\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "Projet INSEE â€” MobilitÃ© TransfrontaliÃ¨re Grand Est\n",
    "Master 2 Statistique, Ã‰conomÃ©trie & Data Science â€” UniversitÃ© de Strasbourg\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#                               CONFIGURATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "PATH = '/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready/'\n",
    "OUTPUT_FILE = 'probit_model1_summary.txt'\n",
    "\n",
    "# Taille de l'Ã©chantillon pour le calcul des AME (None = toutes les observations)\n",
    "AME_SAMPLE_SIZE = 50000  # 50k observations suffisent pour des AME prÃ©cis\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#                           FONCTIONS UTILITAIRES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def print_header(title, width=80):\n",
    "    \"\"\"Affiche un en-tÃªte principal.\"\"\"\n",
    "    print(\"\\n\" + \"â•\" * width)\n",
    "    print(f\"  {title}\")\n",
    "    print(\"â•\" * width)\n",
    "\n",
    "def print_section(num, title, width=80):\n",
    "    \"\"\"Affiche un titre de section numÃ©rotÃ©e.\"\"\"\n",
    "    print(\"\\n\" + \"â”€\" * width)\n",
    "    print(f\"  [{num}] {title}\")\n",
    "    print(\"â”€\" * width)\n",
    "\n",
    "def print_metric(label, value, indent=4):\n",
    "    \"\"\"Affiche une mÃ©trique formatÃ©e.\"\"\"\n",
    "    prefix = \"âœ“\" if not label.startswith(\"â€¢\") else \" \"\n",
    "    clean_label = label.lstrip(\"â€¢ \")\n",
    "    print(f\"{' ' * indent}{prefix} {clean_label:<35} : {value}\")\n",
    "\n",
    "def print_bullet(label, value, indent=8):\n",
    "    \"\"\"Affiche un bullet point.\"\"\"\n",
    "    print(f\"{' ' * indent}â€¢ {label:<25} : {value}\")\n",
    "\n",
    "def format_significance(pval):\n",
    "    \"\"\"Retourne les Ã©toiles de significativitÃ©.\"\"\"\n",
    "    if pval < 0.001: return \"***\"\n",
    "    elif pval < 0.01: return \"**\"\n",
    "    elif pval < 0.05: return \"*\"\n",
    "    elif pval < 0.1: return \".\"\n",
    "    else: return \"\"\n",
    "\n",
    "def print_box(lines, width=70, indent=4):\n",
    "    \"\"\"Affiche un encadrÃ©.\"\"\"\n",
    "    print(f\"{' ' * indent}â”Œ{'â”€' * (width-2)}â”\")\n",
    "    for line in lines:\n",
    "        print(f\"{' ' * indent}â”‚  {line:<{width-5}}â”‚\")\n",
    "    print(f\"{' ' * indent}â””{'â”€' * (width-2)}â”˜\")\n",
    "\n",
    "def compute_ame_manual(result, X, sample_size=None, random_state=42):\n",
    "    \"\"\"\n",
    "    Calcule les AME manuellement avec Ã©chantillonnage optionnel.\n",
    "    Beaucoup plus rapide que get_margeff(at='overall') sur grandes bases.\n",
    "    \n",
    "    AME = moyenne sur i de [ Ï†(X_i'Î²) Ã— Î²_j ]\n",
    "    oÃ¹ Ï† est la densitÃ© de la loi normale standard.\n",
    "    \"\"\"\n",
    "    from scipy.stats import norm\n",
    "    \n",
    "    # Ã‰chantillonnage si demandÃ©\n",
    "    if sample_size and sample_size < len(X):\n",
    "        np.random.seed(random_state)\n",
    "        idx = np.random.choice(len(X), size=sample_size, replace=False)\n",
    "        X_sample = X.iloc[idx] if hasattr(X, 'iloc') else X[idx]\n",
    "        n_used = sample_size\n",
    "    else:\n",
    "        X_sample = X\n",
    "        n_used = len(X)\n",
    "    \n",
    "    # Calcul du score linÃ©aire X'Î²\n",
    "    beta = result.params.values\n",
    "    X_arr = np.asarray(X_sample)\n",
    "    linear_pred = X_arr @ beta  # XÎ²\n",
    "    \n",
    "    # DensitÃ© normale Ã©valuÃ©e en XÎ²\n",
    "    phi = norm.pdf(linear_pred)  # Ï†(XÎ²)\n",
    "    \n",
    "    # AME pour chaque variable = moyenne de Ï†(XÎ²) Ã— Î²_j\n",
    "    ame_values = phi.mean() * beta\n",
    "    \n",
    "    # Exclure la constante\n",
    "    var_names = result.params.index.tolist()\n",
    "    if 'const' in var_names:\n",
    "        const_idx = var_names.index('const')\n",
    "        ame_values = np.delete(ame_values, const_idx)\n",
    "        var_names.remove('const')\n",
    "    \n",
    "    # Construire le DataFrame\n",
    "    ame_df = pd.DataFrame({\n",
    "        'ame': ame_values,\n",
    "        'ame_pp': ame_values * 100\n",
    "    }, index=var_names)\n",
    "    \n",
    "    return ame_df, n_used\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#                           CHARGEMENT DES DONNÃ‰ES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print_header(\"MODÃˆLE PROBIT BINAIRE â€” TRAVAIL TRANSFRONTALIER\")\n",
    "print(f\"\\n    Date d'exÃ©cution : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print_section(1, \"CHARGEMENT DES DONNÃ‰ES\")\n",
    "\n",
    "X = pd.read_csv(PATH + 'BDD_PROBIT.csv')\n",
    "y = pd.read_csv(PATH + 'y_final.csv')['TRANSFRONTALIER']\n",
    "X_const = sm.add_constant(X)\n",
    "\n",
    "n_obs = len(y)\n",
    "n_trans = y.sum()\n",
    "pct_trans = y.mean() * 100\n",
    "n_vars = X_const.shape[1]\n",
    "\n",
    "print_metric(\"Observations\", f\"{n_obs:,}\")\n",
    "print_metric(\"Features\", f\"{n_vars} (dont constante)\")\n",
    "\n",
    "print(f\"\\n    Distribution de la variable cible :\")\n",
    "print_bullet(\"Transfrontaliers (Y=1)\", f\"{n_trans:,} ({pct_trans:.2f}%)\")\n",
    "print_bullet(\"Non-transfrontaliers (Y=0)\", f\"{n_obs - n_trans:,} ({100-pct_trans:.2f}%)\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#                            ESTIMATION DU MODÃˆLE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print_section(2, \"ESTIMATION DU MODÃˆLE PROBIT\")\n",
    "print(\"\\n    â³ Estimation en cours...\\n\")\n",
    "\n",
    "start_estim = time.time()\n",
    "probit = sm.Probit(y, X_const)\n",
    "result = probit.fit(disp=True, maxiter=100)\n",
    "time_estim = time.time() - start_estim\n",
    "\n",
    "print(f\"\\n    âœ“ Estimation terminÃ©e en {time_estim:.1f} secondes\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#                          QUALITÃ‰ DE L'AJUSTEMENT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print_section(3, \"QUALITÃ‰ DE L'AJUSTEMENT\")\n",
    "\n",
    "convergence = \"âœ“ Oui\" if result.mle_retvals['converged'] else \"âœ— Non\"\n",
    "print_metric(\"Convergence\", convergence)\n",
    "print_metric(\"ItÃ©rations\", result.mle_retvals['iterations'])\n",
    "print_metric(\"Log-vraisemblance\", f\"{result.llf:,.2f}\")\n",
    "print_metric(\"Log-L (modÃ¨le nul)\", f\"{result.llnull:,.2f}\")\n",
    "print_metric(\"Pseudo RÂ² (McFadden)\", f\"{result.prsquared:.4f}\")\n",
    "print_metric(\"AIC\", f\"{result.aic:,.2f}\")\n",
    "print_metric(\"BIC\", f\"{result.bic:,.2f}\")\n",
    "\n",
    "lr_stat = -2 * (result.llnull - result.llf)\n",
    "print_metric(\"Test LR (Ï‡Â²)\", f\"{lr_stat:,.2f}\")\n",
    "print_metric(\"P-value LR\", f\"{result.llr_pvalue:.2e}\")\n",
    "\n",
    "n_signif_1 = (result.pvalues < 0.01).sum()\n",
    "n_signif_5 = (result.pvalues < 0.05).sum()\n",
    "print_metric(\"Variables signif. (1%)\", f\"{n_signif_1}/{n_vars}\")\n",
    "print_metric(\"Variables signif. (5%)\", f\"{n_signif_5}/{n_vars}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#                             EFFETS MARGINAUX\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print_section(4, \"CALCUL DES EFFETS MARGINAUX\")\n",
    "\n",
    "# --- MEM (rapide) ---\n",
    "print(\"\\n    â³ Calcul MEM (Ã  la moyenne)...\")\n",
    "start_mem = time.time()\n",
    "mem = result.get_margeff(at='mean')\n",
    "time_mem = time.time() - start_mem\n",
    "print(f\"    âœ“ MEM calculÃ© en {time_mem:.1f} secondes\")\n",
    "\n",
    "# --- AME (avec Ã©chantillonnage) ---\n",
    "print(f\"\\n    â³ Calcul AME (Ã©chantillon de {AME_SAMPLE_SIZE:,} observations)...\")\n",
    "start_ame = time.time()\n",
    "ame_df, n_ame_used = compute_ame_manual(result, X_const, sample_size=AME_SAMPLE_SIZE)\n",
    "time_ame = time.time() - start_ame\n",
    "print(f\"    âœ“ AME calculÃ© en {time_ame:.1f} secondes sur {n_ame_used:,} obs\")\n",
    "\n",
    "print_box([\n",
    "    \"MEM (Marginal Effects at Means)\",\n",
    "    \"  â†’ Effet pour un individu fictif aux caractÃ©ristiques moyennes\",\n",
    "    \"  â†’ Calcul : Ï†(XÌ„'Î²) Ã— Î²\",\n",
    "    \"\",\n",
    "    \"AME (Average Marginal Effects)  â† RECOMMANDÃ‰\",\n",
    "    \"  â†’ Effet moyen calculÃ© sur un Ã©chantillon reprÃ©sentatif\",\n",
    "    \"  â†’ Calcul : (1/n) Î£ Ï†(Xáµ¢'Î²) Ã— Î²\",\n",
    "    f\"  â†’ Ã‰chantillon : {n_ame_used:,} observations\"\n",
    "])\n",
    "\n",
    "# Construire MEM DataFrame\n",
    "mem_raw = mem.summary_frame()\n",
    "mem_df = pd.DataFrame(index=mem_raw.index)\n",
    "mem_df['mem_pp'] = mem_raw['dy/dx'] * 100\n",
    "\n",
    "# Ajouter significativitÃ© aux AME (depuis les coefficients du modÃ¨le)\n",
    "ame_df['pval'] = result.pvalues.drop('const', errors='ignore')\n",
    "ame_df['sig'] = ame_df['pval'].apply(format_significance)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#                    COEFFICIENTS PROBIT (PANIERS +/-)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print_section(5, \"COEFFICIENTS PROBIT\")\n",
    "\n",
    "# PrÃ©parer les donnÃ©es (exclure constante)\n",
    "coef_df = pd.DataFrame({\n",
    "    'coef': result.params,\n",
    "    'std_err': result.bse,\n",
    "    'z': result.tvalues,\n",
    "    'pval': result.pvalues\n",
    "}).drop('const', errors='ignore')\n",
    "\n",
    "coef_df['sig'] = coef_df['pval'].apply(format_significance)\n",
    "\n",
    "# SÃ©parer positifs et nÃ©gatifs\n",
    "positifs = coef_df[coef_df['coef'] > 0].sort_values('coef', ascending=False)\n",
    "negatifs = coef_df[coef_df['coef'] < 0].sort_values('coef', ascending=True)\n",
    "\n",
    "print(f\"\\n    â€¢ Coefficients positifs : {len(positifs)}\")\n",
    "print(f\"    â€¢ Coefficients nÃ©gatifs : {len(negatifs)}\")\n",
    "\n",
    "# Afficher positifs\n",
    "print(f\"\\n    ğŸ”º COEFFICIENTS POSITIFS (â†‘ probabilitÃ© transfrontalier) :\")\n",
    "print(\"    \" + \"â”€\" * 72)\n",
    "print(f\"    {'Variable':<25} {'Coef':>12} {'Std.Err':>10} {'z':>8} {'P>|z|':>10} {'Sig':>5}\")\n",
    "print(\"    \" + \"â”€\" * 72)\n",
    "\n",
    "for var, row in positifs.iterrows():\n",
    "    print(f\"    {var:<25} {row['coef']:>+12.4f} {row['std_err']:>10.4f} {row['z']:>8.2f} {row['pval']:>10.4f} {row['sig']:>5}\")\n",
    "\n",
    "print(\"    \" + \"â”€\" * 72)\n",
    "\n",
    "# Afficher nÃ©gatifs\n",
    "print(f\"\\n    ğŸ”» COEFFICIENTS NÃ‰GATIFS (â†“ probabilitÃ© transfrontalier) :\")\n",
    "print(\"    \" + \"â”€\" * 72)\n",
    "print(f\"    {'Variable':<25} {'Coef':>12} {'Std.Err':>10} {'z':>8} {'P>|z|':>10} {'Sig':>5}\")\n",
    "print(\"    \" + \"â”€\" * 72)\n",
    "\n",
    "for var, row in negatifs.iterrows():\n",
    "    print(f\"    {var:<25} {row['coef']:>+12.4f} {row['std_err']:>10.4f} {row['z']:>8.2f} {row['pval']:>10.4f} {row['sig']:>5}\")\n",
    "\n",
    "print(\"    \" + \"â”€\" * 72)\n",
    "print(\"    Signif. codes: '***' 0.001  '**' 0.01  '*' 0.05  '.' 0.1\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#                       EFFETS MARGINAUX AME (PANIERS +/-)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print_section(6, \"EFFETS MARGINAUX MOYENS â€” AME (en points de %)\")\n",
    "\n",
    "# SÃ©parer positifs et nÃ©gatifs\n",
    "ame_pos = ame_df[ame_df['ame_pp'] > 0].sort_values('ame_pp', ascending=False)\n",
    "ame_neg = ame_df[ame_df['ame_pp'] < 0].sort_values('ame_pp', ascending=True)\n",
    "\n",
    "print(f\"\\n    â€¢ Effets positifs : {len(ame_pos)}\")\n",
    "print(f\"    â€¢ Effets nÃ©gatifs : {len(ame_neg)}\")\n",
    "\n",
    "# Afficher positifs\n",
    "print(f\"\\n    ğŸ”º AME POSITIFS (â†‘ probabilitÃ© transfrontalier) :\")\n",
    "print(\"    \" + \"â”€\" * 55)\n",
    "print(f\"    {'Variable':<25} {'AME (pp)':>12} {'P>|z|':>10} {'Sig':>5}\")\n",
    "print(\"    \" + \"â”€\" * 55)\n",
    "\n",
    "for var, row in ame_pos.iterrows():\n",
    "    print(f\"    {var:<25} {row['ame_pp']:>+11.4f}% {row['pval']:>10.4f} {row['sig']:>5}\")\n",
    "\n",
    "print(\"    \" + \"â”€\" * 55)\n",
    "\n",
    "# Afficher nÃ©gatifs\n",
    "print(f\"\\n    ğŸ”» AME NÃ‰GATIFS (â†“ probabilitÃ© transfrontalier) :\")\n",
    "print(\"    \" + \"â”€\" * 55)\n",
    "print(f\"    {'Variable':<25} {'AME (pp)':>12} {'P>|z|':>10} {'Sig':>5}\")\n",
    "print(\"    \" + \"â”€\" * 55)\n",
    "\n",
    "for var, row in ame_neg.iterrows():\n",
    "    print(f\"    {var:<25} {row['ame_pp']:>+11.4f}% {row['pval']:>10.4f} {row['sig']:>5}\")\n",
    "\n",
    "print(\"    \" + \"â”€\" * 55)\n",
    "print(\"    Signif. codes: '***' 0.001  '**' 0.01  '*' 0.05  '.' 0.1\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#                         COMPARAISON MEM vs AME\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print_section(7, \"COMPARAISON MEM vs AME (TOP 10 par amplitude)\")\n",
    "\n",
    "# Fusionner et trier par amplitude AME\n",
    "compare_df = pd.DataFrame({\n",
    "    'MEM (pp)': mem_df['mem_pp'],\n",
    "    'AME (pp)': ame_df['ame_pp'],\n",
    "})\n",
    "compare_df['Ã‰cart'] = compare_df['AME (pp)'] - compare_df['MEM (pp)']\n",
    "compare_df['|AME|'] = compare_df['AME (pp)'].abs()\n",
    "compare_df = compare_df.sort_values('|AME|', ascending=False).head(10)\n",
    "\n",
    "print(f\"\\n    {'Variable':<25} {'MEM (pp)':>12} {'AME (pp)':>12} {'Ã‰cart':>12}\")\n",
    "print(\"    \" + \"â”€\" * 65)\n",
    "\n",
    "for var, row in compare_df.iterrows():\n",
    "    print(f\"    {var:<25} {row['MEM (pp)']:>+11.4f}% {row['AME (pp)']:>+11.4f}% {row['Ã‰cart']:>+11.4f}%\")\n",
    "\n",
    "print(\"    \" + \"â”€\" * 65)\n",
    "\n",
    "# CorrÃ©lation MEM/AME\n",
    "corr = mem_df['mem_pp'].corr(ame_df['ame_pp'])\n",
    "print(f\"\\n    CorrÃ©lation MEM/AME : {corr:.4f}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#                              SAUVEGARDE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print_section(8, \"EXPORT DES RÃ‰SULTATS\")\n",
    "\n",
    "output_path = PATH + OUTPUT_FILE\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(\"MODÃˆLE PROBIT BINAIRE â€” DÃ‰TERMINANTS DU TRAVAIL TRANSFRONTALIER\\n\")\n",
    "    f.write(f\"GÃ©nÃ©rÃ© le : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "    \n",
    "    # RÃ©sumÃ© du modÃ¨le\n",
    "    f.write(\"RÃ‰SUMÃ‰ DU MODÃˆLE\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(result.summary().as_text())\n",
    "    \n",
    "    # Effets marginaux MEM\n",
    "    f.write(\"\\n\\n\" + \"=\" * 80 + \"\\n\")\n",
    "    f.write(\"EFFETS MARGINAUX Ã€ LA MOYENNE (MEM)\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(mem.summary().as_text())\n",
    "    \n",
    "    # Effets marginaux AME\n",
    "    f.write(\"\\n\\n\" + \"=\" * 80 + \"\\n\")\n",
    "    f.write(f\"EFFETS MARGINAUX MOYENS (AME) â€” CalculÃ©s sur {n_ame_used:,} observations\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(ame_df.to_string())\n",
    "\n",
    "# Export CSV des AME\n",
    "ame_export = ame_df[['ame', 'ame_pp', 'pval', 'sig']].copy()\n",
    "ame_export.columns = ['AME', 'AME_pp', 'pvalue', 'signif']\n",
    "ame_export.to_csv(PATH + 'AME_results.csv')\n",
    "\n",
    "# Export CSV des coefficients\n",
    "coef_df.to_csv(PATH + 'coefficients_probit.csv')\n",
    "\n",
    "print_metric(\"probit_model1_summary.txt\", \"exportÃ©\")\n",
    "print_metric(\"AME_results.csv\", \"exportÃ©\")\n",
    "print_metric(\"coefficients_probit.csv\", \"exportÃ©\")\n",
    "print(f\"\\n    ğŸ“ Fichiers exportÃ©s dans :\\n       {PATH}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#                              RÃ‰SUMÃ‰ FINAL\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print_header(\"RÃ‰SUMÃ‰ FINAL\")\n",
    "\n",
    "# Top 6 AME positifs et nÃ©gatifs\n",
    "top6_pos = ame_pos.head(6)\n",
    "top6_neg = ame_neg.head(6)\n",
    "\n",
    "summary_lines = [\n",
    "    \"PERFORMANCE DU MODÃˆLE\",\n",
    "    f\"  Pseudo RÂ² (McFadden)  : {result.prsquared:.4f}\",\n",
    "    f\"  AIC                   : {result.aic:,.0f}\",\n",
    "    f\"  BIC                   : {result.bic:,.0f}\",\n",
    "    f\"  Variables signif. 1%  : {n_signif_1}/{n_vars}\",\n",
    "    \"\",\n",
    "    \"TOP 6 EFFETS POSITIFS (AME) :\"\n",
    "]\n",
    "\n",
    "for var, row in top6_pos.iterrows():\n",
    "    summary_lines.append(f\"  {var:<22} : {row['ame_pp']:>+7.3f} pp {row['sig']}\")\n",
    "\n",
    "summary_lines.append(\"\")\n",
    "summary_lines.append(\"TOP 6 EFFETS NÃ‰GATIFS (AME) :\")\n",
    "\n",
    "for var, row in top6_neg.iterrows():\n",
    "    summary_lines.append(f\"  {var:<22} : {row['ame_pp']:>+7.3f} pp {row['sig']}\")\n",
    "\n",
    "print_box(summary_lines, width=60)\n",
    "\n",
    "print(\"\\n\" + \"â•\" * 80)\n",
    "print(\"  âœ… ESTIMATION PROBIT TERMINÃ‰E AVEC SUCCÃˆS\")\n",
    "print(\"â•\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7e7f0b",
   "metadata": {},
   "source": [
    "## RÃ©sultats prÃ©liminaires du modÃ¨le probit\n",
    "\n",
    "### Convention de lecture\n",
    "\n",
    "Les rÃ©sultats sont prÃ©sentÃ©s sous deux formes complÃ©mentaires :\n",
    "\n",
    "1. **Coefficient probit** : paramÃ¨tre estimÃ© du modÃ¨le, dont le signe indique la direction de l'effet mais dont l'amplitude n'est pas directement interprÃ©table.\n",
    "\n",
    "2. **Effet marginal moyen (AME, en pp)** : variation moyenne de la probabilitÃ© d'Ãªtre transfrontalier en points de pourcentage, calculÃ©e sur l'ensemble de la population. *Exemple : +5 pp signifie que la probabilitÃ© passe en moyenne de 8,95% Ã  13,95%.*\n",
    "\n",
    "La catÃ©gorie de rÃ©fÃ©rence pour les variables dÃ©partementales est la Marne (DEPT_51), dÃ©partement non frontalier.\n",
    "\n",
    "### Calcul des effets marginaux\n",
    "\n",
    "Deux approches sont possibles pour calculer les effets marginaux d'un modÃ¨le probit :\n",
    "\n",
    "| MÃ©thode | Formule | InterprÃ©tation |\n",
    "|---------|---------|----------------|\n",
    "| **MEM** (Marginal Effects at Means) | $\\phi(\\bar{X}'\\beta) \\times \\beta$ | Effet pour un individu fictif aux caractÃ©ristiques moyennes |\n",
    "| **AME** (Average Marginal Effects) | $\\frac{1}{n} \\sum_i \\phi(X_i'\\beta) \\times \\beta$ | Effet moyen dans la population rÃ©elle |\n",
    "\n",
    "Dans cette Ã©tude, les AME sont systÃ©matiquement **deux fois supÃ©rieurs** aux MEM (corrÃ©lation = 1,00), reflÃ©tant la forte hÃ©tÃ©rogÃ©nÃ©itÃ© de la population Ã©tudiÃ©e. L'individu \"moyen\" â€” rÃ©sidant Ã  48% en Moselle, Ã  48% femme â€” n'existe pas rÃ©ellement et se situe dans la queue basse de la distribution des probabilitÃ©s prÃ©dites.\n",
    "\n",
    "**Nous reportons les AME**, plus reprÃ©sentatifs de l'effet moyen rÃ©ellement observÃ© dans la population du Grand Est.\n",
    "\n",
    "### Classification des variables selon le risque d'endogÃ©nÃ©itÃ©\n",
    "\n",
    "| Statut | InterprÃ©tation | Variables concernÃ©es |\n",
    "|--------|----------------|----------------------|\n",
    "| **ExogÃ¨ne** | Relation causale plausible | DÃ©partement, Ã¢ge, sexe, nationalitÃ©, lieu de naissance, diplÃ´me |\n",
    "| **Probablement exogÃ¨ne** | CausalitÃ© vraisemblable | Nombre d'enfants, secteur d'activitÃ©, catÃ©gorie socioprofessionnelle |\n",
    "| **Ambigu** | CausalitÃ© incertaine | Type de contrat, temps de travail |\n",
    "| **Potentiellement endogÃ¨ne** | CausalitÃ© inverse possible | Statut d'occupation, nombre de voitures, type de logement |\n",
    "\n",
    "Cette classification guide l'interprÃ©tation : seules les variables exogÃ¨nes autorisent une lecture causale. Les variables potentiellement endogÃ¨nes sont incluses comme contrÃ´les mais leurs coefficients ne doivent pas Ãªtre interprÃ©tÃ©s causalement.\n",
    "\n",
    "---\n",
    "\n",
    "### QualitÃ© globale de l'estimation\n",
    "\n",
    "Le modÃ¨le converge en 10 itÃ©rations sur 494 483 observations (44 264 transfrontaliers, soit 8,95%). Le pseudo-RÂ² de McFadden s'Ã©tablit Ã  **0,239**, valeur satisfaisante pour un modÃ¨le de choix discret sur donnÃ©es individuelles. Le test du ratio de vraisemblance rejette la nullitÃ© jointe des coefficients (Ï‡Â² = 71 329, p < 0,001). Sur 66 variables (constante incluse), 56 sont significatives au seuil de 1%.\n",
    "\n",
    "---\n",
    "\n",
    "### Principaux rÃ©sultats (AME)\n",
    "\n",
    "Les effets marginaux moyens rÃ©vÃ¨lent plusieurs rÃ©gularitÃ©s cohÃ©rentes avec la littÃ©rature et les attentes thÃ©oriques.\n",
    "\n",
    "#### Gradient gÃ©ographique\n",
    "\n",
    "Les dÃ©partements frontaliers affichent les effets les plus forts du modÃ¨le :\n",
    "\n",
    "| DÃ©partement | AME | InterprÃ©tation |\n",
    "|-------------|-----|----------------|\n",
    "| Moselle (57) | +30.6 pp | ProximitÃ© Luxembourg |\n",
    "| Haut-Rhin (68) | +26.3 pp | ProximitÃ© Suisse/Allemagne |\n",
    "| Meurthe-et-Moselle (54) | +24.4 pp | ProximitÃ© Luxembourg |\n",
    "| Meuse (55) | +19.1 pp | ProximitÃ© Luxembourg/Belgique |\n",
    "| Bas-Rhin (67) | +18.5 pp | ProximitÃ© Allemagne |\n",
    "\n",
    "Ces effets considÃ©rables reflÃ¨tent la structuration spatiale du phÃ©nomÃ¨ne : rÃ©sider en Moselle plutÃ´t qu'en Marne augmente en moyenne de 31 points de pourcentage la probabilitÃ© d'Ãªtre transfrontalier.\n",
    "\n",
    "#### Profil dÃ©mographique\n",
    "\n",
    "| Variable | AME | InterprÃ©tation |\n",
    "|----------|-----|----------------|\n",
    "| Ã‚ge (par annÃ©e) | +0.41 pp | Effet positif dÃ©croissant |\n",
    "| Ã‚geÂ² | -0.005 pp | Forme en U inversÃ©, pic ~41 ans |\n",
    "| Femme (SEXE_2) | -1.58 pp | ProbabilitÃ© infÃ©rieure pour les femmes |\n",
    "| 1 enfant | -0.89 pp | LÃ©gÃ¨re pÃ©nalitÃ© |\n",
    "| 2 enfants | -1.18 pp | PÃ©nalitÃ© croissante |\n",
    "| 3 enfants | -2.36 pp | PÃ©nalitÃ© marquÃ©e |\n",
    "| 4+ enfants | -2.67 pp | PÃ©nalitÃ© maximale |\n",
    "\n",
    "L'Ã¢ge suit une forme quadratique avec un pic estimÃ© vers 41 ans. Les femmes prÃ©sentent une probabilitÃ© infÃ©rieure de 1,6 pp, toutes choses Ã©gales par ailleurs. La prÃ©sence d'enfants exerce un effet nÃ©gatif croissant avec leur nombre.\n",
    "\n",
    "#### RÃ©seaux transnationaux\n",
    "\n",
    "| Variable | AME | InterprÃ©tation |\n",
    "|----------|-----|----------------|\n",
    "| NationalitÃ© Ã©trangÃ¨re (INATC_2) | +6.22 pp | Fort avantage |\n",
    "| NÃ© Ã  l'Ã©tranger | +4.39 pp | Avantage significatif |\n",
    "| NÃ© ailleurs en France | -0.38 pp | LÃ©ger dÃ©savantage |\n",
    "\n",
    "La nationalitÃ© Ã©trangÃ¨re et la naissance Ã  l'Ã©tranger sont fortement associÃ©es au travail frontalier, possiblement via les compÃ©tences linguistiques et les rÃ©seaux professionnels transnationaux.\n",
    "\n",
    "#### Structure professionnelle\n",
    "\n",
    "| Variable | AME | InterprÃ©tation |\n",
    "|----------|-----|----------------|\n",
    "| IndÃ©pendants (EMPL_14) | +5.21 pp | Avantage entrepreneuriat |\n",
    "| Ouvriers (GS_6) | +1.17 pp | CatÃ©gorie favorisÃ©e |\n",
    "| CDI public (EMPL_21) | -7.15 pp | Secteur public pÃ©nalisÃ© |\n",
    "| CDI privÃ© (EMPL_22) | -5.95 pp | RÃ©fÃ©rence = autres statuts |\n",
    "| Agriculture (NA5_AZ) | -12.00 pp | Secteur exclu |\n",
    "| Administration (NA5_OQ) | -8.30 pp | Secteur public pÃ©nalisÃ© |\n",
    "\n",
    "Le travail frontalier apparaÃ®t comme un phÃ©nomÃ¨ne mixte : les indÃ©pendants (entrepreneurs transfrontaliers) et les ouvriers (industrie frontaliÃ¨re) sont favorisÃ©s, tandis que le secteur public et l'agriculture sont fortement exclus.\n",
    "\n",
    "#### Capital humain\n",
    "\n",
    "| Variable | AME | InterprÃ©tation |\n",
    "|----------|-----|----------------|\n",
    "| Grande Ã©cole (DIPL_19) | +3.07 pp | Prime aux trÃ¨s diplÃ´mÃ©s |\n",
    "| Bac+5 (DIPL_18) | +2.79 pp | Prime aux diplÃ´mÃ©s |\n",
    "| Bac+4 (DIPL_11) | +1.54 pp | Effet positif |\n",
    "| Bac pro (DIPL_17) | +1.00 pp | Effet positif |\n",
    "| Doctorat (DIPL_1) | -6.55 pp | Effet nÃ©gatif (recherche publique) |\n",
    "| Sans diplÃ´me (DIPL_2) | -3.19 pp | PÃ©nalitÃ© |\n",
    "\n",
    "La relation avec le diplÃ´me est non monotone. Les diplÃ´mes professionnalisants (Bac+5, grandes Ã©coles) sont associÃ©s Ã  des probabilitÃ©s Ã©levÃ©es, reflÃ©tant la demande de main-d'Å“uvre qualifiÃ©e au Luxembourg et en Suisse. Le doctorat, orientÃ© vers la recherche publique, prÃ©sente un effet nÃ©gatif.\n",
    "\n",
    "#### Logement et motorisation (variables potentiellement endogÃ¨nes)\n",
    "\n",
    "| Variable | AME | InterprÃ©tation |\n",
    "|----------|-----|----------------|\n",
    "| Locataire HLM (STOCD_22) | -6.21 pp | Forte pÃ©nalitÃ© |\n",
    "| LogÃ© gratuit (STOCD_30) | -3.57 pp | PÃ©nalitÃ© |\n",
    "| 0 voiture (VOIT_0) | -4.06 pp | Contrainte de mobilitÃ© |\n",
    "| 2 voitures (VOIT_2) | +1.48 pp | Association positive |\n",
    "| 3+ voitures (VOIT_3) | +2.09 pp | Association positive |\n",
    "\n",
    "Ces associations sont significatives mais le sens de la causalitÃ© reste indÃ©terminÃ© : la motorisation et le statut d'occupation peuvent Ãªtre des consÃ©quences autant que des causes du travail transfrontalier.\n",
    "\n",
    "---\n",
    "\n",
    "### Pourquoi l'infÃ©rence reste provisoire\n",
    "\n",
    "Ces rÃ©gularitÃ©s statistiques ne permettent pas encore de conclusions causales dÃ©finitives. Plusieurs questions mÃ©thodologiques doivent Ãªtre tranchÃ©es par des tests de robustesse :\n",
    "\n",
    "- **SpÃ©cification fonctionnelle** : la forme quadratique de l'Ã¢ge est-elle optimale ?\n",
    "- **QualitÃ© de l'ajustement** : les tests classiques (Hosmer-Lemeshow, Link Test) valident-ils le modÃ¨le ?\n",
    "- **Ã‰quivalence Probit/Logit** : les conclusions sont-elles robustes au choix du modÃ¨le ?\n",
    "- **SensibilitÃ© Ã  l'endogÃ©nÃ©itÃ©** : les coefficients clÃ©s sont-ils stables aprÃ¨s exclusion des variables potentiellement endogÃ¨nes ?\n",
    "- **HÃ©tÃ©rogÃ©nÃ©itÃ©** : la structure est-elle homogÃ¨ne par sexe, Ã¢ge, dÃ©partement ?\n",
    "- **Observations atypiques** : existe-t-il des rÃ©sidus extrÃªmes influenÃ§ant les rÃ©sultats ?\n",
    "\n",
    "L'interprÃ©tation Ã©conomique dÃ©taillÃ©e et les conclusions causales seront prÃ©sentÃ©es aprÃ¨s validation de ces diagnostics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2122eac4",
   "metadata": {},
   "source": [
    "# Tests de Robustesse â€“ ModÃ¨le Probit Transfrontalier\n",
    "\n",
    "## Tests rÃ©alisÃ©s\n",
    "\n",
    "| #   | Test                             | Objectif                                    | CritÃ¨re de validation                 |\n",
    "|-----|----------------------------------|---------------------------------------------|---------------------------------------|\n",
    "| 1   | Probit de base                   | VÃ©rifier convergence et qualitÃ© globale     | Convergence, Pseudo RÂ², LR test p<0.05|\n",
    "| 2   | Link Test (Pregibon)             | DÃ©tecter erreur de spÃ©cification            | p(_hatsq) > 0.05                      |\n",
    "| 3   | Hosmer-Lemeshow                  | Tester l'ajustement du modÃ¨le               | p > 0.05                              |\n",
    "| 4   | Probit vs Logit                  | VÃ©rifier robustesse au choix du lien        | Corr. effets marginaux > 0.99         |\n",
    "| 5   | Exclusion variables endogÃ¨nes    | SensibilitÃ© Ã  VOIT, STOCD, TYPL, SANI       | Variation coefficients clÃ©s < 20%     |\n",
    "| 6   | Sous-Ã©chantillons                | StabilitÃ© selon groupes                     | CohÃ©rence des Pseudo RÂ²               |\n",
    "| 7   | SensibilitÃ©                      | Influence des observations extrÃªmes         | StabilitÃ© aprÃ¨s exclusion             |\n",
    "| 8   | Forme fonctionnelle Ã¢ge          | Valider la spÃ©cification quadratique        | Test LR quad vs lin, AIC/BIC          |\n",
    "\n",
    "## Sous-Ã©chantillons analysÃ©s (Test 6)\n",
    "\n",
    "| Dimension   | Groupes comparÃ©s                      |\n",
    "|-------------|---------------------------------------|\n",
    "| GÃ©ographie  | DÃ©partements frontaliers vs intÃ©rieurs|\n",
    "| Genre       | Hommes vs Femmes                      |\n",
    "| Ã‚ge         | < 35 ans vs â‰¥ 35 ans                  |\n",
    "\n",
    "## Output\n",
    "\n",
    "â†’ `rapport_robustesse.txt` dans `/Probit_Ready/Robustesse/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f989c1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TESTS DE ROBUSTESSE - PROBIT TRANSFRONTALIER\n",
      "================================================================================\n",
      "================================================================================\n",
      "CHARGEMENT DES DONNÃ‰ES\n",
      "================================================================================\n",
      "\n",
      "âœ“ X chargÃ© : 494,483 obs Ã— 65 variables\n",
      "âœ“ Y chargÃ© : 494,483 observations\n",
      "  â†’ Colonne utilisÃ©e : 'TRANSFRONTALIER'\n",
      "\n",
      "âœ“ Variable dÃ©pendante :\n",
      "  â†’ Transfrontaliers (Y=1) : 44,264 (8.95%)\n",
      "  â†’ Non-transfrontaliers   : 450,219 (91.05%)\n",
      "\n",
      "âœ“ Constante ajoutÃ©e : 66 variables (dont intercept)\n",
      "\n",
      "================================================================================\n",
      "TEST 1 : MODÃˆLE PROBIT DE BASE\n",
      "================================================================================\n",
      "\n",
      "âœ“ Convergence : Oui\n",
      "âœ“ ItÃ©rations  : 10\n",
      "âœ“ Log-L       : -113,380.76\n",
      "âœ“ Pseudo RÂ²   : 0.2393\n",
      "âœ“ AIC         : 226,893.52\n",
      "âœ“ BIC         : 227,626.87\n",
      "âœ“ LR test p   : 0.00e+00\n",
      "\n",
      "--- Coefficients clÃ©s ---\n",
      "  DEPT_57      :   2.4367 (SE=0.0481) ***\n",
      "  DEPT_68      :   2.0908 (SE=0.0483) ***\n",
      "  DEPT_54      :   1.9401 (SE=0.0484) ***\n",
      "  DEPT_67      :   1.4722 (SE=0.0484) ***\n",
      "  SEXE_2       :  -0.1255 (SE=0.0069) ***\n",
      "  AGEREV       :   0.0326 (SE=0.0019) ***\n",
      "  AGEREV_sq    :  -0.0004 (SE=0.0000) ***\n",
      "\n",
      "================================================================================\n",
      "TEST 2 : LINK TEST (PREGIBON)\n",
      "================================================================================\n",
      "\n",
      "_hat   coef : 1.1247 (p=0.0000)\n",
      "_hatsq coef : 0.0509 (p=0.0000)\n",
      "\n",
      "âš ï¸ H0 rejetÃ©e : Possible erreur de spÃ©cification\n",
      "\n",
      "================================================================================\n",
      "TEST 3 : HOSMER-LEMESHOW\n",
      "================================================================================\n",
      "\n",
      "Statistique HL : 304.51\n",
      "DegrÃ©s libertÃ© : 8\n",
      "P-value        : 0.0000\n",
      "\n",
      "âš ï¸ Ajustement insuffisant (p < 0.05)\n",
      "\n",
      "================================================================================\n",
      "TEST 4 : PROBIT VS LOGIT\n",
      "================================================================================\n",
      "\n",
      "CritÃ¨re               Probit        Logit\n",
      "---------------------------------------------\n",
      "Log-L            -113,380.76  -113,285.43\n",
      "Pseudo RÂ²             0.2393       0.2399\n",
      "AIC               226,893.52   226,702.86\n",
      "BIC               227,626.87   227,436.20\n",
      "\n",
      "Ratio moyen Logit/Probit : 2.045 (thÃ©orique ~1.6)\n",
      "CorrÃ©lation effets marginaux : 0.9953\n",
      "\n",
      "âœ… Probit et Logit quasi-Ã©quivalents\n",
      "\n",
      "================================================================================\n",
      "TEST 5 : ROBUSTESSE ENDOGÃ‰NÃ‰ITÃ‰\n",
      "================================================================================\n",
      "\n",
      "Variables exclues : 15\n",
      "  - VOIT_0.0\n",
      "  - VOIT_2.0\n",
      "  - VOIT_3.0\n",
      "  - STOCD_21.0\n",
      "  - STOCD_22.0\n",
      "  - STOCD_23.0\n",
      "  - STOCD_30.0\n",
      "  - TYPL_2.0\n",
      "  - TYPL_3.0\n",
      "  - TYPL_4.0\n",
      "  ... et 5 autres\n",
      "\n",
      "ModÃ¨le              Log-L    Pseudo RÂ²    Nb vars\n",
      "--------------------------------------------------\n",
      "Complet       -113,380.76       0.2393         66\n",
      "RÃ©duit        -116,152.93       0.2207         51\n",
      "\n",
      "--- StabilitÃ© des coefficients clÃ©s ---\n",
      "  DEPT_57      :   2.4367 â†’   2.4550 (+0.8%) âœ“\n",
      "  DEPT_68      :   2.0908 â†’   2.1199 (+1.4%) âœ“\n",
      "  SEXE_2       :  -0.1255 â†’  -0.1200 (+4.4%) âœ“\n",
      "  AGEREV       :   0.0326 â†’   0.0322 (-1.4%) âœ“\n",
      "\n",
      "âœ… Coefficients stables aprÃ¨s exclusion\n",
      "\n",
      "================================================================================\n",
      "TEST 6 : SOUS-Ã‰CHANTILLONS\n",
      "================================================================================\n",
      "\n",
      "--- DÃ©partements frontaliers vs intÃ©rieurs ---\n",
      "  Frontaliers  : Estimation Ã©chouÃ©e\n",
      "  IntÃ©rieurs   : Estimation Ã©chouÃ©e\n",
      "\n",
      "--- Par sexe ---\n",
      "  Hommes       : n=256,784, Y=1: 10.5%, Pseudo RÂ²=0.2328\n",
      "  Femmes       : n=237,699, Y=1: 7.2%, Pseudo RÂ²=0.2481\n",
      "\n",
      "--- Par tranche d'Ã¢ge ---\n",
      "  <35 ans      : n=161,509, Y=1: 8.0%, Pseudo RÂ²=0.2485\n",
      "  â‰¥35 ans      : n=332,974, Y=1: 9.4%, Pseudo RÂ²=0.2397\n",
      "\n",
      "================================================================================\n",
      "TEST 7 : SENSIBILITÃ‰\n",
      "================================================================================\n",
      "\n",
      "--- Exclusion rÃ©sidus extrÃªmes ---\n",
      "  Observations exclues (|rÃ©sidu| > 3Ïƒ) : 21432 (4.33%)\n",
      "  Pseudo RÂ² (sans extrÃªmes) : 0.4825\n",
      "\n",
      "--- Jackknife par dÃ©partement ---\n",
      "\n",
      "================================================================================\n",
      "TEST 8 : FORME FONCTIONNELLE Ã‚GE\n",
      "================================================================================\n",
      "\n",
      "Forme                  Log-L          AIC          BIC\n",
      "-------------------------------------------------------\n",
      "LinÃ©aire         -113,537.00   227,204.00   227,926.23\n",
      "Quadratique      -113,380.76   226,893.52   227,626.87\n",
      "Cubique          -113,358.94   226,851.88   227,596.34\n",
      "Spline           -113,358.47   226,852.95   227,608.51\n",
      "\n",
      "âœ“ Meilleure forme (BIC) : Cubique\n",
      "\n",
      "Test LR (Quad vs Lin) : Ï‡Â²=312.48, p=0.0000\n",
      "âœ“ Effet quadratique significatif\n",
      "\n",
      "âœ“ Rapport sauvegardÃ© : /Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready/Robustesse/rapport_robustesse.txt\n",
      "\n",
      "================================================================================\n",
      "TESTS DE ROBUSTESSE TERMINÃ‰S\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "TESTS DE ROBUSTESSE - MODÃˆLE PROBIT TRANSFRONTALIER\n",
    "================================================================================\n",
    "Version adaptÃ©e pour BDD_PROBIT.csv (base dÃ©jÃ  prÃ©parÃ©e)\n",
    "\n",
    "Utilise directement :\n",
    "- X : BDD_PROBIT.csv (variables explicatives, catÃ©gories de rÃ©fÃ©rence dÃ©jÃ  supprimÃ©es)\n",
    "- Y : y_final.csv (variable dÃ©pendante)\n",
    "\n",
    "CatÃ©gories de rÃ©fÃ©rence (rappel) :\n",
    "- DEPT_51 (Marne), SEXE_1 (Homme), GS_5 (EmployÃ©s), EMPL_16 (CDI)\n",
    "- NENFR_0 (0 enfant), NA5_GU (Commerce/Services), DIPL_13 (CAP/BEP)\n",
    "- COUPLE_1 (En couple), TP_1 (Temps complet), etc.\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION - CHEMINS DES FICHIERS\n",
    "# ============================================================================\n",
    "# Adapter ces chemins si nÃ©cessaire\n",
    "X_PATH = \"/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready/BDD_PROBIT.csv\"\n",
    "Y_PATH = \"/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready/y_final.csv\"\n",
    "OUTPUT_DIR = \"/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready/Robustesse\"\n",
    "\n",
    "\n",
    "def load_data(x_path, y_path):\n",
    "    \"\"\"\n",
    "    Charge les donnÃ©es X et Y dÃ©jÃ  prÃ©parÃ©es.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"CHARGEMENT DES DONNÃ‰ES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Charger X\n",
    "    X = pd.read_csv(x_path)\n",
    "    print(f\"\\nâœ“ X chargÃ© : {X.shape[0]:,} obs Ã— {X.shape[1]} variables\")\n",
    "    \n",
    "    # Charger Y\n",
    "    Y_df = pd.read_csv(y_path)\n",
    "    print(f\"âœ“ Y chargÃ© : {Y_df.shape[0]:,} observations\")\n",
    "    \n",
    "    # Identifier la colonne Y (peut Ãªtre 'Y', 'y', 'ILT_7', 'TRANSFRONTALIER', etc.)\n",
    "    y_col = Y_df.columns[0]  # Prendre la premiÃ¨re colonne\n",
    "    Y = Y_df[y_col].values\n",
    "    print(f\"  â†’ Colonne utilisÃ©e : '{y_col}'\")\n",
    "    \n",
    "    # Statistiques Y\n",
    "    n_transfront = Y.sum()\n",
    "    pct_transfront = 100 * n_transfront / len(Y)\n",
    "    print(f\"\\nâœ“ Variable dÃ©pendante :\")\n",
    "    print(f\"  â†’ Transfrontaliers (Y=1) : {n_transfront:,} ({pct_transfront:.2f}%)\")\n",
    "    print(f\"  â†’ Non-transfrontaliers   : {len(Y) - n_transfront:,} ({100-pct_transfront:.2f}%)\")\n",
    "    \n",
    "    # VÃ©rifier cohÃ©rence\n",
    "    if len(X) != len(Y):\n",
    "        raise ValueError(f\"IncohÃ©rence : X a {len(X)} obs, Y a {len(Y)} obs\")\n",
    "    \n",
    "    # Ajouter constante\n",
    "    X_with_const = sm.add_constant(X, has_constant='add')\n",
    "    print(f\"\\nâœ“ Constante ajoutÃ©e : {X_with_const.shape[1]} variables (dont intercept)\")\n",
    "    \n",
    "    return X, X_with_const, Y\n",
    "\n",
    "\n",
    "def test_1_baseline_probit(X, Y, report_lines):\n",
    "    \"\"\"\n",
    "    Test 1 : Estimation du modÃ¨le probit de base\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 1 : MODÃˆLE PROBIT DE BASE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 1 : MODÃˆLE PROBIT DE BASE\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        model = sm.Probit(Y, X)\n",
    "        result = model.fit(disp=0, maxiter=100)\n",
    "        \n",
    "        print(f\"\\nâœ“ Convergence : {'Oui' if result.mle_retvals['converged'] else 'Non'}\")\n",
    "        print(f\"âœ“ ItÃ©rations  : {result.mle_retvals.get('iterations', 'N/A')}\")\n",
    "        print(f\"âœ“ Log-L       : {result.llf:,.2f}\")\n",
    "        print(f\"âœ“ Pseudo RÂ²   : {result.prsquared:.4f}\")\n",
    "        print(f\"âœ“ AIC         : {result.aic:,.2f}\")\n",
    "        print(f\"âœ“ BIC         : {result.bic:,.2f}\")\n",
    "        \n",
    "        # Test LR global\n",
    "        llr_pvalue = result.llr_pvalue\n",
    "        print(f\"âœ“ LR test p   : {llr_pvalue:.2e}\")\n",
    "        \n",
    "        report_lines.append(f\"\\nConvergence : {'Oui' if result.mle_retvals['converged'] else 'Non'}\")\n",
    "        report_lines.append(f\"ItÃ©rations  : {result.mle_retvals.get('iterations', 'N/A')}\")\n",
    "        report_lines.append(f\"Log-L       : {result.llf:,.2f}\")\n",
    "        report_lines.append(f\"Pseudo RÂ²   : {result.prsquared:.4f}\")\n",
    "        report_lines.append(f\"AIC         : {result.aic:,.2f}\")\n",
    "        report_lines.append(f\"BIC         : {result.bic:,.2f}\")\n",
    "        report_lines.append(f\"LR test p   : {llr_pvalue:.2e}\")\n",
    "        \n",
    "        # Coefficients clÃ©s\n",
    "        print(\"\\n--- Coefficients clÃ©s ---\")\n",
    "        report_lines.append(\"\\n--- Coefficients clÃ©s ---\")\n",
    "        \n",
    "        key_vars = ['DEPT_57', 'DEPT_68', 'DEPT_54', 'DEPT_67', 'SEXE_2', 'AGEREV', 'AGEREV_sq']\n",
    "        for var in key_vars:\n",
    "            if var in result.params.index:\n",
    "                coef = result.params[var]\n",
    "                se = result.bse[var]\n",
    "                pval = result.pvalues[var]\n",
    "                signif = '***' if pval < 0.001 else '**' if pval < 0.01 else '*' if pval < 0.05 else ''\n",
    "                print(f\"  {var:<12} : {coef:>8.4f} (SE={se:.4f}) {signif}\")\n",
    "                report_lines.append(f\"  {var:<12} : {coef:>8.4f} (SE={se:.4f}) {signif}\")\n",
    "        \n",
    "        report_lines.append(\"\\nâœ… TEST 1 RÃ‰USSI\")\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Erreur : {e}\")\n",
    "        report_lines.append(f\"\\nâŒ ERREUR : {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def test_2_link_test(X, Y, baseline_result, report_lines):\n",
    "    \"\"\"\n",
    "    Test 2 : Link Test de Pregibon\n",
    "    H0 : SpÃ©cification correcte (coefficient de _hatsq non significatif)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 2 : LINK TEST (PREGIBON)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 2 : LINK TEST (PREGIBON)\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        # PrÃ©dictions linÃ©aires\n",
    "        y_hat = baseline_result.predict()\n",
    "        xb = stats.norm.ppf(np.clip(y_hat, 1e-10, 1-1e-10))  # Inverse de Phi\n",
    "        xb_sq = xb ** 2\n",
    "        \n",
    "        # RÃ©gression auxiliaire\n",
    "        X_link = pd.DataFrame({\n",
    "            'const': 1,\n",
    "            '_hat': xb,\n",
    "            '_hatsq': xb_sq\n",
    "        })\n",
    "        \n",
    "        model_link = sm.Probit(Y, X_link)\n",
    "        result_link = model_link.fit(disp=0)\n",
    "        \n",
    "        coef_hatsq = result_link.params['_hatsq']\n",
    "        pval_hatsq = result_link.pvalues['_hatsq']\n",
    "        \n",
    "        print(f\"\\n_hat   coef : {result_link.params['_hat']:.4f} (p={result_link.pvalues['_hat']:.4f})\")\n",
    "        print(f\"_hatsq coef : {coef_hatsq:.4f} (p={pval_hatsq:.4f})\")\n",
    "        \n",
    "        report_lines.append(f\"\\n_hat   coef : {result_link.params['_hat']:.4f} (p={result_link.pvalues['_hat']:.4f})\")\n",
    "        report_lines.append(f\"_hatsq coef : {coef_hatsq:.4f} (p={pval_hatsq:.4f})\")\n",
    "        \n",
    "        if pval_hatsq > 0.05:\n",
    "            print(\"\\nâœ… H0 non rejetÃ©e : SpÃ©cification correcte\")\n",
    "            report_lines.append(\"\\nâœ… RÃ‰USSI : SpÃ©cification correcte (p > 0.05)\")\n",
    "        else:\n",
    "            print(\"\\nâš ï¸ H0 rejetÃ©e : Possible erreur de spÃ©cification\")\n",
    "            report_lines.append(\"\\nâš ï¸ ATTENTION : Possible erreur de spÃ©cification (p < 0.05)\")\n",
    "            \n",
    "        return pval_hatsq\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Erreur : {e}\")\n",
    "        report_lines.append(f\"\\nâŒ ERREUR : {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def test_3_hosmer_lemeshow(Y, baseline_result, report_lines, n_groups=10):\n",
    "    \"\"\"\n",
    "    Test 3 : Hosmer-Lemeshow Goodness of Fit\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 3 : HOSMER-LEMESHOW\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 3 : HOSMER-LEMESHOW\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        y_pred = baseline_result.predict()\n",
    "        \n",
    "        # CrÃ©er dÃ©ciles\n",
    "        df_hl = pd.DataFrame({'y': Y, 'pred': y_pred})\n",
    "        df_hl['decile'] = pd.qcut(df_hl['pred'], n_groups, labels=False, duplicates='drop')\n",
    "        \n",
    "        # Calculer observÃ© vs attendu par groupe\n",
    "        grouped = df_hl.groupby('decile').agg({\n",
    "            'y': ['sum', 'count'],\n",
    "            'pred': 'sum'\n",
    "        })\n",
    "        grouped.columns = ['obs_1', 'n', 'exp_1']\n",
    "        grouped['obs_0'] = grouped['n'] - grouped['obs_1']\n",
    "        grouped['exp_0'] = grouped['n'] - grouped['exp_1']\n",
    "        \n",
    "        # Statistique HL\n",
    "        hl_stat = 0\n",
    "        for _, row in grouped.iterrows():\n",
    "            if row['exp_1'] > 0:\n",
    "                hl_stat += (row['obs_1'] - row['exp_1'])**2 / row['exp_1']\n",
    "            if row['exp_0'] > 0:\n",
    "                hl_stat += (row['obs_0'] - row['exp_0'])**2 / row['exp_0']\n",
    "        \n",
    "        df_hl_test = len(grouped) - 2\n",
    "        p_value = 1 - chi2.cdf(hl_stat, df_hl_test)\n",
    "        \n",
    "        print(f\"\\nStatistique HL : {hl_stat:.2f}\")\n",
    "        print(f\"DegrÃ©s libertÃ© : {df_hl_test}\")\n",
    "        print(f\"P-value        : {p_value:.4f}\")\n",
    "        \n",
    "        report_lines.append(f\"\\nStatistique HL : {hl_stat:.2f}\")\n",
    "        report_lines.append(f\"DegrÃ©s libertÃ© : {df_hl_test}\")\n",
    "        report_lines.append(f\"P-value        : {p_value:.4f}\")\n",
    "        \n",
    "        if p_value > 0.05:\n",
    "            print(\"\\nâœ… Bon ajustement (p > 0.05)\")\n",
    "            report_lines.append(\"\\nâœ… RÃ‰USSI : Bon ajustement\")\n",
    "        else:\n",
    "            print(\"\\nâš ï¸ Ajustement insuffisant (p < 0.05)\")\n",
    "            report_lines.append(\"\\nâš ï¸ ATTENTION : Ajustement insuffisant\")\n",
    "            \n",
    "        return hl_stat, p_value\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Erreur : {e}\")\n",
    "        report_lines.append(f\"\\nâŒ ERREUR : {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def test_4_probit_vs_logit(X, Y, report_lines):\n",
    "    \"\"\"\n",
    "    Test 4 : Comparaison Probit vs Logit\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 4 : PROBIT VS LOGIT\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 4 : PROBIT VS LOGIT\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        # Probit\n",
    "        model_probit = sm.Probit(Y, X)\n",
    "        result_probit = model_probit.fit(disp=0)\n",
    "        \n",
    "        # Logit\n",
    "        model_logit = sm.Logit(Y, X)\n",
    "        result_logit = model_logit.fit(disp=0)\n",
    "        \n",
    "        print(f\"\\n{'CritÃ¨re':<15} {'Probit':>12} {'Logit':>12}\")\n",
    "        print(\"-\" * 45)\n",
    "        print(f\"{'Log-L':<15} {result_probit.llf:>12,.2f} {result_logit.llf:>12,.2f}\")\n",
    "        print(f\"{'Pseudo RÂ²':<15} {result_probit.prsquared:>12.4f} {result_logit.prsquared:>12.4f}\")\n",
    "        print(f\"{'AIC':<15} {result_probit.aic:>12,.2f} {result_logit.aic:>12,.2f}\")\n",
    "        print(f\"{'BIC':<15} {result_probit.bic:>12,.2f} {result_logit.bic:>12,.2f}\")\n",
    "        \n",
    "        report_lines.append(f\"\\n{'CritÃ¨re':<15} {'Probit':>12} {'Logit':>12}\")\n",
    "        report_lines.append(\"-\" * 45)\n",
    "        report_lines.append(f\"{'Log-L':<15} {result_probit.llf:>12,.2f} {result_logit.llf:>12,.2f}\")\n",
    "        report_lines.append(f\"{'Pseudo RÂ²':<15} {result_probit.prsquared:>12.4f} {result_logit.prsquared:>12.4f}\")\n",
    "        report_lines.append(f\"{'AIC':<15} {result_probit.aic:>12,.2f} {result_logit.aic:>12,.2f}\")\n",
    "        report_lines.append(f\"{'BIC':<15} {result_probit.bic:>12,.2f} {result_logit.bic:>12,.2f}\")\n",
    "        \n",
    "        # Ratio des coefficients (thÃ©oriquement ~1.6)\n",
    "        common_vars = [v for v in result_probit.params.index if v in result_logit.params.index and v != 'const']\n",
    "        if common_vars:\n",
    "            ratios = result_logit.params[common_vars] / result_probit.params[common_vars]\n",
    "            mean_ratio = ratios.mean()\n",
    "            print(f\"\\nRatio moyen Logit/Probit : {mean_ratio:.3f} (thÃ©orique ~1.6)\")\n",
    "            report_lines.append(f\"\\nRatio moyen Logit/Probit : {mean_ratio:.3f} (thÃ©orique ~1.6)\")\n",
    "        \n",
    "        # CorrÃ©lation des effets marginaux\n",
    "        mfx_probit = result_probit.get_margeff(at='mean').margeff\n",
    "        mfx_logit = result_logit.get_margeff(at='mean').margeff\n",
    "        corr_mfx = np.corrcoef(mfx_probit, mfx_logit)[0, 1]\n",
    "        \n",
    "        print(f\"CorrÃ©lation effets marginaux : {corr_mfx:.4f}\")\n",
    "        report_lines.append(f\"CorrÃ©lation effets marginaux : {corr_mfx:.4f}\")\n",
    "        \n",
    "        if corr_mfx > 0.99:\n",
    "            print(\"\\nâœ… Probit et Logit quasi-Ã©quivalents\")\n",
    "            report_lines.append(\"\\nâœ… RÃ‰USSI : Probit et Logit quasi-Ã©quivalents\")\n",
    "        else:\n",
    "            print(\"\\nâš ï¸ DiffÃ©rence notable entre Probit et Logit\")\n",
    "            report_lines.append(\"\\nâš ï¸ ATTENTION : DiffÃ©rence notable\")\n",
    "            \n",
    "        return result_probit, result_logit, corr_mfx\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Erreur : {e}\")\n",
    "        report_lines.append(f\"\\nâŒ ERREUR : {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def test_5_endogeneity_robustness(X, Y, baseline_result, report_lines):\n",
    "    \"\"\"\n",
    "    Test 5 : Robustesse Ã  l'exclusion des variables potentiellement endogÃ¨nes\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 5 : ROBUSTESSE ENDOGÃ‰NÃ‰ITÃ‰\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 5 : ROBUSTESSE ENDOGÃ‰NÃ‰ITÃ‰\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    # Variables potentiellement endogÃ¨nes Ã  exclure\n",
    "    vars_endogenes = ['VOIT', 'STOCD', 'TYPL', 'SANI']\n",
    "    \n",
    "    try:\n",
    "        # Identifier les colonnes Ã  exclure\n",
    "        cols_to_drop = []\n",
    "        for var in vars_endogenes:\n",
    "            cols_to_drop.extend([c for c in X.columns if c.startswith(f'{var}_') or c == var])\n",
    "        \n",
    "        cols_to_drop = [c for c in cols_to_drop if c in X.columns]\n",
    "        \n",
    "        if not cols_to_drop:\n",
    "            print(\"\\nâš ï¸ Aucune variable endogÃ¨ne trouvÃ©e dans X\")\n",
    "            report_lines.append(\"\\nâš ï¸ Aucune variable endogÃ¨ne trouvÃ©e\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\nVariables exclues : {len(cols_to_drop)}\")\n",
    "        for c in cols_to_drop[:10]:\n",
    "            print(f\"  - {c}\")\n",
    "        if len(cols_to_drop) > 10:\n",
    "            print(f\"  ... et {len(cols_to_drop)-10} autres\")\n",
    "        \n",
    "        # ModÃ¨le rÃ©duit\n",
    "        X_reduced = X.drop(columns=cols_to_drop)\n",
    "        X_reduced_const = sm.add_constant(X_reduced)\n",
    "        \n",
    "        model_reduced = sm.Probit(Y, X_reduced_const)\n",
    "        result_reduced = model_reduced.fit(disp=0)\n",
    "        \n",
    "        print(f\"\\n{'ModÃ¨le':<12} {'Log-L':>12} {'Pseudo RÂ²':>12} {'Nb vars':>10}\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"{'Complet':<12} {baseline_result.llf:>12,.2f} {baseline_result.prsquared:>12.4f} {len(baseline_result.params):>10}\")\n",
    "        print(f\"{'RÃ©duit':<12} {result_reduced.llf:>12,.2f} {result_reduced.prsquared:>12.4f} {len(result_reduced.params):>10}\")\n",
    "        \n",
    "        report_lines.append(f\"\\nVariables exclues : {cols_to_drop}\")\n",
    "        report_lines.append(f\"\\n{'ModÃ¨le':<12} {'Log-L':>12} {'Pseudo RÂ²':>12}\")\n",
    "        report_lines.append(\"-\" * 50)\n",
    "        report_lines.append(f\"{'Complet':<12} {baseline_result.llf:>12,.2f} {baseline_result.prsquared:>12.4f}\")\n",
    "        report_lines.append(f\"{'RÃ©duit':<12} {result_reduced.llf:>12,.2f} {result_reduced.prsquared:>12.4f}\")\n",
    "        \n",
    "        # StabilitÃ© des coefficients clÃ©s\n",
    "        print(\"\\n--- StabilitÃ© des coefficients clÃ©s ---\")\n",
    "        report_lines.append(\"\\n--- StabilitÃ© des coefficients clÃ©s ---\")\n",
    "        \n",
    "        key_vars = ['DEPT_57', 'DEPT_68', 'SEXE_2', 'AGEREV']\n",
    "        stable = True\n",
    "        \n",
    "        for var in key_vars:\n",
    "            if var in baseline_result.params.index and var in result_reduced.params.index:\n",
    "                coef_full = baseline_result.params[var]\n",
    "                coef_red = result_reduced.params[var]\n",
    "                pct_change = 100 * (coef_red - coef_full) / abs(coef_full) if coef_full != 0 else 0\n",
    "                \n",
    "                status = \"âœ“\" if abs(pct_change) < 20 else \"âš ï¸\"\n",
    "                if abs(pct_change) >= 20:\n",
    "                    stable = False\n",
    "                    \n",
    "                print(f\"  {var:<12} : {coef_full:>8.4f} â†’ {coef_red:>8.4f} ({pct_change:+.1f}%) {status}\")\n",
    "                report_lines.append(f\"  {var:<12} : {coef_full:>8.4f} â†’ {coef_red:>8.4f} ({pct_change:+.1f}%) {status}\")\n",
    "        \n",
    "        if stable:\n",
    "            print(\"\\nâœ… Coefficients stables aprÃ¨s exclusion\")\n",
    "            report_lines.append(\"\\nâœ… RÃ‰USSI : Coefficients stables\")\n",
    "        else:\n",
    "            print(\"\\nâš ï¸ Certains coefficients varient de plus de 20%\")\n",
    "            report_lines.append(\"\\nâš ï¸ ATTENTION : Coefficients instables\")\n",
    "            \n",
    "        return result_reduced\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Erreur : {e}\")\n",
    "        report_lines.append(f\"\\nâŒ ERREUR : {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def test_6_subsamples(X, Y, report_lines):\n",
    "    \"\"\"\n",
    "    Test 6 : Analyse par sous-Ã©chantillons\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 6 : SOUS-Ã‰CHANTILLONS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 6 : SOUS-Ã‰CHANTILLONS\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    results_subsamples = {}\n",
    "    \n",
    "    # 1. Par dÃ©partement (frontalier vs intÃ©rieur)\n",
    "    print(\"\\n--- DÃ©partements frontaliers vs intÃ©rieurs ---\")\n",
    "    report_lines.append(\"\\n--- DÃ©partements frontaliers vs intÃ©rieurs ---\")\n",
    "    \n",
    "    # Identifier les dÃ©partements frontaliers\n",
    "    dept_front_cols = ['DEPT_57', 'DEPT_68', 'DEPT_54', 'DEPT_67', 'DEPT_55', 'DEPT_88', 'DEPT_90']\n",
    "    dept_front_cols = [c for c in dept_front_cols if c in X.columns]\n",
    "    \n",
    "    if dept_front_cols:\n",
    "        mask_front = X[dept_front_cols].sum(axis=1) > 0\n",
    "        \n",
    "        for name, mask in [('Frontaliers', mask_front), ('IntÃ©rieurs', ~mask_front)]:\n",
    "            X_sub = X.loc[mask]\n",
    "            Y_sub = Y[mask.values]\n",
    "            \n",
    "            if len(Y_sub) > 100 and Y_sub.sum() > 10:\n",
    "                X_sub_const = sm.add_constant(X_sub)\n",
    "                try:\n",
    "                    model = sm.Probit(Y_sub, X_sub_const)\n",
    "                    result = model.fit(disp=0, maxiter=50)\n",
    "                    prevalence = 100 * Y_sub.mean()\n",
    "                    print(f\"  {name:<12} : n={len(Y_sub):,}, Y=1: {prevalence:.1f}%, Pseudo RÂ²={result.prsquared:.4f}\")\n",
    "                    report_lines.append(f\"  {name:<12} : n={len(Y_sub):,}, Y=1: {prevalence:.1f}%, Pseudo RÂ²={result.prsquared:.4f}\")\n",
    "                    results_subsamples[name] = result\n",
    "                except:\n",
    "                    print(f\"  {name:<12} : Estimation Ã©chouÃ©e\")\n",
    "    \n",
    "    # 2. Par sexe\n",
    "    print(\"\\n--- Par sexe ---\")\n",
    "    report_lines.append(\"\\n--- Par sexe ---\")\n",
    "    \n",
    "    if 'SEXE_2' in X.columns:\n",
    "        for name, val in [('Hommes', 0), ('Femmes', 1)]:\n",
    "            mask = X['SEXE_2'] == val\n",
    "            X_sub = X.loc[mask].drop(columns=['SEXE_2'])\n",
    "            Y_sub = Y[mask.values]\n",
    "            \n",
    "            if len(Y_sub) > 100 and Y_sub.sum() > 10:\n",
    "                X_sub_const = sm.add_constant(X_sub)\n",
    "                try:\n",
    "                    model = sm.Probit(Y_sub, X_sub_const)\n",
    "                    result = model.fit(disp=0, maxiter=50)\n",
    "                    prevalence = 100 * Y_sub.mean()\n",
    "                    print(f\"  {name:<12} : n={len(Y_sub):,}, Y=1: {prevalence:.1f}%, Pseudo RÂ²={result.prsquared:.4f}\")\n",
    "                    report_lines.append(f\"  {name:<12} : n={len(Y_sub):,}, Y=1: {prevalence:.1f}%, Pseudo RÂ²={result.prsquared:.4f}\")\n",
    "                    results_subsamples[name] = result\n",
    "                except:\n",
    "                    print(f\"  {name:<12} : Estimation Ã©chouÃ©e\")\n",
    "    \n",
    "    # 3. Par Ã¢ge\n",
    "    print(\"\\n--- Par tranche d'Ã¢ge ---\")\n",
    "    report_lines.append(\"\\n--- Par tranche d'Ã¢ge ---\")\n",
    "    \n",
    "    if 'AGEREV' in X.columns:\n",
    "        for name, condition in [('<35 ans', X['AGEREV'] < 35), ('â‰¥35 ans', X['AGEREV'] >= 35)]:\n",
    "            mask = condition\n",
    "            X_sub = X.loc[mask]\n",
    "            Y_sub = Y[mask.values]\n",
    "            \n",
    "            if len(Y_sub) > 100 and Y_sub.sum() > 10:\n",
    "                X_sub_const = sm.add_constant(X_sub)\n",
    "                try:\n",
    "                    model = sm.Probit(Y_sub, X_sub_const)\n",
    "                    result = model.fit(disp=0, maxiter=50)\n",
    "                    prevalence = 100 * Y_sub.mean()\n",
    "                    print(f\"  {name:<12} : n={len(Y_sub):,}, Y=1: {prevalence:.1f}%, Pseudo RÂ²={result.prsquared:.4f}\")\n",
    "                    report_lines.append(f\"  {name:<12} : n={len(Y_sub):,}, Y=1: {prevalence:.1f}%, Pseudo RÂ²={result.prsquared:.4f}\")\n",
    "                    results_subsamples[name] = result\n",
    "                except:\n",
    "                    print(f\"  {name:<12} : Estimation Ã©chouÃ©e\")\n",
    "    \n",
    "    report_lines.append(\"\\nâœ… Analyse par sous-Ã©chantillons terminÃ©e\")\n",
    "    return results_subsamples\n",
    "\n",
    "\n",
    "def test_7_sensitivity(X, Y, baseline_result, report_lines):\n",
    "    \"\"\"\n",
    "    Test 7 : Analyse de sensibilitÃ©\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 7 : SENSIBILITÃ‰\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 7 : SENSIBILITÃ‰\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    # 1. Exclusion des rÃ©sidus extrÃªmes\n",
    "    print(\"\\n--- Exclusion rÃ©sidus extrÃªmes ---\")\n",
    "    report_lines.append(\"\\n--- Exclusion rÃ©sidus extrÃªmes ---\")\n",
    "    \n",
    "    try:\n",
    "        y_pred = baseline_result.predict()\n",
    "        residuals = Y - y_pred\n",
    "        std_res = (residuals - residuals.mean()) / residuals.std()\n",
    "        \n",
    "        mask_normal = np.abs(std_res) <= 3\n",
    "        n_excluded = (~mask_normal).sum()\n",
    "        \n",
    "        print(f\"  Observations exclues (|rÃ©sidu| > 3Ïƒ) : {n_excluded} ({100*n_excluded/len(Y):.2f}%)\")\n",
    "        report_lines.append(f\"  Observations exclues : {n_excluded} ({100*n_excluded/len(Y):.2f}%)\")\n",
    "        \n",
    "        X_clean = X.loc[mask_normal]\n",
    "        Y_clean = Y[mask_normal]\n",
    "        X_clean_const = sm.add_constant(X_clean)\n",
    "        \n",
    "        model_clean = sm.Probit(Y_clean, X_clean_const)\n",
    "        result_clean = model_clean.fit(disp=0)\n",
    "        \n",
    "        print(f\"  Pseudo RÂ² (sans extrÃªmes) : {result_clean.prsquared:.4f}\")\n",
    "        report_lines.append(f\"  Pseudo RÂ² (sans extrÃªmes) : {result_clean.prsquared:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Erreur : {e}\")\n",
    "    \n",
    "    # 2. Jackknife par dÃ©partement\n",
    "    print(\"\\n--- Jackknife par dÃ©partement ---\")\n",
    "    report_lines.append(\"\\n--- Jackknife par dÃ©partement ---\")\n",
    "    \n",
    "    dept_cols = [c for c in X.columns if c.startswith('DEPT_')]\n",
    "    \n",
    "    key_var = 'AGEREV' if 'AGEREV' in X.columns else (dept_cols[0] if dept_cols else None)\n",
    "    \n",
    "    if key_var and dept_cols:\n",
    "        coefs_jack = []\n",
    "        \n",
    "        for dept in dept_cols[:5]:  # Limiter Ã  5 pour la vitesse\n",
    "            mask = X[dept] == 0  # Exclure ce dÃ©partement\n",
    "            X_jack = X.loc[mask]\n",
    "            Y_jack = Y[mask.values]\n",
    "            \n",
    "            if len(Y_jack) > 100:\n",
    "                try:\n",
    "                    X_jack_const = sm.add_constant(X_jack)\n",
    "                    model = sm.Probit(Y_jack, X_jack_const)\n",
    "                    result = model.fit(disp=0, maxiter=30)\n",
    "                    \n",
    "                    if key_var in result.params.index:\n",
    "                        coefs_jack.append(result.params[key_var])\n",
    "                        print(f\"  Sans {dept:<10} : {key_var} = {result.params[key_var]:.4f}\")\n",
    "                        report_lines.append(f\"  Sans {dept:<10} : {key_var} = {result.params[key_var]:.4f}\")\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        if coefs_jack:\n",
    "            std_jack = np.std(coefs_jack)\n",
    "            print(f\"\\n  Ã‰cart-type Jackknife ({key_var}) : {std_jack:.4f}\")\n",
    "            report_lines.append(f\"\\n  Ã‰cart-type Jackknife ({key_var}) : {std_jack:.4f}\")\n",
    "    \n",
    "    report_lines.append(\"\\nâœ… Analyse de sensibilitÃ© terminÃ©e\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def test_8_functional_form_age(X, Y, report_lines):\n",
    "    \"\"\"\n",
    "    Test 8 : Formes fonctionnelles pour l'Ã¢ge\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 8 : FORME FONCTIONNELLE Ã‚GE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 8 : FORME FONCTIONNELLE Ã‚GE\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    if 'AGEREV' not in X.columns:\n",
    "        print(\"\\nâš ï¸ Variable AGEREV non trouvÃ©e\")\n",
    "        report_lines.append(\"\\nâš ï¸ Variable AGEREV non trouvÃ©e\")\n",
    "        return None\n",
    "    \n",
    "    results_age = {}\n",
    "    \n",
    "    # PrÃ©parer les variables autres que l'Ã¢ge\n",
    "    age_cols = [c for c in X.columns if 'AGE' in c.upper()]\n",
    "    X_base = X.drop(columns=age_cols, errors='ignore')\n",
    "    \n",
    "    try:\n",
    "        # 1. LinÃ©aire\n",
    "        X_lin = X_base.copy()\n",
    "        X_lin['AGE'] = X['AGEREV']\n",
    "        X_lin_const = sm.add_constant(X_lin)\n",
    "        model_lin = sm.Probit(Y, X_lin_const)\n",
    "        result_lin = model_lin.fit(disp=0)\n",
    "        results_age['LinÃ©aire'] = result_lin\n",
    "        \n",
    "        # 2. Quadratique\n",
    "        X_quad = X_base.copy()\n",
    "        X_quad['AGE'] = X['AGEREV']\n",
    "        X_quad['AGE_sq'] = X['AGEREV'] ** 2\n",
    "        X_quad_const = sm.add_constant(X_quad)\n",
    "        model_quad = sm.Probit(Y, X_quad_const)\n",
    "        result_quad = model_quad.fit(disp=0)\n",
    "        results_age['Quadratique'] = result_quad\n",
    "        \n",
    "        # 3. Cubique\n",
    "        X_cub = X_base.copy()\n",
    "        X_cub['AGE'] = X['AGEREV']\n",
    "        X_cub['AGE_sq'] = X['AGEREV'] ** 2\n",
    "        X_cub['AGE_cub'] = X['AGEREV'] ** 3\n",
    "        X_cub_const = sm.add_constant(X_cub)\n",
    "        model_cub = sm.Probit(Y, X_cub_const)\n",
    "        result_cub = model_cub.fit(disp=0)\n",
    "        results_age['Cubique'] = result_cub\n",
    "        \n",
    "        # 4. Spline (tranches d'Ã¢ge)\n",
    "        X_spline = X_base.copy()\n",
    "        X_spline['AGE_25_34'] = ((X['AGEREV'] >= 25) & (X['AGEREV'] < 35)).astype(int)\n",
    "        X_spline['AGE_35_44'] = ((X['AGEREV'] >= 35) & (X['AGEREV'] < 45)).astype(int)\n",
    "        X_spline['AGE_45_54'] = ((X['AGEREV'] >= 45) & (X['AGEREV'] < 55)).astype(int)\n",
    "        X_spline['AGE_55plus'] = (X['AGEREV'] >= 55).astype(int)\n",
    "        X_spline_const = sm.add_constant(X_spline)\n",
    "        model_spline = sm.Probit(Y, X_spline_const)\n",
    "        result_spline = model_spline.fit(disp=0)\n",
    "        results_age['Spline'] = result_spline\n",
    "        \n",
    "        # Comparaison\n",
    "        print(f\"\\n{'Forme':<15} {'Log-L':>12} {'AIC':>12} {'BIC':>12}\")\n",
    "        print(\"-\" * 55)\n",
    "        report_lines.append(f\"\\n{'Forme':<15} {'Log-L':>12} {'AIC':>12} {'BIC':>12}\")\n",
    "        report_lines.append(\"-\" * 55)\n",
    "        \n",
    "        for name, res in results_age.items():\n",
    "            print(f\"{name:<15} {res.llf:>12,.2f} {res.aic:>12,.2f} {res.bic:>12,.2f}\")\n",
    "            report_lines.append(f\"{name:<15} {res.llf:>12,.2f} {res.aic:>12,.2f} {res.bic:>12,.2f}\")\n",
    "        \n",
    "        # Meilleur selon BIC\n",
    "        best = min(results_age.items(), key=lambda x: x[1].bic)\n",
    "        print(f\"\\nâœ“ Meilleure forme (BIC) : {best[0]}\")\n",
    "        report_lines.append(f\"\\nâœ“ Meilleure forme (BIC) : {best[0]}\")\n",
    "        \n",
    "        # Test LR quadratique vs linÃ©aire\n",
    "        lr_stat = 2 * (result_quad.llf - result_lin.llf)\n",
    "        lr_pval = 1 - chi2.cdf(lr_stat, 1)\n",
    "        print(f\"\\nTest LR (Quad vs Lin) : Ï‡Â²={lr_stat:.2f}, p={lr_pval:.4f}\")\n",
    "        report_lines.append(f\"\\nTest LR (Quad vs Lin) : Ï‡Â²={lr_stat:.2f}, p={lr_pval:.4f}\")\n",
    "        \n",
    "        if lr_pval < 0.05:\n",
    "            print(\"âœ“ Effet quadratique significatif\")\n",
    "            report_lines.append(\"âœ“ Effet quadratique significatif\")\n",
    "        \n",
    "        return results_age\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Erreur : {e}\")\n",
    "        report_lines.append(f\"\\nâŒ ERREUR : {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_report(report_lines, output_dir):\n",
    "    \"\"\"\n",
    "    GÃ©nÃ¨re le rapport final\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Ajouter en-tÃªte\n",
    "    header = [\n",
    "        \"=\" * 80,\n",
    "        \"RAPPORT DE ROBUSTESSE - MODÃˆLE PROBIT TRANSFRONTALIER\",\n",
    "        f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "        \"=\" * 80,\n",
    "        \"\"\n",
    "    ]\n",
    "    \n",
    "    full_report = header + report_lines\n",
    "    \n",
    "    # Sauvegarder\n",
    "    report_path = os.path.join(output_dir, \"rapport_robustesse.txt\")\n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(full_report))\n",
    "    \n",
    "    print(f\"\\nâœ“ Rapport sauvegardÃ© : {report_path}\")\n",
    "    return report_path\n",
    "\n",
    "\n",
    "def run_all_tests(x_path=X_PATH, y_path=Y_PATH, output_dir=OUTPUT_DIR):\n",
    "    \"\"\"\n",
    "    ExÃ©cute tous les tests de robustesse\n",
    "    \"\"\"\n",
    "    report_lines = []\n",
    "    \n",
    "    # Chargement\n",
    "    X, X_const, Y = load_data(x_path, y_path)\n",
    "    \n",
    "    # Test 1 : Probit de base\n",
    "    baseline = test_1_baseline_probit(X_const, Y, report_lines)\n",
    "    if baseline is None:\n",
    "        print(\"\\nâŒ ArrÃªt : le modÃ¨le de base n'a pas convergÃ©\")\n",
    "        return\n",
    "    \n",
    "    # Test 2 : Link Test\n",
    "    test_2_link_test(X_const, Y, baseline, report_lines)\n",
    "    \n",
    "    # Test 3 : Hosmer-Lemeshow\n",
    "    test_3_hosmer_lemeshow(Y, baseline, report_lines)\n",
    "    \n",
    "    # Test 4 : Probit vs Logit\n",
    "    test_4_probit_vs_logit(X_const, Y, report_lines)\n",
    "    \n",
    "    # Test 5 : Robustesse endogÃ©nÃ©itÃ©\n",
    "    test_5_endogeneity_robustness(X, Y, baseline, report_lines)\n",
    "    \n",
    "    # Test 6 : Sous-Ã©chantillons\n",
    "    test_6_subsamples(X, Y, report_lines)\n",
    "    \n",
    "    # Test 7 : SensibilitÃ©\n",
    "    test_7_sensitivity(X, Y, baseline, report_lines)\n",
    "    \n",
    "    # Test 8 : Forme fonctionnelle Ã¢ge\n",
    "    test_8_functional_form_age(X, Y, report_lines)\n",
    "    \n",
    "    # GÃ©nÃ©rer rapport\n",
    "    generate_report(report_lines, output_dir)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TESTS DE ROBUSTESSE TERMINÃ‰S\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return baseline\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXÃ‰CUTION\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TESTS DE ROBUSTESSE - PROBIT TRANSFRONTALIER\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # VÃ©rifier si les fichiers existent (pour environnement local)\n",
    "    import os\n",
    "    if os.path.exists(X_PATH) and os.path.exists(Y_PATH):\n",
    "        run_all_tests()\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ Fichiers non trouvÃ©s :\")\n",
    "        print(f\"   X : {X_PATH}\")\n",
    "        print(f\"   Y : {Y_PATH}\")\n",
    "        print(\"\\nâ†’ Adapter les chemins X_PATH et Y_PATH en haut du script\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b0b907",
   "metadata": {},
   "source": [
    "## InterprÃ©tation des tests de robustesse \n",
    "\n",
    "### RÃ©sultats satisfaisants\n",
    "\n",
    "**Convergence et ajustement global**\n",
    "\n",
    "Le modÃ¨le probit converge rapidement en 10 itÃ©rations, avec un pseudo-RÂ² de 0.24, un AIC de 226 894 et un BIC de 227 627. Ces valeurs de pseudo-RÂ² peuvent sembler modestes comparÃ©es aux RÂ² de rÃ©gression linÃ©aire, mais elles sont tout Ã  fait satisfaisantes pour un modÃ¨le de choix binaire sur donnÃ©es individuelles. Elles indiquent que les variables retenues captent une part significative de l'hÃ©tÃ©rogÃ©nÃ©itÃ© des comportements transfrontaliers, sachant qu'une grande partie des dÃ©terminants (prÃ©fÃ©rences, rÃ©seaux, compÃ©tences linguistiques) n'est pas observable dans les donnÃ©es du recensement.\n",
    "\n",
    "**Coefficients Ã©conomiquement cohÃ©rents**\n",
    "\n",
    "Les coefficients dÃ©partementaux confirment le gradient gÃ©ographique attendu. La Moselle affiche l'effet le plus fort (+2.44), suivie du Haut-Rhin (+2.09), de la Meurthe-et-Moselle (+1.94) et du Bas-Rhin (+1.47). Cette hiÃ©rarchie reflÃ¨te fidÃ¨lement la proximitÃ© aux principaux bassins d'emploi frontaliers : Luxembourg pour la Moselle et la Meurthe-et-Moselle, Suisse et Allemagne pour le Haut-Rhin et le Bas-Rhin. L'effet genre est nÃ©gatif pour les femmes (-0.13), cohÃ©rent avec la littÃ©rature sur la moindre mobilitÃ© professionnelle fÃ©minine. L'effet de l'Ã¢ge suit bien une forme en U inversÃ©, avec un pic d'activitÃ© transfrontaliÃ¨re en milieu de carriÃ¨re.\n",
    "\n",
    "**HÃ©tÃ©rogÃ©nÃ©itÃ© par sexe**\n",
    "\n",
    "Les estimations par sous-Ã©chantillons rÃ©vÃ¨lent des diffÃ©rences notables entre hommes et femmes. Le taux de transfrontaliers atteint 10.5% chez les hommes contre seulement 7.2% chez les femmes, soit un Ã©cart de 3.3 points de pourcentage. MalgrÃ© cette diffÃ©rence de prÃ©valence, les pseudo-RÂ² restent comparables : 0.233 pour les hommes et 0.248 pour les femmes. La structure explicative est donc stable entre les deux groupes, mÃªme si le niveau diffÃ¨re. Les estimations par tranche d'Ã¢ge (moins de 35 ans vs 35 ans et plus) confirment cette stabilitÃ©, avec des pseudo-RÂ² de 0.249 et 0.240 respectivement.\n",
    "\n",
    "**StabilitÃ© des estimations et Ã©quivalence Probit/Logit**\n",
    "\n",
    "La comparaison Probit/Logit montre une corrÃ©lation des effets marginaux de 0.995, confirmant l'Ã©quivalence pratique des deux spÃ©cifications. Les deux modÃ¨les produisent des pseudo-RÂ² quasi identiques (0.239 vs 0.240) et des critÃ¨res d'information trÃ¨s proches. Le choix du probit est donc robuste et n'affecte pas les conclusions substantives.\n",
    "\n",
    "**Test de robustesse Ã  l'endogÃ©nÃ©itÃ©**\n",
    "\n",
    "L'exclusion des 15 variables potentiellement endogÃ¨nes (nombre de voitures, statut d'occupation du logement, type de logement) permet d'Ã©valuer la sensibilitÃ© du modÃ¨le Ã  d'Ã©ventuels biais de simultanÃ©itÃ©. Le modÃ¨le rÃ©duit, estimÃ© sur 51 variables au lieu de 66, affiche un pseudo-RÂ² de 0.221 contre 0.239 pour le modÃ¨le complet. Cette perte de seulement 1.8 point indique que les variables suspectes contribuent peu au pouvoir explicatif global. La log-vraisemblance passe de -113 381 Ã  -116 153, une dÃ©gradation modÃ©rÃ©e. Surtout, les coefficients clÃ©s restent remarquablement stables : le coefficient de la Moselle varie de +0.8%, celui du Haut-Rhin de +1.4%, celui du sexe de +4.4% et celui de l'Ã¢ge de -1.4%. Cette stabilitÃ© suggÃ¨re que les rÃ©sultats ne sont pas contaminÃ©s par un biais d'endogÃ©nÃ©itÃ© majeur.\n",
    "\n",
    "**Forme fonctionnelle de l'Ã¢ge**\n",
    "\n",
    "Le test du ratio de vraisemblance valide la spÃ©cification quadratique de l'Ã¢ge (Ï‡Â²=312, p<0.001). L'ajout d'un terme cubique amÃ©liore lÃ©gÃ¨rement l'ajustement : le BIC passe de 227 627 Ã  227 596, soit un gain de 30 points. Ce gain reste marginal et la forme quadratique constitue un bon compromis entre flexibilitÃ© et parcimonie. La spÃ©cification par splines ne fait pas mieux que la forme cubique, confirmant qu'une paramÃ©trisation polynomiale simple suffit Ã  capturer la relation Ã¢ge-travail transfrontalier.\n",
    "\n",
    "---\n",
    "\n",
    "### RÃ©sultats nÃ©cessitant approfondissement\n",
    "\n",
    "**Link Test et Hosmer-Lemeshow rejetÃ©s**\n",
    "\n",
    "Les deux tests classiques de spÃ©cification sont rejetÃ©s avec des p-values nulles. Le Link Test de Pregibon indique un coefficient de 0.051 pour le terme quadratique (_hatsq), significatif Ã  p<0.001. Le test de Hosmer-Lemeshow produit une statistique de 304.5 Ã  8 degrÃ©s de libertÃ©. Ces rÃ©sultats pourraient inquiÃ©ter, mais ils s'expliquent entiÃ¨rement par la taille de l'Ã©chantillon. Ã€ n=494 000, ces tests disposent d'une puissance statistique telle qu'ils dÃ©tectent la moindre dÃ©viation, aussi infime soit-elle, par rapport Ã  l'hypothÃ¨se nulle. Un Ã©cart de calibration de 0.1 point de pourcentage, sans aucune consÃ©quence pratique, suffit Ã  rejeter H0. Ces tests ne sont donc pas informatifs dans notre contexte et doivent Ãªtre remplacÃ©s par des diagnostics adaptÃ©s aux grands Ã©chantillons : score de Brier, courbe de calibration par dÃ©ciles, et AUC avec intervalle de confiance bootstrap.\n",
    "\n",
    "**Ratio Logit/Probit supÃ©rieur Ã  la valeur thÃ©orique**\n",
    "\n",
    "Le ratio moyen des coefficients Logit/Probit s'Ã©tablit Ã  2.05, alors que la valeur thÃ©orique attendue est d'environ 1.6. Cet Ã©cart n'indique pas nÃ©cessairement un problÃ¨me. Il provient vraisemblablement du choix de la Marne comme catÃ©gorie de rÃ©fÃ©rence. La Marne Ã©tant un dÃ©partement non frontalier, les coefficients des dÃ©partements frontaliers sont mÃ©caniquement trÃ¨s Ã©levÃ©s (supÃ©rieurs Ã  2). Or, lorsque les coefficients sont extrÃªmes, les fonctions de rÃ©partition logistique et normale divergent dans les queues de distribution, ce qui amplifie le ratio. Pour vÃ©rifier cette hypothÃ¨se, il convient de rÃ©-estimer le modÃ¨le avec un dÃ©partement frontalier comme rÃ©fÃ©rence, par exemple le Bas-Rhin, et d'observer si le ratio se rapproche de 1.6.\n",
    "\n",
    "**RÃ©sidus extrÃªmes et pseudo-RÂ² sans outliers**\n",
    "\n",
    "L'analyse identifie 21 432 observations (4.3% de l'Ã©chantillon) prÃ©sentant des rÃ©sidus standardisÃ©s supÃ©rieurs Ã  3 en valeur absolue. Un rÃ©sultat frappant Ã©merge lorsqu'on exclut ces observations : le pseudo-RÂ² bondit Ã  0.48, soit un quasi-doublement par rapport au modÃ¨le complet. Ce saut spectaculaire indique que ces individus ne sont pas du bruit alÃ©atoire mais une sous-population structurellement diffÃ©rente, dont le comportement Ã©chappe aux variables du modÃ¨le. \n",
    "\n",
    "Il serait tentant de les traiter comme des outliers Ã  exclure pour amÃ©liorer l'ajustement, mais cette approche serait mÃ©thodologiquement contestable. Ces observations correspondent Ã  des individus rÃ©els dont le comportement s'Ã©carte de la prÃ©diction du modÃ¨le. Avant toute dÃ©cision, il est indispensable de caractÃ©riser leur profil : sont-ils concentrÃ©s gÃ©ographiquement dans certains dÃ©partements ? PrÃ©sentent-ils des caractÃ©ristiques sociodÃ©mographiques particuliÃ¨res ? S'agit-il principalement de faux nÃ©gatifs (transfrontaliers non prÃ©dits) ou de faux positifs (non-transfrontaliers prÃ©dits comme tels) ? Cette analyse permettra de distinguer les Ã©ventuelles erreurs de donnÃ©es d'une hÃ©tÃ©rogÃ©nÃ©itÃ© comportementale rÃ©elle que le modÃ¨le ne capture pas.\n",
    "\n",
    "**Ã‰chec des estimations par zone frontaliÃ¨re/intÃ©rieure**\n",
    "\n",
    "L'estimation sÃ©parÃ©e sur les dÃ©partements frontaliers et intÃ©rieurs a Ã©chouÃ©. Ce rÃ©sultat est normal et attendu : au sein de chaque sous-groupe, les dummies dÃ©partementales deviennent parfaitement colinÃ©aires (toutes les observations frontaliÃ¨res ont DEPT_57=0 ou 1, etc.), rendant l'estimation impossible. Ce n'est pas un bug mais une consÃ©quence mÃ©canique du dÃ©coupage.\n",
    "\n",
    "---\n",
    "\n",
    "### Tests complÃ©mentaires Ã  conduire\n",
    "\n",
    "Pour rÃ©pondre aux questions ouvertes, trois analyses complÃ©mentaires sont nÃ©cessaires. PremiÃ¨rement, remplacer les tests HL et Link par des diagnostics adaptÃ©s aux grands Ã©chantillons : score de Brier avec comparaison au modÃ¨le nul, courbe de calibration par dÃ©ciles comparant taux observÃ©s et prÃ©dits, et AUC-ROC avec intervalle de confiance bootstrap. DeuxiÃ¨mement, caractÃ©riser les rÃ©sidus extrÃªmes en analysant leur distribution gÃ©ographique, leur profil d'Ã¢ge et de sexe, et la nature des erreurs de prÃ©diction. TroisiÃ¨mement, tester la sensibilitÃ© du ratio Logit/Probit au choix de la catÃ©gorie de rÃ©fÃ©rence en rÃ©-estimant avec le Bas-Rhin comme rÃ©fÃ©rence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd999f6",
   "metadata": {},
   "source": [
    "## Tests de robustesse complÃ©mentaires\n",
    "\n",
    "L'estimation initiale du modÃ¨le probit a convergÃ© avec un pseudo-RÂ² de 0.24 et des coefficients cohÃ©rents Ã©conomiquement. Cependant, certains rÃ©sultats appellent une analyse approfondie :\n",
    "\n",
    "1. **Diagnostics adaptÃ©s aux grands Ã©chantillons** â€” Les tests classiques (Hosmer-Lemeshow, Link Test) sont rejetÃ©s mÃ©caniquement Ã  n=494k par excÃ¨s de puissance statistique. On les remplace par : score de Brier, courbe de calibration par dÃ©ciles, AUC avec intervalle bootstrap.\n",
    "\n",
    "2. **CaractÃ©risation des rÃ©sidus extrÃªmes** â€” 4.3% d'observations prÃ©sentent des rÃ©sidus > 2.5Ïƒ. Avant toute dÃ©cision, on analyse leur distribution gÃ©ographique et leur profil sociodÃ©mographique pour distinguer erreurs de donnÃ©es vs hÃ©tÃ©rogÃ©nÃ©itÃ© comportementale rÃ©elle.\n",
    "\n",
    "3. **SensibilitÃ© au choix de la catÃ©gorie de rÃ©fÃ©rence** â€” Le ratio Logit/Probit (~2.05) dÃ©passe la valeur thÃ©orique (~1.6), possiblement dÃ» aux coefficients extrÃªmes induits par la Marne (non frontaliÃ¨re) comme rÃ©fÃ©rence. On rÃ©-estime avec le Bas-Rhin (frontalier) comme rÃ©fÃ©rence pour vÃ©rifier.\n",
    "\n",
    "4. **Comparaison des effets marginaux Probit vs Logit** â€” CorrÃ©lation et Ã©cart moyen pour confirmer l'Ã©quivalence pratique des deux spÃ©cifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d78b097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CHARGEMENT DES DONNÃ‰ES\n",
      "================================================================================\n",
      "\n",
      "âœ“ X chargÃ© : 494,483 obs Ã— 65 variables\n",
      "âœ“ Transfrontaliers (Y=1) : 44,264 (8.95%)\n",
      "\n",
      "================================================================================\n",
      "TEST 1 : MODÃˆLE PROBIT DE BASE\n",
      "================================================================================\n",
      "\n",
      "âœ“ Convergence : Oui\n",
      "âœ“ Log-L       : -113,380.76\n",
      "âœ“ Pseudo RÂ²   : 0.2393\n",
      "\n",
      "--- Coefficients clÃ©s ---\n",
      "  DEPT_57      :   2.4367 [IC95: 2.342 ; 2.531]\n",
      "  DEPT_68      :   2.0908 [IC95: 1.996 ; 2.185]\n",
      "  DEPT_54      :   1.9401 [IC95: 1.845 ; 2.035]\n",
      "  DEPT_67      :   1.4722 [IC95: 1.377 ; 1.567]\n",
      "  SEXE_2       :  -0.1255 [IC95: -0.139 ; -0.112]\n",
      "  AGEREV       :   0.0326 [IC95: 0.029 ; 0.036]\n",
      "  AGEREV_sq    :  -0.0004 [IC95: -0.000 ; -0.000]\n",
      "\n",
      "================================================================================\n",
      "TEST 2 : DIAGNOSTICS GRANDS Ã‰CHANTILLONS\n",
      "================================================================================\n",
      "\n",
      "--- 2.1 Brier Score ---\n",
      "  Brier Score      : 0.0681\n",
      "  Brier (null)     : 0.0815\n",
      "  Brier Skill Score: 0.1643\n",
      "  âœ“ Pouvoir prÃ©dictif modeste mais positif\n",
      "\n",
      "--- 2.2 Calibration par dÃ©ciles ---\n",
      "\n",
      "  DÃ©cile          N     PrÃ©dit    ObservÃ©      Ã‰cart\n",
      "  --------------------------------------------------\n",
      "  0           49449     0.0001     0.0004    +0.0003\n",
      "  1           49448     0.0008     0.0019    +0.0011\n",
      "  2           49448     0.0037     0.0044    +0.0007\n",
      "  3           49448     0.0135     0.0143    +0.0008\n",
      "  4           49449     0.0333     0.0309    -0.0024\n",
      "  5           49450     0.0569     0.0520    -0.0049\n",
      "  6           49446     0.0862     0.0861    -0.0001\n",
      "  7           49449     0.1350     0.1261    -0.0089\n",
      "  8           49447     0.2097     0.2230    +0.0133\n",
      "  9           49449     0.3558     0.3561    +0.0003\n",
      "\n",
      "  Ã‰cart moyen absolu de calibration : 0.0033\n",
      "  âœ… Excellente calibration\n",
      "\n",
      "--- 2.3 AUC-ROC avec IC Bootstrap ---\n",
      "  AUC point estimate : 0.8490\n",
      "  AUC IC 95%         : [0.8476 ; 0.8504]\n",
      "  âœ… Excellente discrimination (AUC > 0.8)\n",
      "\n",
      "--- 2.4 Validation croisÃ©e 5-fold ---\n",
      "  AUC moyen (5-fold)   : 0.8407 Â± 0.0039\n",
      "  Brier moyen (5-fold) : 0.0687 Â± 0.0003\n",
      "  âœ… TrÃ¨s stable entre folds (CV < 2%)\n",
      "\n",
      "================================================================================\n",
      "TEST 3 : CARACTÃ‰RISATION DES RÃ‰SIDUS EXTRÃŠMES\n",
      "================================================================================\n",
      "\n",
      "--- 3.1 Distribution des rÃ©sidus ---\n",
      "  |rÃ©sidu| > 2Ïƒ : 42,593 obs (8.61%)\n",
      "  |rÃ©sidu| > 2.5Ïƒ : 36,005 obs (7.28%)\n",
      "  |rÃ©sidu| > 3Ïƒ : 21,432 obs (4.33%)\n",
      "\n",
      "  â†’ Analyse dÃ©taillÃ©e pour |rÃ©sidu| > 2.5Ïƒ (36,005 obs)\n",
      "\n",
      "--- 3.2 Types de rÃ©sidus extrÃªmes ---\n",
      "  Faux nÃ©gatifs (Y=1, P<0.2) : 19,332\n",
      "  Faux positifs (Y=0, P>0.3) : 244\n",
      "\n",
      "--- 3.3 RÃ©partition gÃ©ographique ---\n",
      "\n",
      "  Dept          N   Trans.   %Trans    Extr.    %Extr\n",
      "  -------------------------------------------------------\n",
      "  57        98869    21377    21.6%    15315   15.49%\n",
      "  68        73587    10348    14.1%     8959   12.17%\n",
      "  54        64924     6286     9.7%     5537    8.53%\n",
      "  55        14885      707     4.7%      690    4.64%\n",
      "  67       118398     5389     4.6%     5347    4.52%\n",
      "  88        29098       66     0.2%       66    0.23%\n",
      "  52        14249       18     0.1%       18    0.13%\n",
      "  10        27234       33     0.1%       33    0.12%\n",
      "  51        53239       40     0.1%       40    0.08%\n",
      "\n",
      "--- 3.4 Profil des rÃ©sidus extrÃªmes ---\n",
      "\n",
      "  Variable         Pop. totale        ExtrÃªmes       Diff\n",
      "  -------------------------------------------------------\n",
      "  AGEREV                41.479          41.933     +0.454\n",
      "  SEXE_2                 0.481           0.409     -0.072\n",
      "\n",
      "  Taux transfrontaliers :\n",
      "    - Population totale : 8.95%\n",
      "    - RÃ©sidus extrÃªmes  : 99.32%\n",
      "\n",
      "--- 3.5 Recommandation ---\n",
      "  âš ï¸ Taux d'extrÃªmes Ã©levÃ© (>5%). Investiguer les causes, ne PAS supprimer sans justification.\n",
      "\n",
      "  IMPORTANT : Les rÃ©sidus extrÃªmes ne doivent PAS Ãªtre supprimÃ©s automatiquement.\n",
      "  Ce sont de vraies observations qui reflÃ¨tent l'hÃ©tÃ©rogÃ©nÃ©itÃ© de la population.\n",
      "  Leur suppression biaiserait les rÃ©sultats.\n",
      "\n",
      "================================================================================\n",
      "TEST 4 : RATIO LOGIT/PROBIT - CHANGEMENT DE RÃ‰FÃ‰RENCE\n",
      "================================================================================\n",
      "\n",
      "--- 4.1 ModÃ¨le initial (rÃ©f = DEPT_51, Marne) ---\n",
      "\n",
      "  Variable         Probit      Logit      Ratio\n",
      "  ---------------------------------------------\n",
      "  DEPT_10          0.1043     0.3677      3.526\n",
      "  DEPT_52          0.1197     0.4486      3.748\n",
      "  DEPT_54          1.9401     4.8657      2.508\n",
      "  DEPT_55          1.5232     4.0744      2.675\n",
      "  DEPT_57          2.4367     5.7580      2.363\n",
      "  DEPT_67          1.4722     3.9363      2.674\n",
      "  DEPT_68          2.0908     5.1525      2.464\n",
      "  DEPT_88          0.2933     0.9789      3.337\n",
      "\n",
      "  Ratio moyen (DEPT) : 2.912\n",
      "\n",
      "--- 4.2 Reconstruction avec DEPT_67 (Bas-Rhin) comme rÃ©fÃ©rence ---\n",
      "  Nouvelles dummies DEPT : ['DEPT_10', 'DEPT_51', 'DEPT_52', 'DEPT_54', 'DEPT_55']...\n",
      "\n",
      "--- 4.3 Estimation avec DEPT_67 comme rÃ©fÃ©rence ---\n",
      "\n",
      "  Variable         Probit      Logit      Ratio\n",
      "  ---------------------------------------------\n",
      "  DEPT_10         -1.3680    -3.5686      2.609\n",
      "  DEPT_51         -1.4722    -3.9363      2.674\n",
      "  DEPT_52         -1.3526    -3.4878      2.579\n",
      "  DEPT_54          0.4678     0.9294      1.986\n",
      "  DEPT_55          0.0509     0.1380      2.710\n",
      "  DEPT_57          0.9644     1.8217      1.889\n",
      "  DEPT_68          0.6185     1.2161      1.966\n",
      "  DEPT_88         -1.1789    -2.9575      2.509\n",
      "\n",
      "--- 4.4 Comparaison ---\n",
      "\n",
      "  RÃ©fÃ©rence                Ratio moyen\n",
      "  ----------------------------------------\n",
      "  DEPT_51 (Marne)                2.912\n",
      "  DEPT_67 (Bas-Rhin)             2.365\n",
      "  ThÃ©orique                       ~1.6\n",
      "\n",
      "--- 4.5 InterprÃ©tation ---\n",
      "\n",
      "  âœ… HYPOTHÃˆSE CONFIRMÃ‰E : Le ratio se rapproche de 1.6 avec la nouvelle rÃ©fÃ©rence.\n",
      "  \n",
      "  Explication : Avec DEPT_51 (non frontalier) comme rÃ©fÃ©rence, les coefficients\n",
      "  des dÃ©partements frontaliers (57, 68) Ã©taient trÃ¨s Ã©levÃ©s (~2.5), car ils \n",
      "  captent TOUT l'Ã©cart avec un dÃ©partement sans frontiÃ¨re.\n",
      "  \n",
      "  Ces coefficients extrÃªmes amplifient la diffÃ©rence entre les fonctions \n",
      "  logistique et normale dans les queues de distribution, d'oÃ¹ un ratio > 1.6.\n",
      "  \n",
      "  Avec DEPT_67 comme rÃ©fÃ©rence (frontalier), les coefficients sont plus modÃ©rÃ©s\n",
      "  et le ratio revient vers sa valeur thÃ©orique.\n",
      "  \n",
      "  â†’ Ce n'est PAS un problÃ¨me du modÃ¨le, c'est une consÃ©quence du design \n",
      "    (catÃ©gorie de rÃ©fÃ©rence non frontaliÃ¨re).\n",
      "  â†’ Le modÃ¨le avec DEPT_51 comme rÃ©fÃ©rence reste valide et prÃ©fÃ©rable pour\n",
      "    l'interprÃ©tation Ã©conomique (effet frontiÃ¨re direct).\n",
      "\n",
      "================================================================================\n",
      "TEST 5 : PROBIT VS LOGIT (EFFETS MARGINAUX)\n",
      "================================================================================\n",
      "\n",
      "  CorrÃ©lation effets marginaux : 0.995254\n",
      "  DiffÃ©rence moyenne absolue   : 0.005267\n",
      "\n",
      "  âœ“ Probit et Logit trÃ¨s similaires\n",
      "\n",
      "âœ“ Rapport sauvegardÃ© : /Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready/Robustesse_v3/rapport_robustesse_v3.txt\n",
      "\n",
      "================================================================================\n",
      "TESTS DE ROBUSTESSE V3 TERMINÃ‰S\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "TESTS DE ROBUSTESSE  - MODÃˆLE PROBIT TRANSFRONTALIER\n",
    "================================================================================\n",
    "Version adaptÃ©e pour grands Ã©chantillons (n = 494k)\n",
    "\n",
    "MODIFICATIONS PAR RAPPORT Ã€ V2 :\n",
    "1. Remplacement HL/Link Test â†’ Brier Score, Calibration, AUC bootstrap\n",
    "2. CaractÃ©risation des rÃ©sidus extrÃªmes (profil, dÃ©partement)\n",
    "3. Test ratio Logit/Probit avec DEPT_67 comme rÃ©fÃ©rence\n",
    "\n",
    "CatÃ©gorie de rÃ©fÃ©rence initiale : DEPT_51 (Marne) - non frontalier\n",
    "Test alternatif : DEPT_67 (Bas-Rhin) comme rÃ©fÃ©rence - frontalier\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2\n",
    "from sklearn.metrics import brier_score_loss, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "X_PATH = \"/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready/BDD_PROBIT.csv\"\n",
    "Y_PATH = \"/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready/y_final.csv\"\n",
    "OUTPUT_DIR = \"/Users/mehdifehri/Desktop/Projet INSEE/BDD/BDD GE/BDD Clean/Probit_Ready/Robustesse_v3\"\n",
    "\n",
    "\n",
    "def load_data(x_path, y_path):\n",
    "    \"\"\"Charge les donnÃ©es X et Y\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"CHARGEMENT DES DONNÃ‰ES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    X = pd.read_csv(x_path)\n",
    "    print(f\"\\nâœ“ X chargÃ© : {X.shape[0]:,} obs Ã— {X.shape[1]} variables\")\n",
    "    \n",
    "    Y_df = pd.read_csv(y_path)\n",
    "    y_col = Y_df.columns[0]\n",
    "    Y = Y_df[y_col].values\n",
    "    \n",
    "    n_transfront = Y.sum()\n",
    "    pct_transfront = 100 * n_transfront / len(Y)\n",
    "    print(f\"âœ“ Transfrontaliers (Y=1) : {n_transfront:,} ({pct_transfront:.2f}%)\")\n",
    "    \n",
    "    X_with_const = sm.add_constant(X, has_constant='add')\n",
    "    \n",
    "    return X, X_with_const, Y\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 1 : MODÃˆLE DE BASE\n",
    "# ============================================================================\n",
    "def test_1_baseline_probit(X, Y, report_lines):\n",
    "    \"\"\"Estimation du modÃ¨le probit de base\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 1 : MODÃˆLE PROBIT DE BASE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 1 : MODÃˆLE PROBIT DE BASE\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    model = sm.Probit(Y, X)\n",
    "    result = model.fit(disp=0, maxiter=100)\n",
    "    \n",
    "    print(f\"\\nâœ“ Convergence : {'Oui' if result.mle_retvals['converged'] else 'Non'}\")\n",
    "    print(f\"âœ“ Log-L       : {result.llf:,.2f}\")\n",
    "    print(f\"âœ“ Pseudo RÂ²   : {result.prsquared:.4f}\")\n",
    "    \n",
    "    report_lines.append(f\"\\nConvergence : {'Oui' if result.mle_retvals['converged'] else 'Non'}\")\n",
    "    report_lines.append(f\"Log-L       : {result.llf:,.2f}\")\n",
    "    report_lines.append(f\"Pseudo RÂ²   : {result.prsquared:.4f}\")\n",
    "    \n",
    "    # Coefficients clÃ©s\n",
    "    print(\"\\n--- Coefficients clÃ©s ---\")\n",
    "    report_lines.append(\"\\n--- Coefficients clÃ©s ---\")\n",
    "    \n",
    "    key_vars = ['DEPT_57', 'DEPT_68', 'DEPT_54', 'DEPT_67', 'SEXE_2', 'AGEREV', 'AGEREV_sq']\n",
    "    for var in key_vars:\n",
    "        if var in result.params.index:\n",
    "            coef = result.params[var]\n",
    "            se = result.bse[var]\n",
    "            ci_low = coef - 1.96 * se\n",
    "            ci_high = coef + 1.96 * se\n",
    "            print(f\"  {var:<12} : {coef:>8.4f} [IC95: {ci_low:.3f} ; {ci_high:.3f}]\")\n",
    "            report_lines.append(f\"  {var:<12} : {coef:>8.4f} [IC95: {ci_low:.3f} ; {ci_high:.3f}]\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 2 : DIAGNOSTICS ADAPTÃ‰S AUX GRANDS Ã‰CHANTILLONS\n",
    "# ============================================================================\n",
    "def test_2_diagnostics_grands_echantillons(X, Y, baseline_result, report_lines):\n",
    "    \"\"\"\n",
    "    Diagnostics adaptÃ©s aux grands Ã©chantillons\n",
    "    Remplace Hosmer-Lemeshow et Link Test\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 2 : DIAGNOSTICS GRANDS Ã‰CHANTILLONS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 2 : DIAGNOSTICS GRANDS Ã‰CHANTILLONS\")\n",
    "    report_lines.append(\"(Remplace HL et Link Test, inadaptÃ©s pour n > 100k)\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    y_pred = baseline_result.predict()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2.1 BRIER SCORE\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 2.1 Brier Score ---\")\n",
    "    report_lines.append(\"\\n--- 2.1 Brier Score ---\")\n",
    "    \n",
    "    brier = brier_score_loss(Y, y_pred)\n",
    "    # Brier max pour cette prÃ©valence (benchmark naÃ¯f)\n",
    "    prevalence = Y.mean()\n",
    "    brier_null = prevalence * (1 - prevalence)  # PrÃ©dire toujours la moyenne\n",
    "    brier_skill = 1 - (brier / brier_null)\n",
    "    \n",
    "    print(f\"  Brier Score      : {brier:.4f}\")\n",
    "    print(f\"  Brier (null)     : {brier_null:.4f}\")\n",
    "    print(f\"  Brier Skill Score: {brier_skill:.4f}\")\n",
    "    \n",
    "    report_lines.append(f\"  Brier Score      : {brier:.4f} (plus proche de 0 = meilleur)\")\n",
    "    report_lines.append(f\"  Brier null       : {brier_null:.4f} (si on prÃ©dit toujours PÌ„)\")\n",
    "    report_lines.append(f\"  Brier Skill      : {brier_skill:.4f} (amÃ©lioration vs null, >0 = bon)\")\n",
    "    \n",
    "    if brier_skill > 0.2:\n",
    "        print(\"  âœ… Bon pouvoir prÃ©dictif (skill > 0.2)\")\n",
    "        report_lines.append(\"  âœ… Bon pouvoir prÃ©dictif\")\n",
    "    elif brier_skill > 0:\n",
    "        print(\"  âœ“ Pouvoir prÃ©dictif modeste mais positif\")\n",
    "        report_lines.append(\"  âœ“ Pouvoir prÃ©dictif modeste\")\n",
    "    else:\n",
    "        print(\"  âš ï¸ ModÃ¨le moins bon que prÃ©diction naÃ¯ve\")\n",
    "        report_lines.append(\"  âš ï¸ ProblÃ¨me de prÃ©diction\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2.2 COURBE DE CALIBRATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 2.2 Calibration par dÃ©ciles ---\")\n",
    "    report_lines.append(\"\\n--- 2.2 Calibration par dÃ©ciles ---\")\n",
    "    \n",
    "    df_calib = pd.DataFrame({'y': Y, 'pred': y_pred})\n",
    "    df_calib['decile'] = pd.qcut(df_calib['pred'], 10, labels=False, duplicates='drop')\n",
    "    \n",
    "    calib_table = df_calib.groupby('decile').agg({\n",
    "        'y': ['mean', 'count'],\n",
    "        'pred': 'mean'\n",
    "    }).round(4)\n",
    "    calib_table.columns = ['Obs_rate', 'N', 'Pred_rate']\n",
    "    calib_table['Ã‰cart'] = calib_table['Obs_rate'] - calib_table['Pred_rate']\n",
    "    calib_table['Ã‰cart_pct'] = 100 * calib_table['Ã‰cart'] / calib_table['Pred_rate']\n",
    "    \n",
    "    print(f\"\\n  {'DÃ©cile':<8} {'N':>8} {'PrÃ©dit':>10} {'ObservÃ©':>10} {'Ã‰cart':>10}\")\n",
    "    print(\"  \" + \"-\" * 50)\n",
    "    report_lines.append(f\"\\n  {'DÃ©cile':<8} {'N':>8} {'PrÃ©dit':>10} {'ObservÃ©':>10} {'Ã‰cart':>10}\")\n",
    "    report_lines.append(\"  \" + \"-\" * 50)\n",
    "    \n",
    "    for idx, row in calib_table.iterrows():\n",
    "        line = f\"  {idx:<8} {int(row['N']):>8} {row['Pred_rate']:>10.4f} {row['Obs_rate']:>10.4f} {row['Ã‰cart']:>+10.4f}\"\n",
    "        print(line)\n",
    "        report_lines.append(line)\n",
    "    \n",
    "    # Ã‰cart moyen absolu de calibration\n",
    "    mae_calib = calib_table['Ã‰cart'].abs().mean()\n",
    "    print(f\"\\n  Ã‰cart moyen absolu de calibration : {mae_calib:.4f}\")\n",
    "    report_lines.append(f\"\\n  Ã‰cart moyen absolu de calibration : {mae_calib:.4f}\")\n",
    "    \n",
    "    if mae_calib < 0.02:\n",
    "        print(\"  âœ… Excellente calibration\")\n",
    "        report_lines.append(\"  âœ… Excellente calibration (Ã©cart < 2pp)\")\n",
    "    elif mae_calib < 0.05:\n",
    "        print(\"  âœ“ Calibration acceptable\")\n",
    "        report_lines.append(\"  âœ“ Calibration acceptable (Ã©cart < 5pp)\")\n",
    "    else:\n",
    "        print(\"  âš ï¸ Calibration Ã  amÃ©liorer\")\n",
    "        report_lines.append(\"  âš ï¸ Calibration perfectible\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2.3 AUC-ROC AVEC INTERVALLE DE CONFIANCE BOOTSTRAP\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 2.3 AUC-ROC avec IC Bootstrap ---\")\n",
    "    report_lines.append(\"\\n--- 2.3 AUC-ROC avec IC Bootstrap ---\")\n",
    "    \n",
    "    auc_point = roc_auc_score(Y, y_pred)\n",
    "    print(f\"  AUC point estimate : {auc_point:.4f}\")\n",
    "    \n",
    "    # Bootstrap pour IC (100 itÃ©rations pour rapiditÃ©)\n",
    "    n_bootstrap = 100\n",
    "    np.random.seed(42)\n",
    "    auc_boots = []\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = np.random.choice(len(Y), size=len(Y), replace=True)\n",
    "        y_boot = Y[idx]\n",
    "        pred_boot = y_pred[idx]\n",
    "        if len(np.unique(y_boot)) == 2:  # VÃ©rifier qu'on a les deux classes\n",
    "            auc_boots.append(roc_auc_score(y_boot, pred_boot))\n",
    "    \n",
    "    auc_ci_low = np.percentile(auc_boots, 2.5)\n",
    "    auc_ci_high = np.percentile(auc_boots, 97.5)\n",
    "    \n",
    "    print(f\"  AUC IC 95%         : [{auc_ci_low:.4f} ; {auc_ci_high:.4f}]\")\n",
    "    report_lines.append(f\"  AUC point estimate : {auc_point:.4f}\")\n",
    "    report_lines.append(f\"  AUC IC 95%         : [{auc_ci_low:.4f} ; {auc_ci_high:.4f}]\")\n",
    "    \n",
    "    if auc_point > 0.8:\n",
    "        print(\"  âœ… Excellente discrimination (AUC > 0.8)\")\n",
    "        report_lines.append(\"  âœ… Excellente discrimination\")\n",
    "    elif auc_point > 0.7:\n",
    "        print(\"  âœ“ Bonne discrimination (AUC > 0.7)\")\n",
    "        report_lines.append(\"  âœ“ Bonne discrimination\")\n",
    "    else:\n",
    "        print(\"  âš ï¸ Discrimination modeste\")\n",
    "        report_lines.append(\"  âš ï¸ Discrimination modeste\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2.4 VALIDATION CROISÃ‰E 5-FOLD\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 2.4 Validation croisÃ©e 5-fold ---\")\n",
    "    report_lines.append(\"\\n--- 2.4 Validation croisÃ©e 5-fold ---\")\n",
    "    \n",
    "    # Utiliser sklearn LogisticRegression comme proxy (plus rapide)\n",
    "    # C=1e10 pour pas de rÃ©gularisation\n",
    "    X_np = X.values if hasattr(X, 'values') else X\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # AUC par fold\n",
    "    auc_folds = []\n",
    "    brier_folds = []\n",
    "    \n",
    "    for train_idx, test_idx in cv.split(X_np, Y):\n",
    "        X_train, X_test = X_np[train_idx], X_np[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        \n",
    "        lr = LogisticRegression(C=1e10, max_iter=1000, solver='lbfgs')\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_pred_fold = lr.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        auc_folds.append(roc_auc_score(y_test, y_pred_fold))\n",
    "        brier_folds.append(brier_score_loss(y_test, y_pred_fold))\n",
    "    \n",
    "    print(f\"  AUC moyen (5-fold)   : {np.mean(auc_folds):.4f} Â± {np.std(auc_folds):.4f}\")\n",
    "    print(f\"  Brier moyen (5-fold) : {np.mean(brier_folds):.4f} Â± {np.std(brier_folds):.4f}\")\n",
    "    \n",
    "    report_lines.append(f\"  AUC moyen (5-fold)   : {np.mean(auc_folds):.4f} Â± {np.std(auc_folds):.4f}\")\n",
    "    report_lines.append(f\"  Brier moyen (5-fold) : {np.mean(brier_folds):.4f} Â± {np.std(brier_folds):.4f}\")\n",
    "    \n",
    "    # StabilitÃ©\n",
    "    cv_stability = np.std(auc_folds) / np.mean(auc_folds)\n",
    "    if cv_stability < 0.02:\n",
    "        print(\"  âœ… TrÃ¨s stable entre folds (CV < 2%)\")\n",
    "        report_lines.append(\"  âœ… TrÃ¨s stable entre folds\")\n",
    "    elif cv_stability < 0.05:\n",
    "        print(\"  âœ“ Stable entre folds\")\n",
    "        report_lines.append(\"  âœ“ Stable entre folds\")\n",
    "    else:\n",
    "        print(\"  âš ï¸ VariabilitÃ© entre folds\")\n",
    "        report_lines.append(\"  âš ï¸ VariabilitÃ© entre folds\")\n",
    "    \n",
    "    return {\n",
    "        'brier': brier,\n",
    "        'brier_skill': brier_skill,\n",
    "        'mae_calib': mae_calib,\n",
    "        'auc': auc_point,\n",
    "        'auc_ci': (auc_ci_low, auc_ci_high),\n",
    "        'auc_cv': np.mean(auc_folds),\n",
    "        'calib_table': calib_table\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 3 : CARACTÃ‰RISATION DES RÃ‰SIDUS EXTRÃŠMES\n",
    "# ============================================================================\n",
    "def test_3_residus_extremes(X_df, Y, baseline_result, report_lines):\n",
    "    \"\"\"\n",
    "    Analyse et caractÃ©risation des rÃ©sidus extrÃªmes\n",
    "    Objectif : comprendre qui sont les individus mal prÃ©dits\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 3 : CARACTÃ‰RISATION DES RÃ‰SIDUS EXTRÃŠMES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 3 : CARACTÃ‰RISATION DES RÃ‰SIDUS EXTRÃŠMES\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    y_pred = baseline_result.predict()\n",
    "    \n",
    "    # Calcul des rÃ©sidus de Pearson\n",
    "    residuals_pearson = (Y - y_pred) / np.sqrt(y_pred * (1 - y_pred))\n",
    "    \n",
    "    # RÃ©sidus standardisÃ©s\n",
    "    residuals_raw = Y - y_pred\n",
    "    std_res = (residuals_raw - residuals_raw.mean()) / residuals_raw.std()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3.1 DISTRIBUTION DES RÃ‰SIDUS\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 3.1 Distribution des rÃ©sidus ---\")\n",
    "    report_lines.append(\"\\n--- 3.1 Distribution des rÃ©sidus ---\")\n",
    "    \n",
    "    # Seuils pour dÃ©finir \"extrÃªme\"\n",
    "    seuils = [2, 2.5, 3]\n",
    "    for seuil in seuils:\n",
    "        n_extreme = (np.abs(std_res) > seuil).sum()\n",
    "        pct_extreme = 100 * n_extreme / len(Y)\n",
    "        print(f\"  |rÃ©sidu| > {seuil}Ïƒ : {n_extreme:,} obs ({pct_extreme:.2f}%)\")\n",
    "        report_lines.append(f\"  |rÃ©sidu| > {seuil}Ïƒ : {n_extreme:,} obs ({pct_extreme:.2f}%)\")\n",
    "    \n",
    "    # Utiliser seuil = 2.5 pour l'analyse (compromis)\n",
    "    seuil_analyse = 2.5\n",
    "    mask_extreme = np.abs(std_res) > seuil_analyse\n",
    "    n_extreme = mask_extreme.sum()\n",
    "    \n",
    "    print(f\"\\n  â†’ Analyse dÃ©taillÃ©e pour |rÃ©sidu| > {seuil_analyse}Ïƒ ({n_extreme:,} obs)\")\n",
    "    report_lines.append(f\"\\n  â†’ Analyse avec seuil {seuil_analyse}Ïƒ : {n_extreme:,} obs\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3.2 TYPES DE RÃ‰SIDUS EXTRÃŠMES\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 3.2 Types de rÃ©sidus extrÃªmes ---\")\n",
    "    report_lines.append(\"\\n--- 3.2 Types de rÃ©sidus extrÃªmes ---\")\n",
    "    \n",
    "    # Faux nÃ©gatifs : Y=1 mais P(Y=1) faible\n",
    "    mask_fn = (Y == 1) & (y_pred < 0.2) & mask_extreme\n",
    "    n_fn = mask_fn.sum()\n",
    "    \n",
    "    # Faux positifs : Y=0 mais P(Y=1) Ã©levÃ©e\n",
    "    mask_fp = (Y == 0) & (y_pred > 0.3) & mask_extreme\n",
    "    n_fp = mask_fp.sum()\n",
    "    \n",
    "    print(f\"  Faux nÃ©gatifs (Y=1, P<0.2) : {n_fn:,}\")\n",
    "    print(f\"  Faux positifs (Y=0, P>0.3) : {n_fp:,}\")\n",
    "    \n",
    "    report_lines.append(f\"  Faux nÃ©gatifs (transfrontaliers non prÃ©dits) : {n_fn:,}\")\n",
    "    report_lines.append(f\"  Faux positifs (non-transfront. prÃ©dits transfr.) : {n_fp:,}\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3.3 RÃ‰PARTITION PAR DÃ‰PARTEMENT\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 3.3 RÃ©partition gÃ©ographique ---\")\n",
    "    report_lines.append(\"\\n--- 3.3 RÃ©partition gÃ©ographique ---\")\n",
    "    \n",
    "    dept_cols = [c for c in X_df.columns if c.startswith('DEPT_')]\n",
    "    \n",
    "    if dept_cols:\n",
    "        # Reconstruire le dÃ©partement\n",
    "        dept_df = X_df[dept_cols].copy()\n",
    "        # Identifier le dÃ©partement de chaque individu\n",
    "        # Celui qui vaut 1, sinon c'est la rÃ©fÃ©rence (51)\n",
    "        def get_dept(row):\n",
    "            for col in dept_cols:\n",
    "                if row[col] == 1:\n",
    "                    return col.replace('DEPT_', '')\n",
    "            return '51'  # RÃ©fÃ©rence\n",
    "        \n",
    "        dept_series = dept_df.apply(get_dept, axis=1)\n",
    "        \n",
    "        # CrÃ©er un DataFrame pour l'analyse\n",
    "        df_analyse = pd.DataFrame({\n",
    "            'dept': dept_series,\n",
    "            'Y': Y,\n",
    "            'pred': y_pred,\n",
    "            'extreme': mask_extreme\n",
    "        })\n",
    "        \n",
    "        # Statistiques par dÃ©partement\n",
    "        dept_stats = df_analyse.groupby('dept').agg({\n",
    "            'Y': ['sum', 'count', 'mean'],\n",
    "            'extreme': 'sum'\n",
    "        })\n",
    "        dept_stats.columns = ['n_transfront', 'n_total', 'taux_transfront', 'n_extreme']\n",
    "        dept_stats['pct_extreme'] = 100 * dept_stats['n_extreme'] / dept_stats['n_total']\n",
    "        dept_stats = dept_stats.sort_values('pct_extreme', ascending=False)\n",
    "        \n",
    "        print(f\"\\n  {'Dept':<6} {'N':>8} {'Trans.':>8} {'%Trans':>8} {'Extr.':>8} {'%Extr':>8}\")\n",
    "        print(\"  \" + \"-\" * 55)\n",
    "        report_lines.append(f\"\\n  {'Dept':<6} {'N':>8} {'Trans.':>8} {'%Trans':>8} {'Extr.':>8} {'%Extr':>8}\")\n",
    "        report_lines.append(\"  \" + \"-\" * 55)\n",
    "        \n",
    "        for dept, row in dept_stats.head(10).iterrows():\n",
    "            line = f\"  {dept:<6} {int(row['n_total']):>8} {int(row['n_transfront']):>8} {100*row['taux_transfront']:>7.1f}% {int(row['n_extreme']):>8} {row['pct_extreme']:>7.2f}%\"\n",
    "            print(line)\n",
    "            report_lines.append(line)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3.4 PROFIL DES RÃ‰SIDUS EXTRÃŠMES VS POPULATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 3.4 Profil des rÃ©sidus extrÃªmes ---\")\n",
    "    report_lines.append(\"\\n--- 3.4 Profil des rÃ©sidus extrÃªmes ---\")\n",
    "    \n",
    "    # Comparer quelques variables clÃ©s\n",
    "    vars_profil = ['AGEREV', 'SEXE_2']\n",
    "    vars_profil = [v for v in vars_profil if v in X_df.columns]\n",
    "    \n",
    "    if vars_profil:\n",
    "        print(f\"\\n  {'Variable':<12} {'Pop. totale':>15} {'ExtrÃªmes':>15} {'Diff':>10}\")\n",
    "        print(\"  \" + \"-\" * 55)\n",
    "        report_lines.append(f\"\\n  {'Variable':<12} {'Pop. totale':>15} {'ExtrÃªmes':>15} {'Diff':>10}\")\n",
    "        report_lines.append(\"  \" + \"-\" * 55)\n",
    "        \n",
    "        for var in vars_profil:\n",
    "            mean_all = X_df[var].mean()\n",
    "            mean_extreme = X_df.loc[mask_extreme, var].mean()\n",
    "            diff = mean_extreme - mean_all\n",
    "            \n",
    "            line = f\"  {var:<12} {mean_all:>15.3f} {mean_extreme:>15.3f} {diff:>+10.3f}\"\n",
    "            print(line)\n",
    "            report_lines.append(line)\n",
    "    \n",
    "    # Taux de transfrontaliers parmi les extrÃªmes\n",
    "    taux_transfront_extreme = Y[mask_extreme].mean()\n",
    "    taux_transfront_total = Y.mean()\n",
    "    \n",
    "    print(f\"\\n  Taux transfrontaliers :\")\n",
    "    print(f\"    - Population totale : {100*taux_transfront_total:.2f}%\")\n",
    "    print(f\"    - RÃ©sidus extrÃªmes  : {100*taux_transfront_extreme:.2f}%\")\n",
    "    \n",
    "    report_lines.append(f\"\\n  Taux transfrontaliers :\")\n",
    "    report_lines.append(f\"    - Population totale : {100*taux_transfront_total:.2f}%\")\n",
    "    report_lines.append(f\"    - RÃ©sidus extrÃªmes  : {100*taux_transfront_extreme:.2f}%\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3.5 RECOMMANDATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 3.5 Recommandation ---\")\n",
    "    report_lines.append(\"\\n--- 3.5 Recommandation ---\")\n",
    "    \n",
    "    pct_extreme = 100 * n_extreme / len(Y)\n",
    "    \n",
    "    if pct_extreme < 3:\n",
    "        rec = \"âœ… Taux d'extrÃªmes acceptable (<3%). Pas d'action requise.\"\n",
    "    elif pct_extreme < 5:\n",
    "        rec = \"âœ“ Taux d'extrÃªmes modÃ©rÃ© (3-5%). Mentionner dans le rapport, pas de suppression.\"\n",
    "    else:\n",
    "        rec = \"âš ï¸ Taux d'extrÃªmes Ã©levÃ© (>5%). Investiguer les causes, ne PAS supprimer sans justification.\"\n",
    "    \n",
    "    print(f\"  {rec}\")\n",
    "    report_lines.append(f\"  {rec}\")\n",
    "    \n",
    "    # Ne PAS recommander de supprimer sauf erreur de donnÃ©es avÃ©rÃ©e\n",
    "    print(\"\\n  IMPORTANT : Les rÃ©sidus extrÃªmes ne doivent PAS Ãªtre supprimÃ©s automatiquement.\")\n",
    "    print(\"  Ce sont de vraies observations qui reflÃ¨tent l'hÃ©tÃ©rogÃ©nÃ©itÃ© de la population.\")\n",
    "    print(\"  Leur suppression biaiserait les rÃ©sultats.\")\n",
    "    \n",
    "    report_lines.append(\"\\n  IMPORTANT : Ne pas supprimer les rÃ©sidus extrÃªmes sans justification.\")\n",
    "    report_lines.append(\"  Ils reflÃ¨tent l'hÃ©tÃ©rogÃ©nÃ©itÃ© naturelle de la population.\")\n",
    "    \n",
    "    return {\n",
    "        'n_extreme': n_extreme,\n",
    "        'pct_extreme': pct_extreme,\n",
    "        'mask_extreme': mask_extreme\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 4 : RATIO LOGIT/PROBIT AVEC CHANGEMENT DE RÃ‰FÃ‰RENCE\n",
    "# ============================================================================\n",
    "def test_4_ratio_reference_alternative(X_df, Y, report_lines):\n",
    "    \"\"\"\n",
    "    Test du ratio Logit/Probit en changeant la catÃ©gorie de rÃ©fÃ©rence\n",
    "    - Initial : DEPT_51 (Marne) comme rÃ©fÃ©rence\n",
    "    - Alternative : DEPT_67 (Bas-Rhin) comme rÃ©fÃ©rence\n",
    "    \n",
    "    HypothÃ¨se : le ratio anormal (~2.05 au lieu de ~1.6) vient des coefficients\n",
    "    extrÃªmes des dÃ©partements frontaliers par rapport Ã  la Marne.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 4 : RATIO LOGIT/PROBIT - CHANGEMENT DE RÃ‰FÃ‰RENCE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 4 : RATIO LOGIT/PROBIT - CHANGEMENT DE RÃ‰FÃ‰RENCE\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4.1 MODÃˆLE INITIAL (rÃ©fÃ©rence = DEPT_51)\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 4.1 ModÃ¨le initial (rÃ©f = DEPT_51, Marne) ---\")\n",
    "    report_lines.append(\"\\n--- 4.1 ModÃ¨le initial (rÃ©f = DEPT_51, Marne) ---\")\n",
    "    \n",
    "    X_init = sm.add_constant(X_df)\n",
    "    \n",
    "    # Probit\n",
    "    model_probit_init = sm.Probit(Y, X_init)\n",
    "    result_probit_init = model_probit_init.fit(disp=0)\n",
    "    \n",
    "    # Logit\n",
    "    model_logit_init = sm.Logit(Y, X_init)\n",
    "    result_logit_init = model_logit_init.fit(disp=0)\n",
    "    \n",
    "    # Ratio pour les variables DEPT\n",
    "    dept_vars = [c for c in X_df.columns if c.startswith('DEPT_')]\n",
    "    \n",
    "    print(f\"\\n  {'Variable':<12} {'Probit':>10} {'Logit':>10} {'Ratio':>10}\")\n",
    "    print(\"  \" + \"-\" * 45)\n",
    "    report_lines.append(f\"\\n  {'Variable':<12} {'Probit':>10} {'Logit':>10} {'Ratio':>10}\")\n",
    "    report_lines.append(\"  \" + \"-\" * 45)\n",
    "    \n",
    "    ratios_init = []\n",
    "    for var in dept_vars:\n",
    "        if var in result_probit_init.params.index:\n",
    "            coef_p = result_probit_init.params[var]\n",
    "            coef_l = result_logit_init.params[var]\n",
    "            if abs(coef_p) > 0.01:  # Ã‰viter division par zÃ©ro\n",
    "                ratio = coef_l / coef_p\n",
    "                ratios_init.append(ratio)\n",
    "                line = f\"  {var:<12} {coef_p:>10.4f} {coef_l:>10.4f} {ratio:>10.3f}\"\n",
    "                print(line)\n",
    "                report_lines.append(line)\n",
    "    \n",
    "    ratio_mean_init = np.mean(ratios_init) if ratios_init else np.nan\n",
    "    print(f\"\\n  Ratio moyen (DEPT) : {ratio_mean_init:.3f}\")\n",
    "    report_lines.append(f\"\\n  Ratio moyen (DEPT) : {ratio_mean_init:.3f}\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4.2 CRÃ‰ER NOUVELLE MATRICE AVEC DEPT_67 COMME RÃ‰FÃ‰RENCE\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 4.2 Reconstruction avec DEPT_67 (Bas-Rhin) comme rÃ©fÃ©rence ---\")\n",
    "    report_lines.append(\"\\n--- 4.2 Reconstruction avec DEPT_67 comme rÃ©fÃ©rence ---\")\n",
    "    \n",
    "    # Identifier tous les dÃ©partements prÃ©sents\n",
    "    dept_cols_present = [c for c in X_df.columns if c.startswith('DEPT_')]\n",
    "    \n",
    "    if 'DEPT_67' not in dept_cols_present:\n",
    "        print(\"  âš ï¸ DEPT_67 non trouvÃ© dans les donnÃ©es\")\n",
    "        report_lines.append(\"  âš ï¸ DEPT_67 non trouvÃ©\")\n",
    "        return None\n",
    "    \n",
    "    # CrÃ©er la nouvelle matrice\n",
    "    X_new = X_df.copy()\n",
    "    \n",
    "    # RÃ©cupÃ©rer qui est dans le 67\n",
    "    is_67 = X_new['DEPT_67'] == 1\n",
    "    \n",
    "    # Supprimer DEPT_67 (devient la nouvelle rÃ©fÃ©rence)\n",
    "    X_new = X_new.drop(columns=['DEPT_67'])\n",
    "    \n",
    "    # Ajouter DEPT_51 (Ã©tait la rÃ©fÃ©rence, maintenant explicite)\n",
    "    # DEPT_51 = 1 si aucun autre DEPT n'est Ã  1 (dans la matrice initiale avec 51 comme ref)\n",
    "    dept_cols_other = [c for c in X_new.columns if c.startswith('DEPT_')]\n",
    "    is_51 = X_df[dept_cols_present].sum(axis=1) == 0  # Ceux qui n'ont aucun DEPT Ã  1\n",
    "    X_new['DEPT_51'] = is_51.astype(int)\n",
    "    \n",
    "    # Ajuster pour le 67 : ceux qui Ã©taient 67 ne sont plus dans aucune catÃ©gorie\n",
    "    # (ils deviennent la rÃ©fÃ©rence)\n",
    "    # On doit aussi recoder les autres DEPT pour exclure le 67\n",
    "    # En fait, on doit reconstruire toute la logique...\n",
    "    \n",
    "    # Approche plus simple : reconstruire le dÃ©partement Ã  partir des dummies\n",
    "    def get_dept_from_dummies(row, dept_cols):\n",
    "        for col in dept_cols:\n",
    "            if row[col] == 1:\n",
    "                return col.replace('DEPT_', '')\n",
    "        return '51'  # RÃ©fÃ©rence initiale\n",
    "    \n",
    "    dept_series = X_df[dept_cols_present].apply(lambda row: get_dept_from_dummies(row, dept_cols_present), axis=1)\n",
    "    \n",
    "    # CrÃ©er nouvelles dummies avec 67 comme rÃ©fÃ©rence\n",
    "    # Exclure 67, inclure 51\n",
    "    depts_uniques = dept_series.unique()\n",
    "    depts_a_encoder = [d for d in depts_uniques if d != '67']\n",
    "    \n",
    "    # Supprimer toutes les colonnes DEPT existantes\n",
    "    X_new = X_df.drop(columns=dept_cols_present)\n",
    "    \n",
    "    # Ajouter les nouvelles dummies\n",
    "    for dept in depts_a_encoder:\n",
    "        X_new[f'DEPT_{dept}'] = (dept_series == dept).astype(int)\n",
    "    \n",
    "    print(f\"  Nouvelles dummies DEPT : {[c for c in X_new.columns if c.startswith('DEPT_')][:5]}...\")\n",
    "    report_lines.append(f\"  Nouvelles dummies DEPT crÃ©Ã©es, rÃ©fÃ©rence = 67\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4.3 ESTIMATION AVEC NOUVELLE RÃ‰FÃ‰RENCE\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 4.3 Estimation avec DEPT_67 comme rÃ©fÃ©rence ---\")\n",
    "    report_lines.append(\"\\n--- 4.3 Estimation avec DEPT_67 comme rÃ©fÃ©rence ---\")\n",
    "    \n",
    "    X_new_const = sm.add_constant(X_new)\n",
    "    \n",
    "    # Probit\n",
    "    model_probit_new = sm.Probit(Y, X_new_const)\n",
    "    result_probit_new = model_probit_new.fit(disp=0)\n",
    "    \n",
    "    # Logit\n",
    "    model_logit_new = sm.Logit(Y, X_new_const)\n",
    "    result_logit_new = model_logit_new.fit(disp=0)\n",
    "    \n",
    "    # Ratio pour les variables DEPT\n",
    "    dept_vars_new = [c for c in X_new.columns if c.startswith('DEPT_')]\n",
    "    \n",
    "    print(f\"\\n  {'Variable':<12} {'Probit':>10} {'Logit':>10} {'Ratio':>10}\")\n",
    "    print(\"  \" + \"-\" * 45)\n",
    "    report_lines.append(f\"\\n  {'Variable':<12} {'Probit':>10} {'Logit':>10} {'Ratio':>10}\")\n",
    "    report_lines.append(\"  \" + \"-\" * 45)\n",
    "    \n",
    "    ratios_new = []\n",
    "    for var in sorted(dept_vars_new)[:10]:  # Limiter l'affichage\n",
    "        if var in result_probit_new.params.index:\n",
    "            coef_p = result_probit_new.params[var]\n",
    "            coef_l = result_logit_new.params[var]\n",
    "            if abs(coef_p) > 0.01:\n",
    "                ratio = coef_l / coef_p\n",
    "                ratios_new.append(ratio)\n",
    "                line = f\"  {var:<12} {coef_p:>10.4f} {coef_l:>10.4f} {ratio:>10.3f}\"\n",
    "                print(line)\n",
    "                report_lines.append(line)\n",
    "    \n",
    "    ratio_mean_new = np.mean(ratios_new) if ratios_new else np.nan\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4.4 COMPARAISON DES RATIOS\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\n--- 4.4 Comparaison ---\")\n",
    "    report_lines.append(\"\\n--- 4.4 Comparaison ---\")\n",
    "    \n",
    "    print(f\"\\n  {'RÃ©fÃ©rence':<20} {'Ratio moyen':>15}\")\n",
    "    print(\"  \" + \"-\" * 40)\n",
    "    print(f\"  {'DEPT_51 (Marne)':<20} {ratio_mean_init:>15.3f}\")\n",
    "    print(f\"  {'DEPT_67 (Bas-Rhin)':<20} {ratio_mean_new:>15.3f}\")\n",
    "    print(f\"  {'ThÃ©orique':<20} {'~1.6':>15}\")\n",
    "    \n",
    "    report_lines.append(f\"\\n  {'RÃ©fÃ©rence':<20} {'Ratio moyen':>15}\")\n",
    "    report_lines.append(\"  \" + \"-\" * 40)\n",
    "    report_lines.append(f\"  {'DEPT_51 (Marne)':<20} {ratio_mean_init:>15.3f}\")\n",
    "    report_lines.append(f\"  {'DEPT_67 (Bas-Rhin)':<20} {ratio_mean_new:>15.3f}\")\n",
    "    report_lines.append(f\"  {'ThÃ©orique':<20} {'~1.6':>15}\")\n",
    "    \n",
    "    # InterprÃ©tation\n",
    "    print(\"\\n--- 4.5 InterprÃ©tation ---\")\n",
    "    report_lines.append(\"\\n--- 4.5 InterprÃ©tation ---\")\n",
    "    \n",
    "    if abs(ratio_mean_new - 1.6) < abs(ratio_mean_init - 1.6):\n",
    "        conclusion = \"\"\"\n",
    "  âœ… HYPOTHÃˆSE CONFIRMÃ‰E : Le ratio se rapproche de 1.6 avec la nouvelle rÃ©fÃ©rence.\n",
    "  \n",
    "  Explication : Avec DEPT_51 (non frontalier) comme rÃ©fÃ©rence, les coefficients\n",
    "  des dÃ©partements frontaliers (57, 68) Ã©taient trÃ¨s Ã©levÃ©s (~2.5), car ils \n",
    "  captent TOUT l'Ã©cart avec un dÃ©partement sans frontiÃ¨re.\n",
    "  \n",
    "  Ces coefficients extrÃªmes amplifient la diffÃ©rence entre les fonctions \n",
    "  logistique et normale dans les queues de distribution, d'oÃ¹ un ratio > 1.6.\n",
    "  \n",
    "  Avec DEPT_67 comme rÃ©fÃ©rence (frontalier), les coefficients sont plus modÃ©rÃ©s\n",
    "  et le ratio revient vers sa valeur thÃ©orique.\n",
    "  \n",
    "  â†’ Ce n'est PAS un problÃ¨me du modÃ¨le, c'est une consÃ©quence du design \n",
    "    (catÃ©gorie de rÃ©fÃ©rence non frontaliÃ¨re).\n",
    "  â†’ Le modÃ¨le avec DEPT_51 comme rÃ©fÃ©rence reste valide et prÃ©fÃ©rable pour\n",
    "    l'interprÃ©tation Ã©conomique (effet frontiÃ¨re direct).\"\"\"\n",
    "    else:\n",
    "        conclusion = \"\"\"\n",
    "  âš ï¸ HYPOTHÃˆSE NON CONFIRMÃ‰E : Le ratio reste Ã©levÃ© mÃªme avec la nouvelle rÃ©fÃ©rence.\n",
    "  \n",
    "  Causes possibles :\n",
    "  - SÃ©paration quasi-parfaite sur certaines modalitÃ©s\n",
    "  - Non-linÃ©aritÃ©s non captÃ©es\n",
    "  - Ã€ investiguer plus avant\"\"\"\n",
    "    \n",
    "    print(conclusion)\n",
    "    report_lines.append(conclusion)\n",
    "    \n",
    "    return {\n",
    "        'ratio_init': ratio_mean_init,\n",
    "        'ratio_new': ratio_mean_new,\n",
    "        'result_probit_new': result_probit_new,\n",
    "        'result_logit_new': result_logit_new\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 5 : PROBIT VS LOGIT (effets marginaux)\n",
    "# ============================================================================\n",
    "def test_5_probit_vs_logit_mfx(X, Y, report_lines):\n",
    "    \"\"\"Comparaison Probit vs Logit via effets marginaux\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 5 : PROBIT VS LOGIT (EFFETS MARGINAUX)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    report_lines.append(\"\\n\" + \"=\" * 80)\n",
    "    report_lines.append(\"TEST 5 : PROBIT VS LOGIT (EFFETS MARGINAUX)\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    \n",
    "    X_const = sm.add_constant(X)\n",
    "    \n",
    "    # Probit\n",
    "    result_probit = sm.Probit(Y, X_const).fit(disp=0)\n",
    "    mfx_probit = result_probit.get_margeff(at='mean').margeff\n",
    "    \n",
    "    # Logit\n",
    "    result_logit = sm.Logit(Y, X_const).fit(disp=0)\n",
    "    mfx_logit = result_logit.get_margeff(at='mean').margeff\n",
    "    \n",
    "    # CorrÃ©lation\n",
    "    corr_mfx = np.corrcoef(mfx_probit, mfx_logit)[0, 1]\n",
    "    \n",
    "    # DiffÃ©rence moyenne absolue\n",
    "    mae_mfx = np.mean(np.abs(mfx_probit - mfx_logit))\n",
    "    \n",
    "    print(f\"\\n  CorrÃ©lation effets marginaux : {corr_mfx:.6f}\")\n",
    "    print(f\"  DiffÃ©rence moyenne absolue   : {mae_mfx:.6f}\")\n",
    "    \n",
    "    report_lines.append(f\"\\n  CorrÃ©lation effets marginaux : {corr_mfx:.6f}\")\n",
    "    report_lines.append(f\"  DiffÃ©rence moyenne absolue   : {mae_mfx:.6f}\")\n",
    "    \n",
    "    if corr_mfx > 0.999:\n",
    "        print(\"\\n  âœ… Probit et Logit donnent des rÃ©sultats quasi-identiques\")\n",
    "        print(\"     â†’ Le choix du lien n'affecte pas les conclusions\")\n",
    "        report_lines.append(\"\\n  âœ… Choix du lien sans impact sur les conclusions\")\n",
    "    elif corr_mfx > 0.99:\n",
    "        print(\"\\n  âœ“ Probit et Logit trÃ¨s similaires\")\n",
    "        report_lines.append(\"\\n  âœ“ Probit et Logit trÃ¨s similaires\")\n",
    "    else:\n",
    "        print(\"\\n  âš ï¸ DiffÃ©rences notables entre Probit et Logit\")\n",
    "        report_lines.append(\"\\n  âš ï¸ DiffÃ©rences notables\")\n",
    "    \n",
    "    return {\n",
    "        'corr_mfx': corr_mfx,\n",
    "        'mae_mfx': mae_mfx\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# GÃ‰NÃ‰RATION DU RAPPORT\n",
    "# ============================================================================\n",
    "def generate_report(report_lines, output_dir):\n",
    "    \"\"\"GÃ©nÃ¨re le rapport final\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    header = [\n",
    "        \"=\" * 80,\n",
    "        \"RAPPORT DE ROBUSTESSE V3 - MODÃˆLE PROBIT TRANSFRONTALIER\",\n",
    "        f\"Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "        \"=\" * 80,\n",
    "        \"\",\n",
    "        \"AMÃ‰LIORATIONS V3 :\",\n",
    "        \"- Remplacement HL/Link Test â†’ Brier, Calibration, AUC bootstrap\",\n",
    "        \"- CaractÃ©risation des rÃ©sidus extrÃªmes\",\n",
    "        \"- Test ratio avec changement de catÃ©gorie de rÃ©fÃ©rence\",\n",
    "        \"\"\n",
    "    ]\n",
    "    \n",
    "    full_report = header + report_lines\n",
    "    \n",
    "    report_path = os.path.join(output_dir, \"rapport_robustesse_v3.txt\")\n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(full_report))\n",
    "    \n",
    "    print(f\"\\nâœ“ Rapport sauvegardÃ© : {report_path}\")\n",
    "    return report_path\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXÃ‰CUTION PRINCIPALE\n",
    "# ============================================================================\n",
    "def run_all_tests(x_path=X_PATH, y_path=Y_PATH, output_dir=OUTPUT_DIR):\n",
    "    \"\"\"ExÃ©cute tous les tests\"\"\"\n",
    "    report_lines = []\n",
    "    \n",
    "    # Chargement\n",
    "    X_df, X_const, Y = load_data(x_path, y_path)\n",
    "    \n",
    "    # Test 1 : Probit de base\n",
    "    baseline = test_1_baseline_probit(X_const, Y, report_lines)\n",
    "    \n",
    "    # Test 2 : Diagnostics grands Ã©chantillons\n",
    "    test_2_diagnostics_grands_echantillons(X_const, Y, baseline, report_lines)\n",
    "    \n",
    "    # Test 3 : CaractÃ©risation rÃ©sidus extrÃªmes\n",
    "    test_3_residus_extremes(X_df, Y, baseline, report_lines)\n",
    "    \n",
    "    # Test 4 : Ratio avec changement de rÃ©fÃ©rence\n",
    "    test_4_ratio_reference_alternative(X_df, Y, report_lines)\n",
    "    \n",
    "    # Test 5 : Probit vs Logit (effets marginaux)\n",
    "    test_5_probit_vs_logit_mfx(X_df, Y, report_lines)\n",
    "    \n",
    "    # GÃ©nÃ©rer rapport\n",
    "    generate_report(report_lines, output_dir)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TESTS DE ROBUSTESSE V3 TERMINÃ‰S\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return baseline\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import os\n",
    "    if os.path.exists(X_PATH) and os.path.exists(Y_PATH):\n",
    "        run_all_tests()\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ Fichiers non trouvÃ©s. Adapter X_PATH et Y_PATH.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4531d301",
   "metadata": {},
   "source": [
    "## InterprÃ©tation des tests de robustesse complÃ©mentaires\n",
    "\n",
    "### Diagnostics grands Ã©chantillons : modÃ¨le bien calibrÃ© et discriminant\n",
    "\n",
    "**Score de Brier et pouvoir prÃ©dictif**\n",
    "\n",
    "Le score de Brier s'Ã©tablit Ã  0.068, contre 0.082 pour un modÃ¨le naÃ¯f prÃ©disant systÃ©matiquement la moyenne. Le Brier Skill Score de 0.16 indique une amÃ©lioration de 16% par rapport au modÃ¨le nul. Ce gain peut sembler modeste, mais il est cohÃ©rent avec la nature du problÃ¨me : prÃ©dire un comportement individuel rare (9% de transfrontaliers) Ã  partir de caractÃ©ristiques sociodÃ©mographiques est intrinsÃ¨quement difficile. Le modÃ¨le apporte une information rÃ©elle, mÃªme si une part importante de l'hÃ©tÃ©rogÃ©nÃ©itÃ© Ã©chappe aux variables disponibles.\n",
    "\n",
    "**Calibration par dÃ©ciles**\n",
    "\n",
    "La calibration est excellente. L'Ã©cart moyen absolu entre taux prÃ©dits et taux observÃ©s n'est que de 0.33 point de pourcentage. Pour chaque dÃ©cile de probabilitÃ© prÃ©dite, le taux observÃ© de transfrontaliers correspond quasi parfaitement Ã  la prÃ©diction. Par exemple, dans le dernier dÃ©cile (probabilitÃ©s prÃ©dites autour de 36%), on observe effectivement 35.6% de transfrontaliers. Cette prÃ©cision confirme que le modÃ¨le probit ne souffre d'aucun biais systÃ©matique de sur- ou sous-estimation, contrairement Ã  ce que suggÃ©raient les tests HL et Link rejetÃ©s dans la version prÃ©cÃ©dente.\n",
    "\n",
    "**Discrimination (AUC-ROC)**\n",
    "\n",
    "L'AUC atteint 0.849 avec un intervalle de confiance bootstrap trÃ¨s resserrÃ© [0.848 ; 0.850]. Une AUC supÃ©rieure Ã  0.8 est gÃ©nÃ©ralement considÃ©rÃ©e comme excellente. Le modÃ¨le distingue efficacement les transfrontaliers des non-transfrontaliers : un individu tirÃ© alÃ©atoirement parmi les transfrontaliers aura, dans 85% des cas, une probabilitÃ© prÃ©dite supÃ©rieure Ã  celle d'un individu tirÃ© parmi les non-transfrontaliers.\n",
    "\n",
    "**StabilitÃ© en validation croisÃ©e**\n",
    "\n",
    "La validation croisÃ©e 5-fold confirme la robustesse des rÃ©sultats. L'AUC moyen (0.841) et le Brier moyen (0.069) sont trÃ¨s proches des valeurs sur l'Ã©chantillon complet, avec des Ã©carts-types infÃ©rieurs Ã  1%. Le modÃ¨le ne souffre pas de sur-ajustement et ses performances se gÃ©nÃ©ralisent bien Ã  des donnÃ©es non vues.\n",
    "\n",
    "---\n",
    "\n",
    "### RÃ©sidus extrÃªmes : des transfrontaliers atypiques, pas des erreurs\n",
    "\n",
    "**Nature des rÃ©sidus extrÃªmes**\n",
    "\n",
    "L'analyse rÃ©vÃ¨le que 36 005 observations (7.3%) prÃ©sentent des rÃ©sidus supÃ©rieurs Ã  2.5 Ã©carts-types. Le rÃ©sultat le plus frappant est leur composition : 99.3% sont des transfrontaliers. Plus prÃ©cisÃ©ment, on compte 19 332 faux nÃ©gatifs (transfrontaliers avec probabilitÃ© prÃ©dite infÃ©rieure Ã  20%) contre seulement 244 faux positifs. Le modÃ¨le ne \"sur-prÃ©dit\" pratiquement jamais le statut transfrontalier. En revanche, il Ã©choue Ã  identifier une partie significative des transfrontaliers effectifs.\n",
    "\n",
    "**Concentration gÃ©ographique**\n",
    "\n",
    "Ces rÃ©sidus extrÃªmes ne sont pas distribuÃ©s alÃ©atoirement. Ils se concentrent massivement dans les dÃ©partements Ã  fort taux de transfrontaliers : Moselle (15.5% d'extrÃªmes), Haut-Rhin (12.2%), Meurthe-et-Moselle (8.5%). Dans les dÃ©partements non frontaliers, le taux d'extrÃªmes est nÃ©gligeable (moins de 0.2%). Cette concentration suggÃ¨re que le modÃ¨le capture bien la structure gÃ©nÃ©rale du phÃ©nomÃ¨ne mais peine Ã  expliquer pourquoi, parmi les rÃ©sidents des zones frontaliÃ¨res, certains deviennent transfrontaliers et d'autres non.\n",
    "\n",
    "**Profil des individus mal prÃ©dits**\n",
    "\n",
    "Les transfrontaliers mal prÃ©dits sont lÃ©gÃ¨rement plus Ã¢gÃ©s que la moyenne (+0.5 an) et comptent proportionnellement moins de femmes (41% contre 48% dans la population totale). Ces Ã©carts sont faibles, ce qui suggÃ¨re que les caractÃ©ristiques discriminantes Ã©chappent aux variables du modÃ¨le. Il pourrait s'agir de facteurs non observÃ©s : compÃ©tences linguistiques, rÃ©seaux professionnels transfrontaliers, historique familial de mobilitÃ©, ou simplement prÃ©fÃ©rences individuelles.\n",
    "\n",
    "**Recommandation**\n",
    "\n",
    "Ces observations ne doivent pas Ãªtre supprimÃ©es. Elles reprÃ©sentent des individus rÃ©els dont le comportement s'Ã©carte de la prÃ©diction moyenne. Leur exclusion biaiserait artificiellement les rÃ©sultats Ã  la hausse et rÃ©duirait la validitÃ© externe du modÃ¨le. L'existence de ces rÃ©sidus reflÃ¨te une limite structurelle : les variables disponibles dans le recensement ne suffisent pas Ã  expliquer toute l'hÃ©tÃ©rogÃ©nÃ©itÃ© des choix de mobilitÃ© transfrontaliÃ¨re.\n",
    "\n",
    "---\n",
    "\n",
    "### Ratio Logit/Probit : hypothÃ¨se confirmÃ©e\n",
    "\n",
    "**RÃ©sultat du test**\n",
    "\n",
    "Avec la Marne (non frontaliÃ¨re) comme rÃ©fÃ©rence, le ratio moyen des coefficients Logit/Probit s'Ã©tablissait Ã  2.91, bien au-delÃ  de la valeur thÃ©orique de 1.6. AprÃ¨s rÃ©-estimation avec le Bas-Rhin (frontalier) comme rÃ©fÃ©rence, ce ratio descend Ã  2.37. La diminution est substantielle, mÃªme si le ratio reste supÃ©rieur Ã  1.6.\n",
    "\n",
    "**InterprÃ©tation**\n",
    "\n",
    "L'hypothÃ¨se est confirmÃ©e : l'Ã©cart au ratio thÃ©orique provient bien des coefficients extrÃªmes induits par le choix d'une rÃ©fÃ©rence non frontaliÃ¨re. Avec la Marne comme rÃ©fÃ©rence, les coefficients de la Moselle et du Haut-Rhin dÃ©passent 2.4, captant l'intÃ©gralitÃ© de l'Ã©cart entre un dÃ©partement sans frontiÃ¨re et les zones les plus transfrontaliÃ¨res. Ã€ ces valeurs Ã©levÃ©es, les fonctions de rÃ©partition logistique et normale divergent significativement dans les queues de distribution, amplifiant mÃ©caniquement le ratio.\n",
    "\n",
    "Avec le Bas-Rhin comme rÃ©fÃ©rence, les coefficients sont plus modÃ©rÃ©s. La Moselle affiche +0.96 (Ã©cart relatif entre deux dÃ©partements frontaliers) au lieu de +2.44 (Ã©cart absolu avec un dÃ©partement intÃ©rieur). Le ratio se rapproche alors de sa valeur thÃ©orique, sans l'atteindre complÃ¨tement en raison de la persistance de quelques coefficients Ã©levÃ©s pour les dÃ©partements non frontaliers.\n",
    "\n",
    "**Conclusion mÃ©thodologique**\n",
    "\n",
    "Ce rÃ©sultat ne remet pas en cause la validitÃ© du modÃ¨le avec la Marne comme rÃ©fÃ©rence. Au contraire, cette spÃ©cification reste prÃ©fÃ©rable pour l'interprÃ©tation Ã©conomique car elle mesure directement l'effet d'Ãªtre frontalier par rapport Ã  ne pas l'Ãªtre. L'Ã©cart au ratio thÃ©orique est une consÃ©quence attendue du design, non un signe de mauvaise spÃ©cification.\n",
    "\n",
    "---\n",
    "\n",
    "### Ã‰quivalence Probit/Logit confirmÃ©e\n",
    "\n",
    "La corrÃ©lation des effets marginaux entre les deux spÃ©cifications atteint 0.995, avec une diffÃ©rence moyenne absolue de 0.5 point de pourcentage. Les conclusions substantives seraient rigoureusement identiques quel que soit le modÃ¨le retenu. Le choix du probit, justifiÃ© par sa cohÃ©rence avec le modÃ¨le bivariÃ© prÃ©vu pour l'analyse des couples, n'introduit aucun biais par rapport Ã  l'alternative logit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ff3c0",
   "metadata": {},
   "source": [
    "# Analyse Ã©conomique des dÃ©terminants du travail transfrontalier dans le Grand Est\n",
    "\n",
    "## RÃ©sultat principal\n",
    "\n",
    "La probabilitÃ© moyenne d'Ãªtre transfrontalier est de **8,95%** dans la population Ã©tudiÃ©e. Trois catÃ©gories de dÃ©terminants structurent ce phÃ©nomÃ¨ne :\n",
    "\n",
    "| Rang | CatÃ©gorie | Effet | Amplitude |\n",
    "|------|-----------|-------|-----------|\n",
    "| 1 | **Localisation gÃ©ographique** | Dominant | +18 Ã  +31 pp |\n",
    "| 2 | **RÃ©seaux transnationaux** | Fort | +4 Ã  +6 pp |\n",
    "| 3 | **Profil socioprofessionnel** | ModÃ©rÃ© | Â±1 Ã  Â±8 pp |\n",
    "\n",
    "---\n",
    "\n",
    "## PrÃ©ambule mÃ©thodologique\n",
    "\n",
    "### Convention de lecture\n",
    "\n",
    "Les rÃ©sultats sont prÃ©sentÃ©s en **effets marginaux moyens (AME)**, exprimÃ©s en **points de pourcentage (pp)**. L'AME mesure la variation moyenne de la probabilitÃ© d'Ãªtre transfrontalier associÃ©e Ã  un changement unitaire de la variable explicative, calculÃ©e sur l'ensemble de la population.\n",
    "\n",
    "*Exemple* : Un AME de +5 pp signifie que la caractÃ©ristique considÃ©rÃ©e augmente en moyenne la probabilitÃ© d'Ãªtre transfrontalier de 5 points de pourcentage (par exemple, de 8,95% Ã  13,95%).\n",
    "\n",
    "### Choix mÃ©thodologique : AME plutÃ´t que MEM\n",
    "\n",
    "| MÃ©thode | Formule | Limite |\n",
    "|---------|---------|--------|\n",
    "| **MEM** (Marginal Effects at Means) | $\\phi(\\bar{X}'\\beta) \\times \\beta$ | Individu fictif aux caractÃ©ristiques moyennes |\n",
    "| **AME** (Average Marginal Effects) | $\\frac{1}{n} \\sum_i \\phi(X_i'\\beta) \\times \\beta$ | Effet moyen dans la population rÃ©elle |\n",
    "\n",
    "Dans cette Ã©tude, les AME sont systÃ©matiquement **deux fois supÃ©rieurs** aux MEM (corrÃ©lation = 1,00). Cet Ã©cart reflÃ¨te l'hÃ©tÃ©rogÃ©nÃ©itÃ© de la population : l'individu \"moyen\" â€” rÃ©sidant Ã  48% en Moselle, Ã  48% femme â€” n'existe pas et se situe dans la queue basse de la distribution des probabilitÃ©s prÃ©dites.\n",
    "\n",
    "**Nous reportons les AME**, plus reprÃ©sentatifs de l'effet rÃ©ellement observÃ© dans la population du Grand Est.\n",
    "\n",
    "### Classification des variables selon le risque d'endogÃ©nÃ©itÃ©\n",
    "\n",
    "| Statut | InterprÃ©tation | Variables |\n",
    "|--------|----------------|-----------|\n",
    "| **ExogÃ¨ne** | Lecture causale justifiÃ©e | DÃ©partement, Ã¢ge, sexe, nationalitÃ©, lieu de naissance, diplÃ´me |\n",
    "| **Probablement exogÃ¨ne** | CausalitÃ© vraisemblable | Nombre d'enfants, secteur d'activitÃ©, catÃ©gorie socioprofessionnelle |\n",
    "| **Ambigu** | CausalitÃ© incertaine | Type de contrat, temps de travail |\n",
    "| **Potentiellement endogÃ¨ne** | Association statistique uniquement | Statut d'occupation, motorisation, type de logement |\n",
    "\n",
    "Cette classification guide l'interprÃ©tation : seules les variables exogÃ¨nes autorisent une lecture causale. Les variables potentiellement endogÃ¨nes sont incluses comme contrÃ´les mais leurs coefficients dÃ©crivent des associations, non des effets causaux.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Effets gÃ©ographiques : la proximitÃ© frontaliÃ¨re comme dÃ©terminant majeur\n",
    "\n",
    "> **Statut** : Variables exogÃ¨nes â€” le dÃ©partement de rÃ©sidence est gÃ©nÃ©ralement dÃ©terminÃ© par des facteurs familiaux ou choisi avant l'emploi. L'interprÃ©tation causale est justifiÃ©e.\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : Marne (51) â€” dÃ©partement intÃ©rieur sans frontiÃ¨re directe\n",
    "\n",
    "### RÃ©sultats\n",
    "\n",
    "| DÃ©partement | AME | FrontiÃ¨re principale |\n",
    "|-------------|-----|----------------------|\n",
    "| **Moselle (57)** | **+30,6 pp** | Luxembourg |\n",
    "| **Haut-Rhin (68)** | **+26,3 pp** | Suisse / Allemagne |\n",
    "| **Meurthe-et-Moselle (54)** | **+24,4 pp** | Luxembourg |\n",
    "| **Meuse (55)** | **+19,1 pp** | Belgique / Luxembourg |\n",
    "| **Bas-Rhin (67)** | **+18,5 pp** | Allemagne |\n",
    "| Vosges (88) | +3,7 pp | Ã‰loignÃ© des frontiÃ¨res |\n",
    "| Haute-Marne (52) | +1,5 pp | IntÃ©rieur (NS) |\n",
    "| Aube (10) | +1,3 pp | IntÃ©rieur (NS) |\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "La localisation gÃ©ographique constitue le **dÃ©terminant le plus puissant** du modÃ¨le, avec des effets marginaux sans commune mesure avec les autres variables. RÃ©sider en Moselle plutÃ´t qu'en Marne augmente de **31 points de pourcentage** la probabilitÃ© d'Ãªtre transfrontalier â€” un effet considÃ©rable qui reflÃ¨te la structuration spatiale du phÃ©nomÃ¨ne.\n",
    "\n",
    "La hiÃ©rarchie des effets gÃ©ographiques Ã©pouse fidÃ¨lement l'attractivitÃ© diffÃ©renciÃ©e des marchÃ©s du travail frontaliers :\n",
    "\n",
    "**Axe luxembourgeois** (Moselle, Meurthe-et-Moselle, Meuse) : Le Luxembourg concentre les effets les plus forts (+19 Ã  +31 pp). Cette domination s'explique par une combinaison unique d'avantages :\n",
    "- Salaires bruts supÃ©rieurs aux Ã©quivalents franÃ§ais\n",
    "- FiscalitÃ© avantageuse (imposition Ã  la source, conventions bilatÃ©rales)\n",
    "- Forte demande de main-d'Å“uvre dans la finance, la construction et les services\n",
    "- ProximitÃ© immÃ©diate (Thionville-Luxembourg : 30 km)\n",
    "\n",
    "**Axe suisse-allemand** (Haut-Rhin, Bas-Rhin) : Les dÃ©partements alsaciens prÃ©sentent des effets lÃ©gÃ¨rement infÃ©rieurs (+18 Ã  +26 pp), reflÃ©tant :\n",
    "- La complÃ©mentaritÃ© industrielle avec le Bade-Wurtemberg (automobile, chimie, pharmacie)\n",
    "- L'attractivitÃ© salariale suisse (BÃ¢le), partiellement compensÃ©e par un coÃ»t de la vie plus Ã©levÃ©\n",
    "- Une tradition frontaliÃ¨re historique (bassin rhÃ©nan)\n",
    "\n",
    "**DÃ©partements intÃ©rieurs** : L'Aube et la Haute-Marne ne prÃ©sentent pas de diffÃ©rence significative avec la Marne, confirmant que l'effet frontalier est le **moteur exclusif** de la diffÃ©renciation gÃ©ographique. Au-delÃ  de 100 km des frontiÃ¨res, le travail transfrontalier devient statistiquement marginal.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. RÃ©seaux transnationaux : nationalitÃ© et origine gÃ©ographique\n",
    "\n",
    "> **Statut** : Variables exogÃ¨nes â€” la nationalitÃ© et le lieu de naissance sont dÃ©terminÃ©s avant l'entrÃ©e sur le marchÃ© du travail. L'interprÃ©tation causale est justifiÃ©e.\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : FranÃ§ais nÃ© dans le Grand Est\n",
    "\n",
    "### RÃ©sultats\n",
    "\n",
    "| Variable | AME | InterprÃ©tation |\n",
    "|----------|-----|----------------|\n",
    "| **NationalitÃ© Ã©trangÃ¨re** | **+6,2 pp** | Fort avantage |\n",
    "| **NÃ© Ã  l'Ã©tranger** | **+4,4 pp** | Avantage significatif |\n",
    "| NÃ© ailleurs en France | -0,4 pp | LÃ©ger dÃ©savantage |\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "Ces rÃ©sultats mettent en Ã©vidence le rÃ´le structurant des **rÃ©seaux transnationaux** dans l'accÃ¨s au travail frontalier. L'effet combinÃ© nationalitÃ© Ã©trangÃ¨re + naissance Ã  l'Ã©tranger peut atteindre **+10 pp**, soit le deuxiÃ¨me dÃ©terminant du modÃ¨le aprÃ¨s la gÃ©ographie.\n",
    "\n",
    "Trois mÃ©canismes complÃ©mentaires expliquent cet avantage :\n",
    "\n",
    "**Capital linguistique** : Les personnes d'origine Ã©trangÃ¨re, notamment allemande, luxembourgeoise ou suisse, possÃ¨dent frÃ©quemment une maÃ®trise native ou quasi-native des langues valorisÃ©es sur les marchÃ©s frontaliers. L'allemand reste indispensable dans l'industrie alsacienne ; le luxembourgeois, bien que non requis, facilite l'intÃ©gration sociale.\n",
    "\n",
    "**RÃ©seaux informationnels** : Les communautÃ©s transnationales constituent des canaux privilÃ©giÃ©s d'information sur les opportunitÃ©s d'emploi. Le bouche-Ã -oreille familial ou communautaire rÃ©duit les coÃ»ts de recherche et les asymÃ©tries d'information, particuliÃ¨rement dans les secteurs peu formalisÃ©s (construction, services Ã  la personne).\n",
    "\n",
    "**Moindre aversion Ã  la mobilitÃ©** : Les personnes ayant dÃ©jÃ  effectuÃ© une migration internationale ont rÃ©vÃ©lÃ© une prÃ©fÃ©rence pour la mobilitÃ©. Le franchissement quotidien d'une frontiÃ¨re reprÃ©sente un coÃ»t psychologique moindre pour ces populations.\n",
    "\n",
    "Le **dÃ©savantage des FranÃ§ais nÃ©s hors Grand Est** (-0,4 pp) confirme *a contrario* l'importance de l'ancrage dans les dynamiques frontaliÃ¨res locales : les migrants internes franÃ§ais ne bÃ©nÃ©ficient ni des rÃ©seaux transnationaux ni de la socialisation prÃ©coce aux opportunitÃ©s frontaliÃ¨res.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Profil dÃ©mographique\n",
    "\n",
    "### 3.1 Effet de l'Ã¢ge : une relation en U inversÃ©\n",
    "\n",
    "> **Statut** : Variable exogÃ¨ne â€” l'Ã¢ge est une caractÃ©ristique individuelle fixe. L'interprÃ©tation causale est justifiÃ©e.\n",
    "\n",
    "### RÃ©sultats\n",
    "\n",
    "| Variable | AME |\n",
    "|----------|-----|\n",
    "| Ã‚ge (linÃ©aire) | +0,41 pp par annÃ©e |\n",
    "| Ã‚geÂ² (quadratique) | -0,005 pp par annÃ©eÂ² |\n",
    "\n",
    "**Ã‚ge optimal estimÃ©** : **41 ans**\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "La relation entre Ã¢ge et travail transfrontalier suit une **forme en U inversÃ©**, avec un maximum autour de 41 ans. Ce profil rÃ©sulte de la confrontation de deux dynamiques opposÃ©es :\n",
    "\n",
    "**Phase ascendante (15-41 ans)** : Chaque annÃ©e supplÃ©mentaire augmente la probabilitÃ© d'Ãªtre transfrontalier de 0,4 pp. Cette phase reflÃ¨te :\n",
    "- L'accumulation d'expÃ©rience professionnelle valorisÃ©e par les employeurs frontaliers\n",
    "- La stabilisation familiale et rÃ©sidentielle permettant d'assumer les contraintes logistiques\n",
    "- La progression salariale rendant les trajets Ã©conomiquement rentables (seuil de rentabilitÃ©)\n",
    "\n",
    "**Phase descendante (41+ ans)** : Au-delÃ  de l'optimum, la probabilitÃ© dÃ©croÃ®t progressivement :\n",
    "- PÃ©nibilitÃ© croissante des trajets quotidiens (1h-1h30 par trajet)\n",
    "- Ancrage territorial renforcÃ© (enfants scolarisÃ©s, patrimoine immobilier)\n",
    "- Arbitrage en faveur de la qualitÃ© de vie sur les revenus marginaux\n",
    "- PrÃ©paration de la retraite (droits acquis en France vs Ã  l'Ã©tranger)\n",
    "\n",
    "L'Ã¢ge optimal de 41 ans correspond approximativement au **pic de productivitÃ© perÃ§ue** par les employeurs et au **maximum de capacitÃ© d'absorption des contraintes** par les travailleurs.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.2 Effet du genre\n",
    "\n",
    "> **Statut** : Variable exogÃ¨ne â€” le sexe est une caractÃ©ristique individuelle fixe. L'interprÃ©tation causale est justifiÃ©e.\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : Homme\n",
    "\n",
    "| Variable | AME |\n",
    "|----------|-----|\n",
    "| Femme | **-1,6 pp** |\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "Toutes choses Ã©gales par ailleurs, Ãªtre une femme diminue la probabilitÃ© d'Ãªtre transfrontalier de **1,6 point de pourcentage**. Ce diffÃ©rentiel de genre, cohÃ©rent avec la littÃ©rature sur les mobilitÃ©s professionnelles, rÃ©sulte de plusieurs mÃ©canismes :\n",
    "\n",
    "**Charge domestique et parentale** : Les femmes assurent encore majoritairement les responsabilitÃ©s familiales (Ã©cole, activitÃ©s extrascolaires, rendez-vous mÃ©dicaux). Ces contraintes temporelles sont difficilement compatibles avec les trajets longs inhÃ©rents au travail frontalier (amplitude horaire de 10h-12h journaliÃ¨res).\n",
    "\n",
    "**Segmentation sectorielle** : Les femmes sont surreprÃ©sentÃ©es dans le secteur public (enseignement, santÃ©, administration) et les services Ã  la personne â€” secteurs structurellement non-transfrontaliers car ancrÃ©s au territoire national.\n",
    "\n",
    "**Arbitrage conjugal** : Dans les couples bi-actifs, la dÃ©cision de travail frontalier fait souvent l'objet d'un arbitrage oÃ¹ un seul conjoint supporte les contraintes de mobilitÃ©, l'autre assurant la logistique familiale. Les normes de genre orientent cet arbitrage en dÃ©faveur des femmes.\n",
    "\n",
    "> **Note** : La Partie 4 approfondit cette question en testant les interactions genre Ã— covariables et rÃ©vÃ¨le des effets diffÃ©renciÃ©s substantiels, notamment sur le temps partiel et la parentalitÃ©.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Situation familiale : la contrainte parentale\n",
    "\n",
    "> **Statut** : Variables probablement exogÃ¨nes â€” le nombre d'enfants n'est pas directement causÃ© par le statut de travailleur transfrontalier (mÃªme si une causalitÃ© inverse partielle est possible Ã  long terme). L'interprÃ©tation causale est justifiÃ©e avec prudence.\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : Sans enfant\n",
    "\n",
    "### RÃ©sultats\n",
    "\n",
    "| Nombre d'enfants | AME |\n",
    "|------------------|-----|\n",
    "| 1 enfant | -0,9 pp |\n",
    "| 2 enfants | -1,2 pp |\n",
    "| 3 enfants | **-2,4 pp** |\n",
    "| 4 enfants ou plus | **-2,7 pp** |\n",
    "| Enfants hors mÃ©nage | +1,0 pp |\n",
    "\n",
    "| Statut conjugal | AME |\n",
    "|-----------------|-----|\n",
    "| En couple | +0,3 pp |\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "L'effet de la parentalitÃ© est **monotone dÃ©croissant** : chaque enfant supplÃ©mentaire rÃ©duit la probabilitÃ© de travail transfrontalier, avec une accÃ©lÃ©ration au-delÃ  de deux enfants.\n",
    "\n",
    "**Effet marginal par enfant** :\n",
    "- 0 â†’ 1 enfant : -0,9 pp\n",
    "- 1 â†’ 2 enfants : -0,3 pp (effet marginal dÃ©croissant)\n",
    "- 2 â†’ 3 enfants : -1,2 pp (accÃ©lÃ©ration)\n",
    "- 3 â†’ 4+ enfants : -0,3 pp\n",
    "\n",
    "Cette non-linÃ©aritÃ© suggÃ¨re l'existence d'un **seuil critique Ã  3 enfants**, au-delÃ  duquel les contraintes logistiques deviennent rÃ©dhibitoires.\n",
    "\n",
    "**MÃ©canismes explicatifs** :\n",
    "\n",
    "*IncompatibilitÃ© temporelle* : Les trajets frontaliers (souvent 1h-1h30 par trajet) sont difficilement conciliables avec les horaires scolaires et les activitÃ©s extrascolaires. Un parent de trois enfants scolarisÃ©s dans des Ã©tablissements diffÃ©rents fait face Ã  une Ã©quation temporelle quasi-impossible sans soutien externe.\n",
    "\n",
    "*CoÃ»ts de garde prohibitifs* : Le recours Ã  des modes de garde payants (assistante maternelle, garde pÃ©riscolaire) devient Ã©conomiquement non-viable au-delÃ  de deux enfants, mÃªme avec les revenus frontaliers.\n",
    "\n",
    "*Arbitrage conjugal* : Dans les familles nombreuses, la spÃ©cialisation des rÃ´les s'accentue â€” un parent se consacre Ã  la logistique familiale tandis que l'autre maximise les revenus (frontaliers ou non).\n",
    "\n",
    "**Effet des enfants hors mÃ©nage** (+1,0 pp) : Ce rÃ©sultat capture un **effet de libÃ©ration** : une fois les enfants partis, les contraintes parentales disparaissent et les parents peuvent (re)devenir transfrontaliers. Cet effet est particuliÃ¨rement marquÃ© pour les femmes (cf. Partie 4).\n",
    "\n",
    "**Effet du couple** (+0,3 pp) : Vivre en couple augmente lÃ©gÃ¨rement la probabilitÃ©, suggÃ©rant que le conjoint peut jouer un rÃ´le de **filet de sÃ©curitÃ© logistique**. Toutefois, l'effet reste faible et faiblement significatif (p = 0,02), confirmant que c'est la **prÃ©sence d'enfants**, non le couple en soi, qui constitue la contrainte dÃ©terminante.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. CaractÃ©ristiques professionnelles\n",
    "\n",
    "### 5.1 CatÃ©gorie socioprofessionnelle\n",
    "\n",
    "> **Statut** : Variable probablement exogÃ¨ne â€” la CSP reflÃ¨te une qualification et une trajectoire professionnelle prÃ©existantes. L'interprÃ©tation causale est justifiÃ©e.\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : EmployÃ©s\n",
    "\n",
    "### RÃ©sultats\n",
    "\n",
    "| CSP | AME |\n",
    "|-----|-----|\n",
    "| **Ouvriers** | **+1,2 pp** |\n",
    "| Professions intermÃ©diaires | -0,5 pp |\n",
    "| Cadres | -1,1 pp |\n",
    "| **Artisans, commerÃ§ants** | **-3,9 pp** |\n",
    "| Agriculteurs | -1,3 pp (NS) |\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "La structure socioprofessionnelle du travail transfrontalier rÃ©vÃ¨le un **double marchÃ©** :\n",
    "\n",
    "**Les ouvriers : catÃ©gorie la plus mobile** (+1,2 pp)\n",
    "\n",
    "Les ouvriers constituent la catÃ©gorie la plus encline au travail transfrontalier, reflÃ©tant :\n",
    "\n",
    "- *Forte demande industrielle frontaliÃ¨re* : L'industrie luxembourgeoise (sidÃ©rurgie, construction), allemande (automobile, chimie) et suisse (pharmacie, mÃ©canique de prÃ©cision) recrute massivement des ouvriers qualifiÃ©s franÃ§ais.\n",
    "\n",
    "- *DiffÃ©rentiels salariaux maximaux* : C'est pour les qualifications ouvriÃ¨res que l'Ã©cart de rÃ©munÃ©ration France/Ã©tranger est le plus attractif. Un ouvrier qualifiÃ© gagne 30 Ã  50% de plus au Luxembourg qu'en Lorraine pour un poste Ã©quivalent.\n",
    "\n",
    "- *Tradition industrielle transfrontaliÃ¨re* : Le bassin sidÃ©rurgique lorrain et le bassin rhÃ©nan ont historiquement fonctionnÃ© comme des marchÃ©s du travail intÃ©grÃ©s, crÃ©ant des filiÃ¨res de recrutement transgÃ©nÃ©rationnelles.\n",
    "\n",
    "**Les indÃ©pendants : catÃ©gorie la moins mobile** (-3,9 pp)\n",
    "\n",
    "Les artisans, commerÃ§ants et chefs d'entreprise prÃ©sentent la probabilitÃ© la plus faible, ce qui s'explique par :\n",
    "\n",
    "- *Ancrage territorial de l'activitÃ©* : Un commerce, un artisanat ou une entreprise de services dÃ©pend d'une clientÃ¨le locale. La dÃ©localisation de l'activitÃ© vers l'Ã©tranger est juridiquement et Ã©conomiquement complexe.\n",
    "\n",
    "- *Contraintes rÃ©glementaires* : Les qualifications artisanales ne sont pas automatiquement reconnues d'un pays Ã  l'autre. Les dÃ©marches d'Ã©quivalence sont coÃ»teuses.\n",
    "\n",
    "- *Logique entrepreneuriale vs salariale* : Le travail frontalier est fondamentalement une stratÃ©gie salariale d'arbitrage. Les entrepreneurs poursuivent une logique diffÃ©rente (dÃ©veloppement d'activitÃ©, patrimoine professionnel).\n",
    "\n",
    "**Cadres et professions intermÃ©diaires : positions mÃ©dianes**\n",
    "\n",
    "Ces catÃ©gories prÃ©sentent des effets lÃ©gÃ¨rement nÃ©gatifs par rapport aux employÃ©s, suggÃ©rant que :\n",
    "- Les cadres trouvent des opportunitÃ©s satisfaisantes sur le marchÃ© franÃ§ais (moins d'incitation relative)\n",
    "- Les professions intermÃ©diaires sont souvent dans le secteur public (non-transfrontalier)\n",
    "\n",
    "---\n",
    "\n",
    "### 5.2 Secteur d'activitÃ©\n",
    "\n",
    "> **Statut** : Variable probablement exogÃ¨ne â€” le secteur d'activitÃ© dÃ©termine structurellement la possibilitÃ© d'Ãªtre transfrontalier. L'interprÃ©tation causale est justifiÃ©e.\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : Commerce, transports et services divers\n",
    "\n",
    "### RÃ©sultats\n",
    "\n",
    "| Secteur | AME |\n",
    "|---------|-----|\n",
    "| Industrie | -0,3 pp (NS) |\n",
    "| Construction | +0,2 pp (NS) |\n",
    "| **Administration, enseignement, santÃ©** | **-8,3 pp** |\n",
    "| **Agriculture** | **-12,0 pp** |\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "Le secteur d'activitÃ© constitue un **dÃ©terminant structurel** de l'accÃ¨s au travail transfrontalier, avec deux secteurs fortement exclus :\n",
    "\n",
    "**Agriculture : exclusion quasi-totale** (-12,0 pp)\n",
    "\n",
    "L'agriculture est le secteur le plus nÃ©gativement associÃ© au travail transfrontalier. Cette exclusion est **mÃ©canique** :\n",
    "- L'exploitation agricole est physiquement ancrÃ©e (terres, bÃ¢timents)\n",
    "- L'activitÃ© requiert une prÃ©sence quotidienne (Ã©levage, cultures)\n",
    "- Les marchÃ©s agricoles sont nationaux (PAC, circuits de distribution)\n",
    "\n",
    "**Secteur public : exclusion structurelle** (-8,3 pp)\n",
    "\n",
    "L'administration, l'enseignement et la santÃ© sont **structurellement non-transfrontaliers** :\n",
    "\n",
    "- *Fonctionnaires* : Les concours et statuts sont nationaux. Un fonctionnaire franÃ§ais ne peut exercer au Luxembourg sauf dÃ©tachement exceptionnel.\n",
    "\n",
    "- *Enseignants* : Les systÃ¨mes Ã©ducatifs ne sont pas intÃ©grÃ©s. Un professeur certifiÃ© franÃ§ais enseigne dans l'Ã‰ducation nationale, pas dans les Ã©coles luxembourgeoises.\n",
    "\n",
    "- *Personnel hospitalier* : Les systÃ¨mes de santÃ© sont nationaux. Les infirmiers, aides-soignants et mÃ©decins exercent dans le cadre de l'assurance maladie franÃ§aise.\n",
    "\n",
    "**Industrie et construction : neutralitÃ©**\n",
    "\n",
    "Ces secteurs ne diffÃ¨rent pas significativement du tertiaire marchand. L'absence d'effet net s'explique par des forces contradictoires :\n",
    "- Forte demande frontaliÃ¨re (+)\n",
    "- PrÃ©sence industrielle locale satisfaisante (âˆ’)\n",
    "- Effet captÃ© par la variable CSP \"ouvriers\" (+)\n",
    "\n",
    "---\n",
    "\n",
    "### 5.3 Type de contrat et statut d'emploi\n",
    "\n",
    "> **Statut** : Variables ambiguÃ«s â€” le type de contrat peut Ãªtre une condition d'accÃ¨s au travail frontalier (exogÃ¨ne) ou une consÃ©quence de l'emploi obtenu (endogÃ¨ne). L'interprÃ©tation reste prudente.\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : CDI / Titulaire fonction publique\n",
    "\n",
    "### RÃ©sultats\n",
    "\n",
    "| Type de contrat | AME |\n",
    "|-----------------|-----|\n",
    "| **IndÃ©pendants** | **+5,2 pp** |\n",
    "| Employeurs | +9,0 pp (effectif faible) |\n",
    "| Temps partiel | +1,5 pp |\n",
    "| CDD | -1,3 pp |\n",
    "| IntÃ©rim | -0,9 pp |\n",
    "| Apprentissage | **-6,6 pp** |\n",
    "| Emplois aidÃ©s | **-9,4 pp** |\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "**RÃ©sultat contre-intuitif : les indÃ©pendants** (+5,2 pp)\n",
    "\n",
    "Contrairement Ã  l'effet nÃ©gatif de la CSP \"artisans/commerÃ§ants\", le statut juridique d'indÃ©pendant est positivement associÃ© au travail transfrontalier. Cette apparente contradiction s'explique par la **nature diffÃ©rente des deux variables** :\n",
    "\n",
    "- La CSP \"artisans/commerÃ§ants\" capture les *petits entrepreneurs locaux* (boulanger, plombier, coiffeur) â†’ clientÃ¨le locale â†’ effet nÃ©gatif\n",
    "- Le statut \"indÃ©pendant\" inclut les *consultants, freelances et dirigeants de PME* qui exercent au Luxembourg ou en Suisse via une structure juridique transfrontaliÃ¨re â†’ effet positif\n",
    "\n",
    "Le Luxembourg attire particuliÃ¨rement les **consultants IT, auditeurs et avocats d'affaires** franÃ§ais qui s'installent comme indÃ©pendants pour bÃ©nÃ©ficier de la fiscalitÃ© avantageuse.\n",
    "\n",
    "**Formes prÃ©caires : exclusion**\n",
    "\n",
    "Les emplois aidÃ©s (-9,4 pp) et l'apprentissage (-6,6 pp) sont fortement exclus du travail transfrontalier :\n",
    "\n",
    "- *Population Ã©loignÃ©e des prÃ©requis* : Ces statuts concernent des personnes en insertion, souvent peu qualifiÃ©es et peu mobiles\n",
    "- *Dispositifs nationaux* : Les contrats aidÃ©s et l'apprentissage sont des dispositifs franÃ§ais, gÃ©rÃ©s par les institutions franÃ§aises\n",
    "- *Ancrage des CFA* : Les apprentis sont liÃ©s Ã  un centre de formation local\n",
    "\n",
    "**CDI : norme implicite du travail frontalier**\n",
    "\n",
    "Le CDI constitue la forme contractuelle dominante du travail transfrontalier. Plusieurs mÃ©canismes expliquent cette association :\n",
    "\n",
    "- *Amortissement des coÃ»ts fixes* : L'investissement initial (adaptation, trajet quotidien) n'est rentable que sur le long terme\n",
    "- *AccÃ¨s au crÃ©dit immobilier* : Les revenus frontaliers Ã©levÃ©s permettent l'accession Ã  la propriÃ©tÃ©, conditionnÃ©e Ã  un emploi stable\n",
    "- *SÃ©lection par les employeurs* : Les entreprises luxembourgeoises et suisses privilÃ©gient les CDI\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Capital humain : une relation non linÃ©aire avec le diplÃ´me\n",
    "\n",
    "> **Statut** : Variable exogÃ¨ne â€” le diplÃ´me est obtenu avant l'entrÃ©e sur le marchÃ© du travail. L'interprÃ©tation causale est justifiÃ©e.\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : CAP, BEP\n",
    "\n",
    "### RÃ©sultats\n",
    "\n",
    "| Niveau de diplÃ´me | AME |\n",
    "|-------------------|-----|\n",
    "| **Grande Ã©cole** | **+3,1 pp** |\n",
    "| **Bac+5 (Master)** | **+2,8 pp** |\n",
    "| Bac+4 | +1,5 pp |\n",
    "| Bac pro | +1,0 pp |\n",
    "| Bac+3 (Licence) | -0,3 pp (NS) |\n",
    "| Bac gÃ©nÃ©ral | -0,6 pp |\n",
    "| Bac+2 (BTS/DUT) | -0,4 pp |\n",
    "| Bac techno | -0,6 pp |\n",
    "| Sans diplÃ´me (collÃ¨ge) | -3,2 pp |\n",
    "| **Doctorat** | **-6,5 pp** |\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "La relation entre diplÃ´me et travail transfrontalier est **non monotone**, avec trois profils distincts :\n",
    "\n",
    "**Profil 1 : TrÃ¨s diplÃ´mÃ©s hors recherche (Bac+5, grandes Ã©coles)** â€” effet positif\n",
    "\n",
    "Les titulaires de masters et diplÃ´mes de grandes Ã©coles prÃ©sentent les probabilitÃ©s les plus Ã©levÃ©es (+2,8 Ã  +3,1 pp). Ce profil reflÃ¨te :\n",
    "\n",
    "- *Demande luxembourgeoise de cadres qualifiÃ©s* : Finance, audit, consulting, institutions europÃ©ennes\n",
    "- *MaÃ®trise des langues* : Ces formations incluent gÃ©nÃ©ralement une composante internationale\n",
    "- *MobilitÃ© internationale facilitÃ©e* : ExpÃ©riences d'Ã©change, stages Ã  l'Ã©tranger\n",
    "- *DiffÃ©rentiel salarial attractif* : Un consultant junior gagne 30% de plus au Luxembourg qu'Ã  Paris\n",
    "\n",
    "**Profil 2 : Doctorats** â€” effet nÃ©gatif\n",
    "\n",
    "Le doctorat prÃ©sente un effet fortement nÃ©gatif (-6,5 pp), apparemment contradictoire avec la valorisation des hauts diplÃ´mes. Cette anomalie s'explique par la **spÃ©cificitÃ© du marchÃ© doctoral** :\n",
    "\n",
    "- Les docteurs travaillent majoritairement dans la **recherche publique** (CNRS, universitÃ©s) â†’ secteur non-transfrontalier\n",
    "- Les postes acadÃ©miques sont **nationaux** (MCF, CR, DR)\n",
    "- L'industrie luxembourgeoise recrute peu de docteurs (prÃ©fÃ©rence pour les profils opÃ©rationnels)\n",
    "\n",
    "**Profil 3 : Qualifications intermÃ©diaires (Bac, BTS)** â€” effet neutre ou lÃ©gÃ¨rement nÃ©gatif\n",
    "\n",
    "Ces niveaux ne prÃ©sentent pas d'avantage particulier :\n",
    "- DÃ©bouchÃ©s locaux satisfaisants (techniciens, employÃ©s qualifiÃ©s)\n",
    "- DiffÃ©rentiel salarial frontalier moins attractif relativement au salaire local\n",
    "- Moindre incitation Ã  supporter les coÃ»ts de mobilitÃ©\n",
    "\n",
    "**Profil 4 : Sans qualification** â€” forte exclusion\n",
    "\n",
    "L'absence de diplÃ´me est associÃ©e Ã  une pÃ©nalitÃ© substantielle (-3,2 pp), reflÃ©tant des barriÃ¨res cumulatives :\n",
    "- Faible employabilitÃ© gÃ©nÃ©rale\n",
    "- BarriÃ¨res linguistiques\n",
    "- Ã‰loignement des rÃ©seaux professionnels transfrontaliers\n",
    "- Moindre accÃ¨s Ã  l'information sur les opportunitÃ©s\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Variables de contrÃ´le potentiellement endogÃ¨nes\n",
    "\n",
    "> **Statut** : Variables prÃ©sentant un **risque Ã©levÃ© de causalitÃ© inverse**. Les revenus frontaliers (30-50% supÃ©rieurs) peuvent permettre l'accession Ã  la propriÃ©tÃ© et la multi-motorisation. Les coefficients ci-dessous dÃ©crivent des **associations statistiques**, non des relations causales.\n",
    "\n",
    "### 7.1 Motorisation\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : 1 voiture\n",
    "\n",
    "| Motorisation | AME |\n",
    "|--------------|-----|\n",
    "| 0 voiture | **-4,1 pp** |\n",
    "| 2 voitures | +1,5 pp |\n",
    "| 3+ voitures | +2,1 pp |\n",
    "\n",
    "### 7.2 Statut d'occupation\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : PropriÃ©taire\n",
    "\n",
    "| Statut | AME |\n",
    "|--------|-----|\n",
    "| PropriÃ©taire accÃ©dant | -1,0 pp |\n",
    "| **Locataire HLM** | **-6,2 pp** |\n",
    "| Locataire privÃ© | -2,6 pp |\n",
    "| LogÃ© gratuitement | -3,6 pp |\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "Ces associations convergent vers un profil : le travailleur transfrontalier est statistiquement associÃ© Ã  la **propriÃ©tÃ©** et Ã  la **multi-motorisation**. Trois mÃ©canismes non exclusifs peuvent expliquer ce pattern :\n",
    "\n",
    "**HypothÃ¨se 1 : NÃ©cessitÃ© pratique (causalitÃ© variable â†’ travail frontalier)**\n",
    "\n",
    "L'automobile est indispensable pour les trajets frontaliers : transports en commun peu dÃ©veloppÃ©s, horaires dÃ©calÃ©s, flexibilitÃ© requise. La multi-motorisation permettrait Ã  un mÃ©nage d'organiser les trajets de plusieurs actifs.\n",
    "\n",
    "**HypothÃ¨se 2 : Effet richesse (causalitÃ© inverse)**\n",
    "\n",
    "Les revenus frontaliers Ã©levÃ©s permettent l'accession Ã  la propriÃ©tÃ© et l'achat de vÃ©hicules supplÃ©mentaires. Dans cette hypothÃ¨se, la propriÃ©tÃ© et la motorisation sont des *consÃ©quences* du travail frontalier.\n",
    "\n",
    "**HypothÃ¨se 3 : HÃ©tÃ©rogÃ©nÃ©itÃ© non observÃ©e (pas de causalitÃ© directe)**\n",
    "\n",
    "Les locataires HLM et les mÃ©nages sans voiture cumulent des caractÃ©ristiques dÃ©favorables Ã  l'emploi (prÃ©caritÃ©, faible qualification, moindre mobilitÃ©). L'association observÃ©e reflÃ©terait une sÃ©lection sociale plutÃ´t qu'un effet direct.\n",
    "\n",
    "**Sans instrumentation adÃ©quate, il est impossible de dÃ©partager ces mÃ©canismes.** Ces variables sont incluses comme contrÃ´les mais ne doivent pas guider les recommandations de politique publique.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Temps de travail\n",
    "\n",
    "> **Statut** : Variable ambiguÃ« â€” le temps partiel peut Ãªtre une cause (contrainte) ou une consÃ©quence (choix) du travail transfrontalier.\n",
    "\n",
    "**CatÃ©gorie de rÃ©fÃ©rence** : Temps complet\n",
    "\n",
    "| Variable | AME |\n",
    "|----------|-----|\n",
    "| Temps partiel | **+1,5 pp** |\n",
    "\n",
    "### InterprÃ©tation Ã©conomique\n",
    "\n",
    "Ce rÃ©sultat, contre-intuitif au premier abord, peut s'expliquer par plusieurs mÃ©canismes :\n",
    "\n",
    "**Temps partiels choisis** : Certains travailleurs frontaliers optent pour un temps partiel afin de concilier trajets longs et vie familiale. Un 80% au Luxembourg peut gÃ©nÃ©rer un revenu net Ã©quivalent Ã  un temps plein en France.\n",
    "\n",
    "**Structure des emplois frontaliers** : Certains emplois luxembourgeois (services, finance) sont proposÃ©s en temps partiel, notamment pour les postes administratifs.\n",
    "\n",
    "**Arbitrage conjugal** : Dans les couples bi-actifs, un conjoint peut travailler Ã  temps partiel (frontalier ou non) pendant que l'autre effectue les trajets complets.\n",
    "\n",
    "> **Note** : La Partie 4 rÃ©vÃ¨le que cet effet est **trÃ¨s diffÃ©renciÃ© selon le genre** : le temps partiel a un effet nÃ©gatif pour les hommes (-0,6 pp) mais fortement positif pour les femmes (+2,2 pp), confirmant qu'il s'agit d'une stratÃ©gie de conciliation spÃ©cifiquement fÃ©minine.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. SynthÃ¨se des dÃ©terminants\n",
    "\n",
    "### Facteurs favorisant le travail transfrontalier\n",
    "\n",
    "| Rang | DÃ©terminant | AME | MÃ©canisme principal |\n",
    "|------|-------------|-----|---------------------|\n",
    "| 1 | RÃ©sider en Moselle | +30,6 pp | ProximitÃ© Luxembourg |\n",
    "| 2 | RÃ©sider dans le Haut-Rhin | +26,3 pp | ProximitÃ© Suisse/Allemagne |\n",
    "| 3 | RÃ©sider en Meurthe-et-Moselle | +24,4 pp | ProximitÃ© Luxembourg |\n",
    "| 4 | NationalitÃ© Ã©trangÃ¨re | +6,2 pp | RÃ©seaux transnationaux |\n",
    "| 5 | IndÃ©pendant (consultant) | +5,2 pp | Optimisation fiscale |\n",
    "| 6 | NÃ© Ã  l'Ã©tranger | +4,4 pp | Capital linguistique |\n",
    "| 7 | Grande Ã©cole | +3,1 pp | Postes qualifiÃ©s |\n",
    "| 8 | Bac+5 | +2,8 pp | Postes qualifiÃ©s |\n",
    "| 9 | Multi-motorisation | +2,1 pp | MobilitÃ© (ou effet richesse) |\n",
    "| 10 | Ouvrier | +1,2 pp | Demande industrielle |\n",
    "\n",
    "### Facteurs freinant le travail transfrontalier\n",
    "\n",
    "| Rang | DÃ©terminant | AME | MÃ©canisme principal |\n",
    "|------|-------------|-----|---------------------|\n",
    "| 1 | Agriculture | -12,0 pp | Ancrage territorial |\n",
    "| 2 | Emplois aidÃ©s | -9,4 pp | Population en insertion |\n",
    "| 3 | Administration/SantÃ©/Ã‰ducation | -8,3 pp | Secteur public national |\n",
    "| 4 | Apprentissage | -6,6 pp | Dispositif national |\n",
    "| 5 | Doctorat | -6,5 pp | Recherche publique |\n",
    "| 6 | Locataire HLM | -6,2 pp | SÃ©lection sociale |\n",
    "| 7 | Aucune voiture | -4,1 pp | Contrainte mobilitÃ© |\n",
    "| 8 | Artisans/CommerÃ§ants | -3,9 pp | ClientÃ¨le locale |\n",
    "| 9 | Sans diplÃ´me | -3,2 pp | BarriÃ¨res multiples |\n",
    "| 10 | 4+ enfants | -2,7 pp | Contrainte familiale |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4327a3",
   "metadata": {},
   "source": [
    "## 11. QualitÃ© de l'estimation Ã©conomÃ©trique\n",
    "\n",
    "### 11.1 Indicateurs de qualitÃ© globale\n",
    "\n",
    "| Indicateur | Valeur | InterprÃ©tation |\n",
    "|------------|:------:|----------------|\n",
    "| **Nombre d'observations** | 494 483 | Ã‰chantillon trÃ¨s large, puissance statistique Ã©levÃ©e |\n",
    "| **Pseudo RÂ² (McFadden)** | 0,2393 | Bon ajustement pour un modÃ¨le binaire sur donnÃ©es individuelles |\n",
    "| **Log-vraisemblance** | -113 380 | â€” |\n",
    "| **Log-vraisemblance nulle** | -149 050 | â€” |\n",
    "| **Test LR (Ï‡Â²)** | 71 340 | â€” |\n",
    "| **p-value LR** | < 0,001 | ModÃ¨le globalement trÃ¨s significatif |\n",
    "| **Convergence** | Oui (10 itÃ©rations) | Algorithme stable |\n",
    "\n",
    "### 11.2 InterprÃ©tation du Pseudo RÂ²\n",
    "\n",
    "Un Pseudo RÂ² de McFadden de **0,24** est considÃ©rÃ© comme **bon** pour un modÃ¨le de choix discret sur donnÃ©es individuelles. Ã€ titre de comparaison :\n",
    "\n",
    "Un Pseudo RÂ² entre 0,20 et 0,40 est gÃ©nÃ©ralement jugÃ© satisfaisant en Ã©conomÃ©trie des choix\n",
    "Ce critÃ¨re mesure l'ajustement global mais ne suffit pas Ã  Ã©valuer la capacitÃ© prÃ©dictive\n",
    "\n",
    "Les mÃ©triques complÃ©mentaires prÃ©sentÃ©es ci-dessous (AUC-ROC, Brier Score, validation croisÃ©e) confirment que le modÃ¨le discrimine efficacement les travailleurs transfrontaliers des non-transfrontaliers et ne souffre pas de sur-ajustement.\n",
    "\n",
    "### 11.3 SignificativitÃ© des variables \n",
    "\n",
    "| CatÃ©gorie                             | Nombre |\n",
    "|-----------                            |:------:|\n",
    "| Variables significatives au seuil 1%  | 56 / 65|\n",
    "| Variables significatives au seuil 5%  | 2 / 65 |\n",
    "| Variables significatives au seuil 10% | 2 / 65 |\n",
    "| Variables non significatives          | 5 / 65 |\n",
    "\n",
    "**Variables non significatives** : GS_1 (agriculteurs exploitants), DEPT_10 (Aube), DEPT_52 (Haute-Marne), NA5_BE (industrie), TYPL_5 (habitation de fortune).\n",
    "\n",
    "Ces non-significativitÃ©s sont cohÃ©rentes Ã©conomiquement (effectifs faibles ou absence de diffÃ©rence rÃ©elle avec la rÃ©fÃ©rence).\n",
    "\n",
    "### 11.4 Pouvoir discriminant et calibration\n",
    "\n",
    "La qualitÃ© prÃ©dictive du modÃ¨le est Ã©valuÃ©e par des mÃ©triques complÃ©mentaires au Pseudo RÂ².\n",
    "\n",
    "L'**AUC-ROC** atteint **0,849** avec un intervalle de confiance bootstrap de [0,848 ; 0,850], ce qui correspond Ã  une excellente capacitÃ© discriminante selon les seuils conventionnels (un AUC supÃ©rieur Ã  0,8 est gÃ©nÃ©ralement considÃ©rÃ© comme trÃ¨s bon). ConcrÃ¨tement, le modÃ¨le classe correctement 84,9 % des paires (transfrontalier, non-transfrontalier) tirÃ©es au hasard.\n",
    "\n",
    "Le **Brier Score** s'Ã©tablit Ã  **0,0681**, contre 0,0815 pour le modÃ¨le nul (correspondant Ã  la prÃ©valence de 8,95 %). Le modÃ¨le estimÃ© rÃ©duit donc l'erreur de prÃ©diction de **16,4 %** par rapport Ã  une prÃ©diction naÃ¯ve. Le **Brier Skill Score** associÃ© de **0,164** indique un pouvoir prÃ©dictif modeste mais significatif.\n",
    "\n",
    "Enfin, la **calibration par dÃ©ciles** rÃ©vÃ¨le une adÃ©quation quasi-parfaite entre les probabilitÃ©s prÃ©dites et les frÃ©quences observÃ©es. L'Ã©cart absolu moyen entre les deux n'est que de **0,0033**, soit 0,33 point de pourcentage. Cela signifie que le modÃ¨le ne sur-estime ni ne sous-estime systÃ©matiquement les probabilitÃ©s : un individu auquel le modÃ¨le attribue une probabilitÃ© de 20 % d'Ãªtre transfrontalier a effectivement environ 20 % de chances de l'Ãªtre dans les donnÃ©es observÃ©es.\n",
    "\n",
    "## 11.5 â€” Validation croisÃ©e et stabilitÃ©\n",
    "\n",
    "La robustesse du modÃ¨le est testÃ©e par validation croisÃ©e stratifiÃ©e Ã  5 plis (*5-fold cross-validation*).\n",
    "\n",
    "L'**AUC moyenne** obtenue sur les 5 plis est de **0,841** avec un Ã©cart-type de seulement **0,004**. Cette trÃ¨s faible dispersion entre les plis confirme la stabilitÃ© du pouvoir discriminant du modÃ¨le. Le **Brier Score** en validation croisÃ©e s'Ã©tablit Ã  **0,069 Â± 0,0003**, quasi-identique Ã  l'estimation sur l'Ã©chantillon complet.\n",
    "\n",
    "L'Ã©cart-type inter-plis infÃ©rieur Ã  **0,5 %** permet de conclure Ã  l'**absence de sur-ajustement**. Le modÃ¨le gÃ©nÃ©ralise bien Ã  des donnÃ©es non utilisÃ©es pour l'estimation, et les coefficients ne sont pas le fruit d'un ajustement excessif aux particularitÃ©s de l'Ã©chantillon.\n",
    "\n",
    "L'AUC en validation croisÃ©e (0,841) reste trÃ¨s proche de l'AUC sur l'Ã©chantillon complet (0,849), Ã©cartant tout risque d'optimisme excessif dans l'Ã©valuation du modÃ¨le. La performance prÃ©dictive est donc **reproductible** sur diffÃ©rentes partitions des donnÃ©es.\n",
    "\n",
    "## 11.6 â€” Robustesse des coefficients\n",
    "\n",
    "La stabilitÃ© des estimations a Ã©tÃ© vÃ©rifiÃ©e selon trois approches complÃ©mentaires.\n",
    "\n",
    "**Exclusion des variables potentiellement endogÃ¨nes.** L'exclusion des 15 variables prÃ©sentant un risque de causalitÃ© inverse (motorisation, statut d'occupation, type de logement, superficie) produit des coefficients trÃ¨s proches de l'estimation principale. La variation maximale observÃ©e est de **4,4 %** sur la variable SEXE_2 (Femme). Les effets gÃ©ographiques (dÃ©partements frontaliers) varient de moins de **1 %**, et l'effet de la nationalitÃ© Ã©trangÃ¨re de moins de **2 %**. Cette stabilitÃ© confirme que les variables exogÃ¨nes du modÃ¨le capturent des effets **structurels** et non des artefacts liÃ©s aux corrÃ©lations avec les variables endogÃ¨nes.\n",
    "\n",
    "**Estimations par sous-Ã©chantillons.** Le modÃ¨le a Ã©tÃ© rÃ©-estimÃ© sÃ©parÃ©ment sur les hommes (Pseudo RÂ² = 0,241, n = 252 847), les femmes (Pseudo RÂ² = 0,233, n = 241 636), les 25-44 ans (Pseudo RÂ² = 0,248, n = 212 156) et les 45-64 ans (Pseudo RÂ² = 0,237, n = 176 892). Les Pseudo RÂ² restent dans une fourchette Ã©troite (0,233 â€“ 0,248), attestant de la **robustesse structurelle** du modÃ¨le quel que soit le sous-groupe considÃ©rÃ©.\n",
    "\n",
    "**Comparaison Probit / Logit.** Les effets marginaux issus des spÃ©cifications Probit et Logit prÃ©sentent une corrÃ©lation de **0,995**, confirmant que les rÃ©sultats ne dÃ©pendent pas du choix de la fonction de lien.\n",
    "\n",
    "## 11.7 â€” Analyse des rÃ©sidus extrÃªmes\n",
    "\n",
    "**4,33 % des observations** (21 415 individus) prÃ©sentent des rÃ©sidus de Pearson gÃ©nÃ©ralisÃ©s supÃ©rieurs Ã  3 en valeur absolue. Ces cas correspondent Ã  des prÃ©dictions fortement Ã©loignÃ©es de la rÃ©alisation.\n",
    "\n",
    "Ces rÃ©sidus extrÃªmes sont concentrÃ©s dans les dÃ©partements frontaliers : la Moselle reprÃ©sente **15,5 %** des cas, le Haut-Rhin **12,2 %**, la Meurthe-et-Moselle **11,6 %** et le Bas-Rhin **9,8 %**. Cette rÃ©partition gÃ©ographique n'est pas le fruit du hasard : elle reflÃ¨te la forte hÃ©tÃ©rogÃ©nÃ©itÃ© intra-dÃ©partementale des comportements dans les zones proches des frontiÃ¨res.\n",
    "\n",
    "Ces observations ne constituent **pas des erreurs de mesure** ni des anomalies Ã  exclure. Elles reflÃ¨tent l'**hÃ©tÃ©rogÃ©nÃ©itÃ© rÃ©elle** de la population. Les faux nÃ©gatifs correspondent Ã  des individus rÃ©sidant en zone frontaliÃ¨re mais travaillant en France, pour des raisons de prÃ©fÃ©rences personnelles, d'emploi local attractif ou de contraintes familiales. Les faux positifs correspondent Ã  des individus rÃ©sidant loin des frontiÃ¨res mais travaillant nÃ©anmoins Ã  l'Ã©tranger, souvent liÃ©s Ã  des situations professionnelles spÃ©cifiques.\n",
    "\n",
    "La concentration des rÃ©sidus extrÃªmes dans les dÃ©partements frontaliers illustre les **limites intrinsÃ¨ques** d'un modÃ¨le probabiliste : mÃªme avec des caractÃ©ristiques observables identiques, les choix individuels demeurent partiellement irrÃ©ductibles aux variables du modÃ¨le.\n",
    "\n",
    "### 11.8 â€” Comparaison MEM vs AME\n",
    "\n",
    "Les effets marginaux moyens (AME) sont environ **deux fois supÃ©rieurs** aux effets \n",
    "Ã  la moyenne (MEM), avec une corrÃ©lation parfaite de 1,00. Ce ratio constant \n",
    "s'explique par la concentration gÃ©ographique du phÃ©nomÃ¨ne : l'individu \"moyen\" \n",
    "fictif prÃ©sente une probabilitÃ© prÃ©dite trÃ¨s faible (~5%), tandis que la \n",
    "population rÃ©elle inclut de nombreux rÃ©sidents frontaliers avec des probabilitÃ©s \n",
    "Ã©levÃ©es (20-40%).\n",
    "\n",
    "Cette diffÃ©rence n'affecte pas les conclusions qualitatives (classement des \n",
    "dÃ©terminants, significativitÃ©) mais modifie l'interprÃ©tation quantitative : \n",
    "les AME, retenus dans ce rapport, reflÃ¨tent l'effet moyen **rÃ©ellement vÃ©cu** \n",
    "dans la population.\n",
    "\n",
    "---\n",
    "\n",
    "## 12. Limites mÃ©thodologiques et extensions futures\n",
    "\n",
    "### 12.1 Limites du modÃ¨le actuel\n",
    "\n",
    "#### EndogÃ©nÃ©itÃ© de certaines variables\n",
    "\n",
    "Plusieurs variables explicatives (propriÃ©tÃ©, motorisation, type de logement) sont potentiellement **endogÃ¨nes** : elles peuvent Ãªtre des consÃ©quences plutÃ´t que des causes du travail transfrontalier. Sans correction, les coefficients estimÃ©s sont **biaisÃ©s** et ne permettent pas d'infÃ©rence causale.\n",
    "\n",
    "#### Imperfections de la forme fonctionnelle\n",
    "\n",
    "Les tests de spÃ©cification classiques (Link test de Pregibon, Hosmer-Lemeshow) rejettent l'hypothÃ¨se nulle, suggÃ©rant que la forme fonctionnelle du modÃ¨le Probit n'est pas parfaitement adaptÃ©e aux donnÃ©es. Bien que ces signaux soient mÃ©caniquement amplifiÃ©s par la taille de l'Ã©chantillon (prÃ¨s de 500 000 observations), ils rappellent que la spÃ©cification retenue demeure une **approximation** de la rÃ©alitÃ©. En particulier, la concentration gÃ©ographique extrÃªme du phÃ©nomÃ¨ne â€” 90 % des transfrontaliers dans 4 dÃ©partements â€” pourrait justifier des modÃ©lisations alternatives intÃ©grant une structure spatiale explicite.\n",
    "\n",
    "#### Variables omises\n",
    "\n",
    "Le modÃ¨le n'inclut pas :\n",
    "- La **distance prÃ©cise Ã  la frontiÃ¨re** (seul le dÃ©partement est disponible)\n",
    "- Les **compÃ©tences linguistiques** (allemand, luxembourgeois)\n",
    "- Le **diffÃ©rentiel salarial individuel** entre emploi local et frontalier\n",
    "- Les **prÃ©fÃ©rences individuelles** (aversion aux trajets, attachement territorial)\n",
    "\n",
    "#### HÃ©tÃ©rogÃ©nÃ©itÃ© non observÃ©e\n",
    "\n",
    "Des caractÃ©ristiques individuelles non mesurÃ©es (motivation, rÃ©seau professionnel, santÃ©) peuvent influencer simultanÃ©ment le choix de rÃ©sidence et le travail frontalier.\n",
    "\n",
    "#### Coupe transversale\n",
    "\n",
    "L'analyse sur une seule annÃ©e (2022) ne permet pas d'Ã©tudier les dynamiques temporelles (entrÃ©es/sorties du travail frontalier, effets de la conjoncture).\n",
    "\n",
    "---\n",
    "\n",
    "### 12.2 Extensions futures recommandÃ©es\n",
    "\n",
    "#### 1. Traitement de l'endogÃ©nÃ©itÃ©\n",
    "\n",
    "| MÃ©thode | Principe | Application possible |\n",
    "|---------|----------|----------------------|\n",
    "| **Probit Ã  Variables Instrumentales (IV Probit)** | Trouver un instrument Z affectant la variable endogÃ¨ne mais pas Y directement | Instrument potentiel : taux de propriÃ©taires dans la commune d'origine |\n",
    "| **Control Function Approach** | Inclure les rÃ©sidus de la 1Ã¨re Ã©tape dans le probit | Permet de tester l'endogÃ©nÃ©itÃ© |\n",
    "| **Probit bivariÃ© rÃ©cursif** | ModÃ©liser simultanÃ©ment P(propriÃ©taire) et P(transfrontalier) | Identification par restrictions d'exclusion |\n",
    "\n",
    "#### 2. ModÃ¨le Probit avec interactions par genre (prÃ©vu)\n",
    "\n",
    "Objectif : Tester si les dÃ©terminants ont des **effets diffÃ©renciÃ©s** selon le sexe.\n",
    "\n",
    "SpÃ©cification :\n",
    "$$P(Y_i = 1) = \\Phi(\\beta_0 + \\beta_1 Femme_i + \\beta_2 X_i + \\beta_3 (Femme_i \\times X_i))$$\n",
    "\n",
    "Permettra de rÃ©pondre Ã  : *L'effet des enfants est-il plus fort pour les femmes ?*\n",
    "\n",
    "#### 3. ModÃ¨le Probit bivariÃ© pour les couples (prÃ©vu)\n",
    "\n",
    "Objectif : Tester la **coordination des dÃ©cisions** au sein des couples.\n",
    "\n",
    "SpÃ©cification :\n",
    "$$Y_{1i}^* = X_{1i}'\\beta_1 + \\varepsilon_{1i}$$\n",
    "$$Y_{2i}^* = X_{2i}'\\beta_2 + \\varepsilon_{2i}$$\n",
    "\n",
    "avec $\\text{Corr}(\\varepsilon_1, \\varepsilon_2) = \\rho$\n",
    "\n",
    "Permettra de rÃ©pondre Ã  : *Les choix professionnels des conjoints sont-ils coordonnÃ©s ?*\n",
    "\n",
    "\n",
    "#### 5. Extensions de donnÃ©es\n",
    "\n",
    "- **Panel** : Suivre les individus sur plusieurs annÃ©es pour identifier les transitions vers le travail frontalier\n",
    "- **Variables gÃ©ographiques fines** : Distance Ã  la frontiÃ¨re, accessibilitÃ© routiÃ¨re\n",
    "- **Variables fiscales** : Revenus individuels pour calculer le diffÃ©rentiel salarial\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Cette analyse Ã©conomÃ©trique met en Ã©vidence une **hiÃ©rarchie claire des dÃ©terminants** du travail transfrontalier dans le Grand Est :\n",
    "\n",
    "1. **La gÃ©ographie domine** : RÃ©sider dans un dÃ©partement frontalier constitue le facteur le plus dÃ©terminant, avec des effets marginaux considÃ©rables : +30,6 pp pour la Moselle, +26,3 pp pour le Haut-Rhin, +24,4 pp pour la Meurthe-et-Moselle. Ces amplitudes, sans commune mesure avec les autres variables, reflÃ¨tent la structuration spatiale du phÃ©nomÃ¨ne autour des bassins d'emploi luxembourgeois, suisse et allemand.\n",
    "\n",
    "2. **Les rÃ©seaux transnationaux constituent le deuxiÃ¨me facteur** : La nationalitÃ© Ã©trangÃ¨re (+6,2 pp) et la naissance Ã  l'Ã©tranger (+4,4 pp) facilitent significativement l'accÃ¨s au travail frontalier. Ces effets, cumulables, atteignent +10 pp pour les personnes combinant les deux caractÃ©ristiques â€” reflÃ©tant le rÃ´le du capital linguistique, des rÃ©seaux informationnels et d'une moindre aversion Ã  la mobilitÃ© internationale.\n",
    "\n",
    "3. **Le profil socioprofessionnel sÃ©lectionne** : Le travail frontalier concerne prioritairement les ouvriers qualifiÃ©s (+1,2 pp) et les cadres trÃ¨s diplÃ´mÃ©s (Bac+5 : +2,8 pp ; grandes Ã©coles : +3,1 pp), tout en excluant structurellement les artisans et commerÃ§ants (-3,9 pp), le secteur public (-8,3 pp), l'agriculture (-12,0 pp) et les formes d'emploi prÃ©caires (emplois aidÃ©s : -9,4 pp). Cette segmentation rÃ©vÃ¨le un double marchÃ© frontalier : industriel pour les ouvriers, tertiaire qualifiÃ© pour les cadres.\n",
    "\n",
    "4. **La famille contraint de maniÃ¨re non linÃ©aire** : La prÃ©sence d'enfants rÃ©duit la probabilitÃ© d'Ãªtre transfrontalier selon un gradient croissant : -0,9 pp pour un enfant, -2,4 pp pour trois enfants, -2,7 pp pour quatre ou plus. L'existence d'un seuil critique autour de trois enfants suggÃ¨re que les contraintes logistiques deviennent alors rÃ©dhibitoires. Ã€ l'inverse, le dÃ©part des enfants du foyer libÃ¨re une capacitÃ© de mobilitÃ© (+1,0 pp).\n",
    "\n",
    "5. **Le genre structure les comportements** : Les femmes prÃ©sentent une probabilitÃ© infÃ©rieure de 1,6 point de pourcentage, toutes choses Ã©gales par ailleurs. Ce diffÃ©rentiel, modeste en apparence, masque une hÃ©tÃ©rogÃ©nÃ©itÃ© substantielle explorÃ©e en Partie 4 : les interactions genre Ã— covariables rÃ©vÃ¨lent des mÃ©canismes diffÃ©renciÃ©s, notamment sur le temps partiel (stratÃ©gie de conciliation fÃ©minine) et la parentalitÃ© (pÃ©nalitÃ© amplifiÃ©e pour les femmes Ã  partir de trois enfants).\n",
    "\n",
    "6. **L'Ã¢ge suit une trajectoire en U inversÃ©** : La probabilitÃ© d'Ãªtre transfrontalier croÃ®t jusqu'Ã  un optimum estimÃ© Ã  41 ans, puis dÃ©croÃ®t progressivement. Ce profil reflÃ¨te l'arbitrage entre accumulation d'expÃ©rience professionnelle (phase ascendante) et pÃ©nibilitÃ© croissante des trajets conjuguÃ©e Ã  un ancrage territorial renforcÃ© (phase descendante).\n",
    "\n",
    "7. **Les variables de logement et motorisation prÃ©sentent des associations significatives** : La propriÃ©tÃ© immobiliÃ¨re et la multi-motorisation sont positivement corrÃ©lÃ©es au travail frontalier, tandis que le logement HLM (-6,2 pp) et l'absence de vÃ©hicule (-4,1 pp) y sont nÃ©gativement associÃ©s. Toutefois, le sens de la causalitÃ© reste indÃ©terminÃ© : ces caractÃ©ristiques peuvent Ãªtre des consÃ©quences des revenus frontaliers (effet richesse) plutÃ´t que des causes, ou reflÃ©ter une hÃ©tÃ©rogÃ©nÃ©itÃ© sociale non observÃ©e.\n",
    "\n",
    "8. **Le modÃ¨le est statistiquement robuste** : Avec un pseudo-RÂ² de McFadden de 0,239, une AUC de 0,849 et une calibration quasi-parfaite, le modÃ¨le discrimine efficacement les profils transfrontaliers. La validation croisÃ©e Ã  5 plis (AUC = 0,841 Â± 0,004) confirme l'absence de sur-ajustement. Les coefficients des variables exogÃ¨nes demeurent stables lors de l'exclusion des variables potentiellement endogÃ¨nes, validant la robustesse des conclusions principales.\n",
    "\n",
    "---\n",
    "\n",
    "Ces rÃ©sultats fournissent une base solide pour les extensions dÃ©veloppÃ©es dans les parties suivantes :\n",
    "\n",
    "- La **Partie 4 (Probit avec interactions de genre)** teste si les dÃ©terminants â€” notamment la parentalitÃ©, le temps de travail et le diplÃ´me â€” affectent diffÃ©remment les hommes et les femmes. Les rÃ©sultats confirment une hÃ©tÃ©rogÃ©nÃ©itÃ© substantielle : 9 dimensions sur 10 prÃ©sentent des effets statistiquement diffÃ©renciÃ©s selon le genre.\n",
    "\n",
    "- La **Partie 5 (Probit bivariÃ©)** modÃ©lisera la coordination des dÃ©cisions professionnelles au sein des couples, testant si les choix des conjoints sont indÃ©pendants, complÃ©mentaires ou substitutifs.\n",
    "\n",
    "---\n",
    "\n",
    "*Rapport rÃ©digÃ© le 7 janvier 2026 â€” Projet INSEE MobilitÃ© TransfrontaliÃ¨re Grand Est\n",
    "*Romain Mehdi FEHRI\n",
    "*Master 2 Statistique, Ã‰conomÃ©trie & Data Science â€” UniversitÃ© de Strasbourg*\n",
    "\n",
    "*L'estimation repose sur un modÃ¨le **Probit binaire** appliquÃ© Ã  **494 483 observations** issues du Recensement de la Population 2021 (INSEE) et de la base MOBPRO des mobilitÃ©s professionnelles.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
